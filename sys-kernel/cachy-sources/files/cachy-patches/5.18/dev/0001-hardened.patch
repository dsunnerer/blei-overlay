From 1225cbf4de64131057f988724e7234f6accfe091 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Sat, 27 May 2017 07:22:12 -0400
Subject: [PATCH 001/104] make DEFAULT_MMAP_MIN_ADDR match LSM_MMAP_MIN_ADDR

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
(cherry picked from commit e2baeb472d421989e5061e2723b47df1679e861e)
---
 mm/Kconfig | 3 ++-
 1 file changed, 2 insertions(+), 1 deletion(-)

diff --git a/mm/Kconfig b/mm/Kconfig
index 034d87953600..fd932dac48e4 100644
--- a/mm/Kconfig
+++ b/mm/Kconfig
@@ -314,7 +314,8 @@ config KSM
 config DEFAULT_MMAP_MIN_ADDR
 	int "Low address space to protect from user allocation"
 	depends on MMU
-	default 4096
+	default 32768 if ARM || (ARM64 && COMPAT)
+	default 65536
 	help
 	  This is the portion of low virtual memory which should be protected
 	  from userspace allocation.  Keeping a user from writing to low pages
-- 
2.36.1

From d42fe0a077ebaba51ab1952e276427c2795096f7 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Mon, 29 May 2017 06:17:41 -0400
Subject: [PATCH 002/104] enable HARDENED_USERCOPY by default

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
(cherry picked from commit 5b42fcde6f61f03f59f7d8dd88c5a1ac9b222a1d)
---
 security/Kconfig | 1 +
 1 file changed, 1 insertion(+)

diff --git a/security/Kconfig b/security/Kconfig
index 9b2c4925585a..4065df6b9a85 100644
--- a/security/Kconfig
+++ b/security/Kconfig
@@ -154,6 +154,7 @@ config HARDENED_USERCOPY
 	bool "Harden memory copies between kernel and userspace"
 	depends on HAVE_HARDENED_USERCOPY_ALLOCATOR
 	imply STRICT_DEVMEM
+	default y
 	help
 	  This option checks for obviously wrong memory regions when
 	  copying memory to/from the kernel (via copy_to_user() and
-- 
2.36.1

From 15d5962de906e05aa713f549c3e00528193205f7 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Wed, 3 May 2017 12:05:15 -0400
Subject: [PATCH 003/104] enable SECURITY_DMESG_RESTRICT by default

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
(cherry picked from commit d4c25afa07be8793a0ee4af8468accf1f335c3d0)
---
 security/Kconfig | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/security/Kconfig b/security/Kconfig
index 4065df6b9a85..01cad4dd5cc9 100644
--- a/security/Kconfig
+++ b/security/Kconfig
@@ -9,7 +9,7 @@ source "security/keys/Kconfig"
 
 config SECURITY_DMESG_RESTRICT
 	bool "Restrict unprivileged access to the kernel syslog"
-	default n
+	default y
 	help
 	  This enforces restrictions on unprivileged users reading the kernel
 	  syslog via dmesg(8).
-- 
2.36.1

From fa48e90039af298afe305fbacfdb925086e4b743 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Wed, 3 May 2017 12:06:14 -0400
Subject: [PATCH 004/104] set kptr_restrict=2 by default

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
(cherry picked from commit 9fb4d9aa3f3eb220029424a73729d65f3dc66ae6)
---
 lib/vsprintf.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/lib/vsprintf.c b/lib/vsprintf.c
index 40d26a07a133..403c4197cc09 100644
--- a/lib/vsprintf.c
+++ b/lib/vsprintf.c
@@ -868,7 +868,7 @@ static char *default_pointer(char *buf, char *end, const void *ptr,
 	return ptr_to_id(buf, end, ptr, spec);
 }
 
-int kptr_restrict __read_mostly;
+int kptr_restrict __read_mostly = 2;
 
 static noinline_for_stack
 char *restricted_pointer(char *buf, char *end, const void *ptr,
-- 
2.36.1

From ffb47a3755bdf3dffe8fcca17c4243fe0a9d13e5 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Wed, 3 May 2017 12:10:57 -0400
Subject: [PATCH 005/104] enable DEBUG_LIST by default

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
(cherry picked from commit 107b9e25ffe97f5738bbbb26f3ca6efc4424081e)
---
 lib/Kconfig.debug | 1 +
 1 file changed, 1 insertion(+)

diff --git a/lib/Kconfig.debug b/lib/Kconfig.debug
index 7e282970177a..c0adc3a2da60 100644
--- a/lib/Kconfig.debug
+++ b/lib/Kconfig.debug
@@ -1658,6 +1658,7 @@ menu "Debug kernel data structures"
 config DEBUG_LIST
 	bool "Debug linked list manipulation"
 	depends on DEBUG_KERNEL || BUG_ON_DATA_CORRUPTION
+	default y
 	help
 	  Enable this to turn on extended checks in the linked-list
 	  walking routines.
-- 
2.36.1

From 1b423795b5d959a9a2fef82f21ec72ab3695de74 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Mon, 29 May 2017 12:21:21 -0400
Subject: [PATCH 006/104] enable BUG_ON_DATA_CORRUPTION by default

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
(cherry picked from commit ab1293943431ebf81f58104a8fd7d0122fd299b1)
---
 lib/Kconfig.debug | 1 +
 1 file changed, 1 insertion(+)

diff --git a/lib/Kconfig.debug b/lib/Kconfig.debug
index c0adc3a2da60..70a6c83ef4cc 100644
--- a/lib/Kconfig.debug
+++ b/lib/Kconfig.debug
@@ -1698,6 +1698,7 @@ config DEBUG_NOTIFIERS
 config BUG_ON_DATA_CORRUPTION
 	bool "Trigger a BUG when data corruption is detected"
 	select DEBUG_LIST
+	default y
 	help
 	  Select this option if the kernel should BUG when it encounters
 	  data corruption in kernel memory structures when they get checked
-- 
2.36.1

From 8fe6e114240c6f22b4407fae0992a250b0e5349e Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Sun, 25 Feb 2018 01:39:32 -0500
Subject: [PATCH 007/104] enable ARM64_SW_TTBR0_PAN by default

(cherry picked from commit c2bbab08917ac791d7c68512bfaea1c85b267b6d)
---
 arch/arm64/Kconfig | 1 +
 1 file changed, 1 insertion(+)

diff --git a/arch/arm64/Kconfig b/arch/arm64/Kconfig
index 20ea89d9ac2f..c6ad3a3fc8a6 100644
--- a/arch/arm64/Kconfig
+++ b/arch/arm64/Kconfig
@@ -1422,6 +1422,7 @@ config RODATA_FULL_DEFAULT_ENABLED
 
 config ARM64_SW_TTBR0_PAN
 	bool "Emulate Privileged Access Never using TTBR0_EL1 switching"
+	default y
 	help
 	  Enabling this option prevents the kernel from accessing
 	  user-space memory directly by pointing TTBR0_EL1 to a reserved
-- 
2.36.1

From d40ca96dba6aa75fad5403c8ce4b1d27cb074f6f Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Sun, 25 Feb 2018 01:33:48 -0500
Subject: [PATCH 008/104] arm64: enable RANDOMIZE_BASE by default

(cherry picked from commit 06eb85b987e934a97f32d2ecc6488511d94191fb)
---
 arch/arm64/Kconfig | 1 +
 1 file changed, 1 insertion(+)

diff --git a/arch/arm64/Kconfig b/arch/arm64/Kconfig
index c6ad3a3fc8a6..a7b919fe57a8 100644
--- a/arch/arm64/Kconfig
+++ b/arch/arm64/Kconfig
@@ -2011,6 +2011,7 @@ config RANDOMIZE_BASE
 	bool "Randomize the address of the kernel image"
 	select ARM64_MODULE_PLTS if MODULES
 	select RELOCATABLE
+	default y
 	help
 	  Randomizes the virtual address at which the kernel image is
 	  loaded, as a security feature that deters exploit attempts
-- 
2.36.1

From ccb49109dd129828514e8a9386af0dfec7d5ca9d Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Wed, 3 May 2017 19:43:38 -0400
Subject: [PATCH 009/104] enable SLAB_FREELIST_RANDOM by default

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
(cherry picked from commit be5adbbece3841abde6fa5cbf7941ac5f88874bc)
---
 init/Kconfig | 1 +
 1 file changed, 1 insertion(+)

diff --git a/init/Kconfig b/init/Kconfig
index b19e2eeaae80..835ab4f990fc 100644
--- a/init/Kconfig
+++ b/init/Kconfig
@@ -1953,6 +1953,7 @@ config SLAB_MERGE_DEFAULT
 config SLAB_FREELIST_RANDOM
 	bool "Randomize slab freelist"
 	depends on SLAB || SLUB
+	default y
 	help
 	  Randomizes the freelist order used on creating new pages. This
 	  security feature reduces the predictability of the kernel slab
-- 
2.36.1

From 2200c69d94031007e5b1cedf095ddbe329178df3 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Sun, 20 Aug 2017 15:39:25 -0400
Subject: [PATCH 010/104] enable SLAB_FREELIST_HARDENED by default

(cherry picked from commit 22e5ffc55e89b84427ac3131d7f14ca82b0d554e)
---
 init/Kconfig | 1 +
 1 file changed, 1 insertion(+)

diff --git a/init/Kconfig b/init/Kconfig
index 835ab4f990fc..26c152c8dcc3 100644
--- a/init/Kconfig
+++ b/init/Kconfig
@@ -1962,6 +1962,7 @@ config SLAB_FREELIST_RANDOM
 config SLAB_FREELIST_HARDENED
 	bool "Harden slab freelist metadata"
 	depends on SLAB || SLUB
+	default y
 	help
 	  Many kernel heap attacks try to target slab cache metadata and
 	  other infrastructure. This options makes minor performance
-- 
2.36.1

From b5bb3b3f04c9eadd57b997324c85e4b7fec7fc4e Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Sat, 8 Jul 2017 02:38:54 -0400
Subject: [PATCH 011/104] disable SLAB_MERGE_DEFAULT by default

(cherry picked from commit 5d214d3bd50d74a3bb59b48ad7d0c1500f2f6b83)
---
 init/Kconfig | 1 -
 1 file changed, 1 deletion(-)

diff --git a/init/Kconfig b/init/Kconfig
index 26c152c8dcc3..2b1be108def6 100644
--- a/init/Kconfig
+++ b/init/Kconfig
@@ -1937,7 +1937,6 @@ endchoice
 
 config SLAB_MERGE_DEFAULT
 	bool "Allow slab caches to be merged"
-	default y
 	depends on SLAB || SLUB
 	help
 	  For reduced kernel memory fragmentation, slab caches can be
-- 
2.36.1

From 20c77c65d2113ae217c6df5a52cf0da77a7972aa Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Mon, 8 May 2017 12:51:54 -0400
Subject: [PATCH 012/104] enable FORTIFY_SOURCE by default

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
(cherry picked from commit 86bbfeeb273f5c7259d7df0d94cc9fafec8f5056)
---
 security/Kconfig | 1 +
 1 file changed, 1 insertion(+)

diff --git a/security/Kconfig b/security/Kconfig
index 01cad4dd5cc9..6bbe8026773a 100644
--- a/security/Kconfig
+++ b/security/Kconfig
@@ -182,6 +182,7 @@ config FORTIFY_SOURCE
 	depends on !CC_IS_CLANG || CLANG_VERSION >= 120001
 	# https://github.com/llvm/llvm-project/issues/53645
 	depends on !CC_IS_CLANG || !X86_32
+	default y
 	help
 	  Detect overflows of buffers in common string and memory functions
 	  where the compiler can determine and validate the buffer sizes.
-- 
2.36.1

From d24af95cdcb8ae071aa35a5212864c06ba599d12 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Wed, 3 May 2017 12:09:17 -0400
Subject: [PATCH 013/104] enable PANIC_ON_OOPS by default

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
(cherry picked from commit 511a05bcacc2b1c4807074b6fd898d47c6b4c836)
---
 lib/Kconfig.debug | 3 ++-
 1 file changed, 2 insertions(+), 1 deletion(-)

diff --git a/lib/Kconfig.debug b/lib/Kconfig.debug
index 70a6c83ef4cc..23ac37cf1389 100644
--- a/lib/Kconfig.debug
+++ b/lib/Kconfig.debug
@@ -1012,6 +1012,7 @@ menu "Debug Oops, Lockups and Hangs"
 
 config PANIC_ON_OOPS
 	bool "Panic on Oops"
+	default y
 	help
 	  Say Y here to enable the kernel to panic when it oopses. This
 	  has the same effect as setting oops=panic on the kernel command
@@ -1021,7 +1022,7 @@ config PANIC_ON_OOPS
 	  anything erroneous after an oops which could result in data
 	  corruption or other issues.
 
-	  Say N if unsure.
+	  Say Y if unsure.
 
 config PANIC_ON_OOPS_VALUE
 	int
-- 
2.36.1

From 1c9ad9acfd9b5cfcdc867378eea32ecefde818b7 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Sun, 14 May 2017 22:39:34 -0400
Subject: [PATCH 014/104] stop hiding SLUB_DEBUG behind EXPERT

It can make sense to disable this to reduce attack surface / complexity.

(cherry picked from commit dfa499a68a1221faa8f32b82ec2859f287b7bb96)
---
 init/Kconfig | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/init/Kconfig b/init/Kconfig
index 2b1be108def6..6052c9b29c3a 100644
--- a/init/Kconfig
+++ b/init/Kconfig
@@ -1878,7 +1878,7 @@ config VM_EVENT_COUNTERS
 
 config SLUB_DEBUG
 	default y
-	bool "Enable SLUB debugging support" if EXPERT
+	bool "Enable SLUB debugging support"
 	depends on SLUB && SYSFS
 	help
 	  SLUB has extensive debug support features. Disabling these can
-- 
2.36.1

From 73b79db0930e16f7327d2399bc221f17853642ca Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Thu, 4 May 2017 18:11:31 -0400
Subject: [PATCH 015/104] stop hiding X86_16BIT behind EXPERT

(cherry picked from commit af02ecd9a342aef9c4e07642f3e6fe127f0b085b)
---
 arch/x86/Kconfig | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig
index b2c65f573353..c231c16d17e4 100644
--- a/arch/x86/Kconfig
+++ b/arch/x86/Kconfig
@@ -1204,7 +1204,7 @@ config VM86
 	default X86_LEGACY_VM86
 
 config X86_16BIT
-	bool "Enable support for 16-bit segments" if EXPERT
+	bool "Enable support for 16-bit segments"
 	default y
 	depends on MODIFY_LDT_SYSCALL
 	help
-- 
2.36.1

From f058c008360903bbb1a58291fcdc01e296def6cd Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Thu, 4 May 2017 18:11:52 -0400
Subject: [PATCH 016/104] disable X86_16BIT by default

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
(cherry picked from commit 1d8205f3b560b36b0a2e90bf5587c4ba7a2f6aa5)
---
 arch/x86/Kconfig | 1 -
 1 file changed, 1 deletion(-)

diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig
index c231c16d17e4..c5aab5c16e45 100644
--- a/arch/x86/Kconfig
+++ b/arch/x86/Kconfig
@@ -1205,7 +1205,6 @@ config VM86
 
 config X86_16BIT
 	bool "Enable support for 16-bit segments"
-	default y
 	depends on MODIFY_LDT_SYSCALL
 	help
 	  This option is required by programs like Wine to run 16-bit
-- 
2.36.1

From 293efcaf53fce184207d25d26d4436b9aec232ed Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Thu, 4 May 2017 18:15:52 -0400
Subject: [PATCH 017/104] stop hiding MODIFY_LDT_SYSCALL behind EXPERT

(cherry picked from commit 3902845faacc576a1921cb06d0f13a59ccfef55a)
---
 arch/x86/Kconfig | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig
index c5aab5c16e45..7d96b71ba0fd 100644
--- a/arch/x86/Kconfig
+++ b/arch/x86/Kconfig
@@ -2413,7 +2413,7 @@ config CMDLINE_OVERRIDE
 	  be set to 'N' under normal conditions.
 
 config MODIFY_LDT_SYSCALL
-	bool "Enable the LDT (local descriptor table)" if EXPERT
+	bool "Enable the LDT (local descriptor table)"
 	default y
 	help
 	  Linux can allow user programs to install a per-process x86
-- 
2.36.1

From 82aa98e88726661d583b2bc4dcff7566060d7c64 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Thu, 4 May 2017 18:16:16 -0400
Subject: [PATCH 018/104] disable MODIFY_LDT_SYSCALL by default

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
(cherry picked from commit a83af37f20e6d0dd36981a3ba41c44f299af6db1)
---
 arch/x86/Kconfig | 1 -
 1 file changed, 1 deletion(-)

diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig
index 7d96b71ba0fd..4eed2eeb5271 100644
--- a/arch/x86/Kconfig
+++ b/arch/x86/Kconfig
@@ -2414,7 +2414,6 @@ config CMDLINE_OVERRIDE
 
 config MODIFY_LDT_SYSCALL
 	bool "Enable the LDT (local descriptor table)"
-	default y
 	help
 	  Linux can allow user programs to install a per-process x86
 	  Local Descriptor Table (LDT) using the modify_ldt(2) system
-- 
2.36.1

From f35a9f704744bbc25c98c88f0aed6bc810d12ff5 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Mon, 29 May 2017 07:08:42 -0400
Subject: [PATCH 019/104] set LEGACY_VSYSCALL_NONE by default

(cherry picked from commit 6313b2e197e6f1eec5420bc79a0c6240253b53a6)
---
 arch/x86/Kconfig | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig
index 4eed2eeb5271..4160176a1566 100644
--- a/arch/x86/Kconfig
+++ b/arch/x86/Kconfig
@@ -2317,7 +2317,7 @@ config COMPAT_VDSO
 choice
 	prompt "vsyscall table for legacy applications"
 	depends on X86_64
-	default LEGACY_VSYSCALL_XONLY
+	default LEGACY_VSYSCALL_NONE
 	help
 	  Legacy user code that does not know how to find the vDSO expects
 	  to be able to issue three syscalls by calling fixed addresses in
-- 
2.36.1

From 7cd90c71c73181d55efb3bc3e2032422356739e4 Mon Sep 17 00:00:00 2001
From: Bernhard40 <32568352+Bernhard40@users.noreply.github.com>
Date: Fri, 6 Oct 2017 10:21:50 +0000
Subject: [PATCH 020/104] stop hiding AIO behind EXPERT

(cherry picked from commit 74466fa23c68e0f29aece23d86149bfa115b50d2)
---
 init/Kconfig | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/init/Kconfig b/init/Kconfig
index 6052c9b29c3a..81cdf10ba266 100644
--- a/init/Kconfig
+++ b/init/Kconfig
@@ -1646,7 +1646,7 @@ config SHMEM
 	  which may be appropriate on small systems without swap.
 
 config AIO
-	bool "Enable AIO support" if EXPERT
+	bool "Enable AIO support"
 	default y
 	help
 	  This option enables POSIX asynchronous I/O which may by used
-- 
2.36.1

From 35fe0733bb17fa1b888e422679273b4d44baffec Mon Sep 17 00:00:00 2001
From: Bernhard40 <32568352+Bernhard40@users.noreply.github.com>
Date: Fri, 6 Oct 2017 10:24:10 +0000
Subject: [PATCH 021/104] disable AIO by default

(cherry picked from commit 39b527afcb392dc467110207bbd57443def7fbbc)
---
 init/Kconfig | 1 -
 1 file changed, 1 deletion(-)

diff --git a/init/Kconfig b/init/Kconfig
index 81cdf10ba266..f2936fee0c9f 100644
--- a/init/Kconfig
+++ b/init/Kconfig
@@ -1647,7 +1647,6 @@ config SHMEM
 
 config AIO
 	bool "Enable AIO support"
-	default y
 	help
 	  This option enables POSIX asynchronous I/O which may by used
 	  by some high performance threaded applications. Disabling
-- 
2.36.1

From 9685df1dc13640a428531e6de692f41807ecce46 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Sun, 25 Feb 2018 02:08:49 -0500
Subject: [PATCH 022/104] remove SYSVIPC from arm64/x86_64 defconfigs

(cherry picked from commit 09d794ce78f6c6724a7f9f5e79bb74ff961d9e20)
---
 arch/arm64/configs/defconfig      | 1 -
 arch/x86/configs/x86_64_defconfig | 1 -
 2 files changed, 2 deletions(-)

diff --git a/arch/arm64/configs/defconfig b/arch/arm64/configs/defconfig
index f30af6e1fe40..acd60e56188a 100644
--- a/arch/arm64/configs/defconfig
+++ b/arch/arm64/configs/defconfig
@@ -1,4 +1,3 @@
-CONFIG_SYSVIPC=y
 CONFIG_POSIX_MQUEUE=y
 CONFIG_AUDIT=y
 CONFIG_NO_HZ_IDLE=y
diff --git a/arch/x86/configs/x86_64_defconfig b/arch/x86/configs/x86_64_defconfig
index 69784505a7a8..f00081475136 100644
--- a/arch/x86/configs/x86_64_defconfig
+++ b/arch/x86/configs/x86_64_defconfig
@@ -1,5 +1,4 @@
 CONFIG_WERROR=y
-CONFIG_SYSVIPC=y
 CONFIG_POSIX_MQUEUE=y
 CONFIG_AUDIT=y
 CONFIG_NO_HZ=y
-- 
2.36.1

From 273819a4f2c13f9fa270050e3f0de596f68a6591 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Sat, 27 May 2017 07:28:10 -0400
Subject: [PATCH 023/104] disable DEVPORT by default

(cherry picked from commit 7f2cfde9e24f5d75e832995c202ffe01d868e1ce)
---
 drivers/char/Kconfig | 1 -
 1 file changed, 1 deletion(-)

diff --git a/drivers/char/Kconfig b/drivers/char/Kconfig
index 55f48375e3fe..d83f351c8913 100644
--- a/drivers/char/Kconfig
+++ b/drivers/char/Kconfig
@@ -347,7 +347,6 @@ config NVRAM
 config DEVPORT
 	bool "/dev/port character device"
 	depends on ISA || PCI
-	default y
 	help
 	  Say Y here if you want to support the /dev/port device. The /dev/port
 	  device is similar to /dev/mem, but for I/O ports.
-- 
2.36.1

From dc04fa2a2e945094ea80b6fd7f19166ee7bc93ee Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Sat, 27 May 2017 07:29:45 -0400
Subject: [PATCH 024/104] disable PROC_VMCORE by default

(cherry picked from commit c07709118776461704737560a31de9795e1268c8)
---
 fs/proc/Kconfig | 1 -
 1 file changed, 1 deletion(-)

diff --git a/fs/proc/Kconfig b/fs/proc/Kconfig
index c930001056f9..6a0a51b3f593 100644
--- a/fs/proc/Kconfig
+++ b/fs/proc/Kconfig
@@ -41,7 +41,6 @@ config PROC_KCORE
 config PROC_VMCORE
 	bool "/proc/vmcore support"
 	depends on PROC_FS && CRASH_DUMP
-	default y
 	help
 	  Exports the dump image of crashed kernel in ELF format.
 
-- 
2.36.1

From bf2cf9c5f12a215b0806712e64b5c905c3dc59e4 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Sun, 28 May 2017 03:03:46 -0400
Subject: [PATCH 025/104] disable NFS_DEBUG by default

(cherry picked from commit d09dba358fe9b5a0b938bf2c0fc9819e14656c6f)
---
 fs/nfs/Kconfig | 1 -
 1 file changed, 1 deletion(-)

diff --git a/fs/nfs/Kconfig b/fs/nfs/Kconfig
index 14a72224b657..080a8027c6b1 100644
--- a/fs/nfs/Kconfig
+++ b/fs/nfs/Kconfig
@@ -195,7 +195,6 @@ config NFS_DEBUG
 	bool
 	depends on NFS_FS && SUNRPC_DEBUG
 	select CRC32
-	default y
 
 config NFS_DISABLE_UDP_SUPPORT
        bool "NFS: Disable NFS UDP protocol support"
-- 
2.36.1

From 5c765fcd80741dcfdd8a7ebaf4fab2fcf49390f1 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Mon, 29 May 2017 12:11:11 -0400
Subject: [PATCH 026/104] enable DEBUG_WX by default

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
(cherry picked from commit bd1a9eeff0115439d1b825aff883ed7f571d753e)
---
 mm/Kconfig.debug | 1 +
 1 file changed, 1 insertion(+)

diff --git a/mm/Kconfig.debug b/mm/Kconfig.debug
index 5bd5bb097252..c9ed59dd4d02 100644
--- a/mm/Kconfig.debug
+++ b/mm/Kconfig.debug
@@ -130,6 +130,7 @@ config DEBUG_WX
 	depends on ARCH_HAS_DEBUG_WX
 	depends on MMU
 	select PTDUMP_CORE
+	default y
 	help
 	  Generate a warning if any W+X mappings are found at boot.
 
-- 
2.36.1

From 8dac2df1e3dc0fe20d8a29fc950eda4d58ba2a36 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Fri, 5 Jan 2018 13:21:16 -0500
Subject: [PATCH 027/104] disable LEGACY_PTYS by default

(cherry picked from commit 91b12f590836e92b05f60ddc55369efa1c881fa5)
---
 drivers/tty/Kconfig | 1 -
 1 file changed, 1 deletion(-)

diff --git a/drivers/tty/Kconfig b/drivers/tty/Kconfig
index cc30ff93e2e4..9fe02e763c9b 100644
--- a/drivers/tty/Kconfig
+++ b/drivers/tty/Kconfig
@@ -121,7 +121,6 @@ config UNIX98_PTYS
 
 config LEGACY_PTYS
 	bool "Legacy (BSD) PTY support"
-	default y
 	help
 	  A pseudo terminal (PTY) is a software device consisting of two
 	  halves: a master and a slave. The slave device behaves identical to
-- 
2.36.1

From 6ed74a453d2af6f7020e80f0043ec37f6a5cf9eb Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Fri, 5 Jan 2018 12:41:42 -0500
Subject: [PATCH 028/104] disable DEVMEM by default

(cherry picked from commit 7a757f8667d7ce645b85c6e6012712083ab94495)
---
 drivers/char/Kconfig | 1 -
 1 file changed, 1 deletion(-)

diff --git a/drivers/char/Kconfig b/drivers/char/Kconfig
index d83f351c8913..b4fafbc0fefd 100644
--- a/drivers/char/Kconfig
+++ b/drivers/char/Kconfig
@@ -314,7 +314,6 @@ config NSC_GPIO
 
 config DEVMEM
 	bool "/dev/mem virtual device support"
-	default y
 	help
 	  Say Y here if you want to support the /dev/mem device.
 	  The /dev/mem device is used to access areas of physical
-- 
2.36.1

From d45dd090d79bf65d06e77d538ea9ffddcde24c20 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Fri, 5 Jan 2018 12:43:49 -0500
Subject: [PATCH 029/104] enable IO_STRICT_DEVMEM by default

(cherry picked from commit d8079c1a992ddae8091187799d3362fde7064b46)
---
 lib/Kconfig.debug | 1 +
 1 file changed, 1 insertion(+)

diff --git a/lib/Kconfig.debug b/lib/Kconfig.debug
index 23ac37cf1389..0c3acd18d6f2 100644
--- a/lib/Kconfig.debug
+++ b/lib/Kconfig.debug
@@ -1827,6 +1827,7 @@ config STRICT_DEVMEM
 config IO_STRICT_DEVMEM
 	bool "Filter I/O access to /dev/mem"
 	depends on STRICT_DEVMEM
+	default y
 	help
 	  If this option is disabled, you allow userspace (root) access to all
 	  io-memory regardless of whether a driver is actively using that
-- 
2.36.1

From d07ce3fa01261e65abf25beda38ed03944c07fc7 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Sun, 7 May 2017 18:28:33 -0400
Subject: [PATCH 030/104] disable COMPAT_BRK by default

(cherry picked from commit a5342e2741e01e7adadf9bf27f98247c2fe5046a)
---
 init/Kconfig | 1 -
 1 file changed, 1 deletion(-)

diff --git a/init/Kconfig b/init/Kconfig
index f2936fee0c9f..db78a8a721ce 100644
--- a/init/Kconfig
+++ b/init/Kconfig
@@ -1887,7 +1887,6 @@ config SLUB_DEBUG
 
 config COMPAT_BRK
 	bool "Disable heap randomization"
-	default y
 	help
 	  Randomizing heap placement makes heap exploits harder, but it
 	  also breaks ancient binaries (including anything libc5 based).
-- 
2.36.1

From dde606198937c5b9ffae4b45ee9d9e70ec65abda Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Sun, 7 May 2017 16:16:39 -0400
Subject: [PATCH 031/104] use maximum supported mmap rnd entropy by default

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
(cherry picked from commit 4fa9c2cdaeac70de033f7fc59570b51e70789ccc)
---
 arch/Kconfig | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/arch/Kconfig b/arch/Kconfig
index 31c4fdc4a4ba..916a0e5e19f1 100644
--- a/arch/Kconfig
+++ b/arch/Kconfig
@@ -948,7 +948,7 @@ config ARCH_MMAP_RND_BITS
 	int "Number of bits to use for ASLR of mmap base address" if EXPERT
 	range ARCH_MMAP_RND_BITS_MIN ARCH_MMAP_RND_BITS_MAX
 	default ARCH_MMAP_RND_BITS_DEFAULT if ARCH_MMAP_RND_BITS_DEFAULT
-	default ARCH_MMAP_RND_BITS_MIN
+	default ARCH_MMAP_RND_BITS_MAX
 	depends on HAVE_ARCH_MMAP_RND_BITS
 	help
 	  This value can be used to select the number of bits to use to
@@ -982,7 +982,7 @@ config ARCH_MMAP_RND_COMPAT_BITS
 	int "Number of bits to use for ASLR of mmap base address for compatible applications" if EXPERT
 	range ARCH_MMAP_RND_COMPAT_BITS_MIN ARCH_MMAP_RND_COMPAT_BITS_MAX
 	default ARCH_MMAP_RND_COMPAT_BITS_DEFAULT if ARCH_MMAP_RND_COMPAT_BITS_DEFAULT
-	default ARCH_MMAP_RND_COMPAT_BITS_MIN
+	default ARCH_MMAP_RND_COMPAT_BITS_MAX
 	depends on HAVE_ARCH_MMAP_RND_COMPAT_BITS
 	help
 	  This value can be used to select the number of bits to use to
-- 
2.36.1

From 0f53e71c740d00a571ba1273c96cbbb425b44d11 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Tue, 30 May 2017 10:47:23 -0400
Subject: [PATCH 032/104] enable protected_{symlinks,hardlinks} by default

(cherry picked from commit 118e3781a82b1a60af73bd12ec37262a47e58213)
---
 fs/namei.c | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/fs/namei.c b/fs/namei.c
index fd3c95ac261b..5f711e9520f7 100644
--- a/fs/namei.c
+++ b/fs/namei.c
@@ -1020,8 +1020,8 @@ static inline void put_link(struct nameidata *nd)
 		path_put(&last->link);
 }
 
-static int sysctl_protected_symlinks __read_mostly;
-static int sysctl_protected_hardlinks __read_mostly;
+static int sysctl_protected_symlinks __read_mostly = 1;
+static int sysctl_protected_hardlinks __read_mostly = 1;
 static int sysctl_protected_fifos __read_mostly;
 static int sysctl_protected_regular __read_mostly;
 
-- 
2.36.1

From bc93475fe3621cac47eadb806009d19b46a26a31 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Sun, 25 Feb 2018 02:13:48 -0500
Subject: [PATCH 033/104] enable SECURITY by default

(cherry picked from commit 2ec76be7d2f5e4085a52152d6f6b81aa4a686479)
---
 security/Kconfig | 1 +
 1 file changed, 1 insertion(+)

diff --git a/security/Kconfig b/security/Kconfig
index 6bbe8026773a..362da3e72207 100644
--- a/security/Kconfig
+++ b/security/Kconfig
@@ -23,6 +23,7 @@ config SECURITY
 	bool "Enable different security models"
 	depends on SYSFS
 	depends on MULTIUSER
+	default y
 	help
 	  This allows you to choose different security modules to be
 	  configured into your kernel.
-- 
2.36.1

From febd9259edf599db6ac194bab07a849e70f8c4ec Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Mon, 29 May 2017 06:17:59 -0400
Subject: [PATCH 034/104] enable SECURITY_YAMA by default

(cherry picked from commit d84b796e7fd4c34c8cee6b9c60e73e074f3e1bd9)
---
 security/yama/Kconfig | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/security/yama/Kconfig b/security/yama/Kconfig
index a810304123ca..b809050b25d2 100644
--- a/security/yama/Kconfig
+++ b/security/yama/Kconfig
@@ -2,7 +2,7 @@
 config SECURITY_YAMA
 	bool "Yama support"
 	depends on SECURITY
-	default n
+	default y
 	help
 	  This selects Yama, which extends DAC support with additional
 	  system-wide security settings beyond regular Linux discretionary
-- 
2.36.1

From 2f68312ad992bf50d5a8b1be01eb6d7e91a458c5 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Sun, 25 Feb 2018 02:14:02 -0500
Subject: [PATCH 035/104] enable SECURITY_NETWORK by default

(cherry picked from commit 3d742626d4b4b25b021d7d4ec44e0eca929ae604)
---
 security/Kconfig | 1 +
 1 file changed, 1 insertion(+)

diff --git a/security/Kconfig b/security/Kconfig
index 362da3e72207..9eda95bba06a 100644
--- a/security/Kconfig
+++ b/security/Kconfig
@@ -49,6 +49,7 @@ config SECURITYFS
 config SECURITY_NETWORK
 	bool "Socket and Networking Security Hooks"
 	depends on SECURITY
+	default y
 	help
 	  This enables the socket and networking security hooks.
 	  If enabled, a security module can use these hooks to
-- 
2.36.1

From cc0c2f7eaed710012f87f2ba682a28cd7339ad32 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Sun, 25 Feb 2018 02:15:24 -0500
Subject: [PATCH 036/104] enable AUDIT by default

(cherry picked from commit 94e9580ffcde82ae44ff37a1bd094e7bd1960b0d)
---
 init/Kconfig | 1 +
 1 file changed, 1 insertion(+)

diff --git a/init/Kconfig b/init/Kconfig
index db78a8a721ce..15e0da02a132 100644
--- a/init/Kconfig
+++ b/init/Kconfig
@@ -452,6 +452,7 @@ config USELIB
 config AUDIT
 	bool "Auditing support"
 	depends on NET
+	default y
 	help
 	  Enable auditing infrastructure that can be used with another
 	  kernel subsystem, such as SELinux (which requires this for
-- 
2.36.1

From b9e4f299835086028660ea9aa2a6a5f7bed87979 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Sun, 25 Feb 2018 02:16:49 -0500
Subject: [PATCH 037/104] enable SECURITY_SELINUX by default

(cherry picked from commit 6412d96fc7b9ea47778035977909979401db60b9)
---
 security/selinux/Kconfig | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/security/selinux/Kconfig b/security/selinux/Kconfig
index 9e921fc72538..76d7ed11513c 100644
--- a/security/selinux/Kconfig
+++ b/security/selinux/Kconfig
@@ -3,7 +3,7 @@ config SECURITY_SELINUX
 	bool "NSA SELinux Support"
 	depends on SECURITY_NETWORK && AUDIT && NET && INET
 	select NETWORK_SECMARK
-	default n
+	default y
 	help
 	  This selects NSA Security-Enhanced Linux (SELinux).
 	  You will also need a policy configuration and a labeled filesystem.
-- 
2.36.1

From 9e6a3b28e5425a9a692f8e36982ac25c39cd7a8a Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Sat, 6 Jan 2018 13:41:11 -0500
Subject: [PATCH 038/104] enable SYN_COOKIES by default

(cherry picked from commit d3e3aaf1046f7a7ee27aafd41c224738bb85cd3a)
---
 net/ipv4/Kconfig | 1 +
 1 file changed, 1 insertion(+)

diff --git a/net/ipv4/Kconfig b/net/ipv4/Kconfig
index 87983e70f03f..989e005bf698 100644
--- a/net/ipv4/Kconfig
+++ b/net/ipv4/Kconfig
@@ -267,6 +267,7 @@ config IP_PIMSM_V2
 
 config SYN_COOKIES
 	bool "IP: TCP syncookie support"
+	default y
 	help
 	  Normal TCP/IP networking is open to an attack known as "SYN
 	  flooding". This denial-of-service attack prevents legitimate remote
-- 
2.36.1

From 1d716ac68286230cb2fd486b77d98f283dc03b6b Mon Sep 17 00:00:00 2001
From: Levente Polyak <levente@leventepolyak.net>
Date: Thu, 19 Sep 2019 19:02:23 +0200
Subject: [PATCH 039/104] enable INIT_ON_ALLOC_DEFAULT_ON by default

(cherry picked from commit b2e118b46c5c7509ee14311fda758a011d71fb67)
---
 security/Kconfig.hardening | 1 +
 1 file changed, 1 insertion(+)

diff --git a/security/Kconfig.hardening b/security/Kconfig.hardening
index ded4d7c0d132..49b59ebbbb47 100644
--- a/security/Kconfig.hardening
+++ b/security/Kconfig.hardening
@@ -218,6 +218,7 @@ config STACKLEAK_RUNTIME_DISABLE
 
 config INIT_ON_ALLOC_DEFAULT_ON
 	bool "Enable heap memory zeroing on allocation by default"
+	default yes
 	help
 	  This has the effect of setting "init_on_alloc=1" on the kernel
 	  command line. This can be disabled with "init_on_alloc=0".
-- 
2.36.1

From fbfd0eadecf87f159f6892fb12c6ae44f04f5ab1 Mon Sep 17 00:00:00 2001
From: Levente Polyak <levente@leventepolyak.net>
Date: Thu, 19 Sep 2019 19:03:01 +0200
Subject: [PATCH 040/104] enable INIT_ON_FREE_DEFAULT_ON by default

(cherry picked from commit 71eebfb0cb465c46e021a4d3be5832b0e0c98676)
---
 security/Kconfig.hardening | 1 +
 1 file changed, 1 insertion(+)

diff --git a/security/Kconfig.hardening b/security/Kconfig.hardening
index 49b59ebbbb47..82e586293c91 100644
--- a/security/Kconfig.hardening
+++ b/security/Kconfig.hardening
@@ -231,6 +231,7 @@ config INIT_ON_ALLOC_DEFAULT_ON
 
 config INIT_ON_FREE_DEFAULT_ON
 	bool "Enable heap memory zeroing on free by default"
+	default yes
 	help
 	  This has the effect of setting "init_on_free=1" on the kernel
 	  command line. This can be disabled with "init_on_free=0".
-- 
2.36.1

From 2715470dca3abe65e2528443d2aa142ae07be2fb Mon Sep 17 00:00:00 2001
From: Levente Polyak <levente@leventepolyak.net>
Date: Sun, 27 Sep 2020 00:43:48 +0200
Subject: [PATCH 041/104] kconfig: select DEBUG_FS_ALLOW_NONE by default if
 DEBUG_FS is enabled

Signed-off-by: Levente Polyak <levente@leventepolyak.net>
(cherry picked from commit 080a09492c42bedeef8fb5a21a8b1204e6eac9a5)
---
 lib/Kconfig.debug | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/lib/Kconfig.debug b/lib/Kconfig.debug
index 0c3acd18d6f2..4fa4df798182 100644
--- a/lib/Kconfig.debug
+++ b/lib/Kconfig.debug
@@ -592,7 +592,7 @@ config DEBUG_FS
 choice
 	prompt "Debugfs default access"
 	depends on DEBUG_FS
-	default DEBUG_FS_ALLOW_ALL
+	default DEBUG_FS_ALLOW_NONE
 	help
 	  This selects the default access restrictions for debugfs.
 	  It can be overridden with kernel command line option
-- 
2.36.1

From e715c77db2186623ec9912ee77701cd586762d70 Mon Sep 17 00:00:00 2001
From: Levente Polyak <levente@leventepolyak.net>
Date: Tue, 22 Dec 2020 23:35:53 +0100
Subject: [PATCH 042/104] stop hiding SYSFS_SYSCALL behind EXPERT

(cherry picked from commit 4a49bd304b03b4ed14f4c336cc687dd76d363cc9)
---
 init/Kconfig | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/init/Kconfig b/init/Kconfig
index 15e0da02a132..ef5f61598682 100644
--- a/init/Kconfig
+++ b/init/Kconfig
@@ -1501,7 +1501,7 @@ config SGETMASK_SYSCALL
 	  If unsure, leave the default option here.
 
 config SYSFS_SYSCALL
-	bool "Sysfs syscall support" if EXPERT
+	bool "Sysfs syscall support"
 	default y
 	help
 	  sys_sysfs is an obsolete system call no longer supported in libc.
-- 
2.36.1

From d83fdf2c4b10bc6db0757fdb07cb691d5e1d0076 Mon Sep 17 00:00:00 2001
From: Levente Polyak <levente@leventepolyak.net>
Date: Tue, 22 Dec 2020 23:36:54 +0100
Subject: [PATCH 043/104] disable SYSFS_SYSCALL by default

(cherry picked from commit 6d42e6c22209b26c7d227e51dc10a2979860676a)
---
 init/Kconfig | 3 +--
 1 file changed, 1 insertion(+), 2 deletions(-)

diff --git a/init/Kconfig b/init/Kconfig
index ef5f61598682..68669520c605 100644
--- a/init/Kconfig
+++ b/init/Kconfig
@@ -1502,13 +1502,12 @@ config SGETMASK_SYSCALL
 
 config SYSFS_SYSCALL
 	bool "Sysfs syscall support"
-	default y
 	help
 	  sys_sysfs is an obsolete system call no longer supported in libc.
 	  Note that disabling this option is more secure but might break
 	  compatibility with some systems.
 
-	  If unsure say Y here.
+	  If unsure say N here.
 
 config FHANDLE
 	bool "open by fhandle syscalls" if EXPERT
-- 
2.36.1

From 1ac59a7ea4b66d574c81855d0cb2b6c9cea0fd9c Mon Sep 17 00:00:00 2001
From: Levente Polyak <levente@leventepolyak.net>
Date: Tue, 22 Dec 2020 23:40:09 +0100
Subject: [PATCH 044/104] stop hiding UID16 behind EXPERT

(cherry picked from commit f33045e3453637ab719f41d676f4461c5692dd28)
---
 init/Kconfig | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/init/Kconfig b/init/Kconfig
index 68669520c605..b57dfbfb62d3 100644
--- a/init/Kconfig
+++ b/init/Kconfig
@@ -1470,7 +1470,7 @@ menuconfig EXPERT
 	  Only use this if you really know what you are doing.
 
 config UID16
-	bool "Enable 16-bit UID system calls" if EXPERT
+	bool "Enable 16-bit UID system calls"
 	depends on HAVE_UID16 && MULTIUSER
 	default y
 	help
-- 
2.36.1

From 924eec887b836c85b9dac93b25d93bb82afc9d64 Mon Sep 17 00:00:00 2001
From: Levente Polyak <levente@leventepolyak.net>
Date: Tue, 22 Dec 2020 23:41:32 +0100
Subject: [PATCH 045/104] disable UID16 by default

(cherry picked from commit d51cd98c4aa452531f2e918f566d1d9d6a1a1e4b)
---
 init/Kconfig | 1 -
 1 file changed, 1 deletion(-)

diff --git a/init/Kconfig b/init/Kconfig
index b57dfbfb62d3..f7e2a1c273b7 100644
--- a/init/Kconfig
+++ b/init/Kconfig
@@ -1472,7 +1472,6 @@ menuconfig EXPERT
 config UID16
 	bool "Enable 16-bit UID system calls"
 	depends on HAVE_UID16 && MULTIUSER
-	default y
 	help
 	  This enables the legacy 16-bit UID syscall wrappers.
 
-- 
2.36.1

From 0832d0ab4690c2c0b01b7fa1414b04b633ef238e Mon Sep 17 00:00:00 2001
From: Levente Polyak <levente@leventepolyak.net>
Date: Wed, 25 Aug 2021 22:24:10 +0200
Subject: [PATCH 046/104] kconfig: enable RANDOMIZE_KSTACK_OFFSET_DEFAULT by
 default

(cherry picked from commit 413f105587a7d18ac92e7e90e11fdf4ed9b28fc2)
---
 arch/Kconfig | 1 +
 1 file changed, 1 insertion(+)

diff --git a/arch/Kconfig b/arch/Kconfig
index 916a0e5e19f1..9112af46d1a8 100644
--- a/arch/Kconfig
+++ b/arch/Kconfig
@@ -1190,6 +1190,7 @@ config RANDOMIZE_KSTACK_OFFSET
 config RANDOMIZE_KSTACK_OFFSET_DEFAULT
 	bool "Default state of kernel stack offset randomization"
 	depends on RANDOMIZE_KSTACK_OFFSET
+	default y
 	help
 	  Kernel stack offset randomization is controlled by kernel boot param
 	  "randomize_kstack_offset=on/off", and this config chooses the default
-- 
2.36.1

From 8b981937dc452e89076d228247853c74e45e1b26 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Sun, 7 May 2017 00:28:23 -0400
Subject: [PATCH 047/104] add __read_only for non-init related usage

(cherry picked from commit 32c069e4b7d1d01ccae1ab09d613f319fd42b66f)
---
 include/linux/cache.h | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/include/linux/cache.h b/include/linux/cache.h
index d742c57eaee5..f0222c070458 100644
--- a/include/linux/cache.h
+++ b/include/linux/cache.h
@@ -37,6 +37,8 @@
 #define __ro_after_init __section(".data..ro_after_init")
 #endif
 
+#define __read_only __ro_after_init
+
 #ifndef ____cacheline_aligned
 #define ____cacheline_aligned __attribute__((__aligned__(SMP_CACHE_BYTES)))
 #endif
-- 
2.36.1

From 0cf0b1ebaa5c1be888d01f61c9460af2a09f36bf Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Fri, 12 May 2017 03:22:00 -0400
Subject: [PATCH 048/104] mark kernel_set_to_readonly as __ro_after_init

This change was extracted from PaX where it's part of KERNEXEC.

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
(cherry picked from commit ac79434810abdfdf8f1107381305ec903e6d4d8c)
---
 arch/x86/mm/init_32.c | 5 ++---
 arch/x86/mm/init_64.c | 5 ++---
 2 files changed, 4 insertions(+), 6 deletions(-)

diff --git a/arch/x86/mm/init_32.c b/arch/x86/mm/init_32.c
index d4e2648a1dfb..a26aed4f2733 100644
--- a/arch/x86/mm/init_32.c
+++ b/arch/x86/mm/init_32.c
@@ -775,7 +775,7 @@ void __init mem_init(void)
 	test_wp_bit();
 }
 
-int kernel_set_to_readonly __read_mostly;
+int kernel_set_to_readonly __ro_after_init;
 
 static void mark_nxdata_nx(void)
 {
@@ -799,12 +799,11 @@ void mark_rodata_ro(void)
 	unsigned long start = PFN_ALIGN(_text);
 	unsigned long size = (unsigned long)__end_rodata - start;
 
+	kernel_set_to_readonly = 1;
 	set_pages_ro(virt_to_page(start), size >> PAGE_SHIFT);
 	pr_info("Write protecting kernel text and read-only data: %luk\n",
 		size >> 10);
 
-	kernel_set_to_readonly = 1;
-
 #ifdef CONFIG_CPA_DEBUG
 	pr_info("Testing CPA: Reverting %lx-%lx\n", start, start + size);
 	set_pages_rw(virt_to_page(start), size >> PAGE_SHIFT);
diff --git a/arch/x86/mm/init_64.c b/arch/x86/mm/init_64.c
index e2942335d143..fe5dcb476e0f 100644
--- a/arch/x86/mm/init_64.c
+++ b/arch/x86/mm/init_64.c
@@ -1366,7 +1366,7 @@ int __init deferred_page_init_max_threads(const struct cpumask *node_cpumask)
 }
 #endif
 
-int kernel_set_to_readonly;
+int kernel_set_to_readonly __ro_after_init;
 
 void mark_rodata_ro(void)
 {
@@ -1379,9 +1379,8 @@ void mark_rodata_ro(void)
 
 	printk(KERN_INFO "Write protecting the kernel read-only data: %luk\n",
 	       (end - start) >> 10);
-	set_memory_ro(start, (end - start) >> PAGE_SHIFT);
-
 	kernel_set_to_readonly = 1;
+	set_memory_ro(start, (end - start) >> PAGE_SHIFT);
 
 	/*
 	 * The rodata/data/bss/brk section (but not the kernel text!)
-- 
2.36.1

From 429bb61ebb9bbd051f4e7f8f33bf0518274a0e0c Mon Sep 17 00:00:00 2001
From: Levente Polyak <levente@leventepolyak.net>
Date: Sun, 13 Jan 2019 21:42:45 +0100
Subject: [PATCH 049/104] Revert "mark kernel_set_to_readonly as
 __ro_after_init"

    This commit causes CPA conflicts, cf.
    https://github.com/anthraxx/linux-hardened/issues/4.

    Signed-off-by: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>

(cherry picked from commit 20cc88410d8bbeefccafa87f151a862d192aa914)
---
 arch/x86/mm/init_32.c | 5 +++--
 arch/x86/mm/init_64.c | 5 +++--
 2 files changed, 6 insertions(+), 4 deletions(-)

diff --git a/arch/x86/mm/init_32.c b/arch/x86/mm/init_32.c
index a26aed4f2733..d4e2648a1dfb 100644
--- a/arch/x86/mm/init_32.c
+++ b/arch/x86/mm/init_32.c
@@ -775,7 +775,7 @@ void __init mem_init(void)
 	test_wp_bit();
 }
 
-int kernel_set_to_readonly __ro_after_init;
+int kernel_set_to_readonly __read_mostly;
 
 static void mark_nxdata_nx(void)
 {
@@ -799,11 +799,12 @@ void mark_rodata_ro(void)
 	unsigned long start = PFN_ALIGN(_text);
 	unsigned long size = (unsigned long)__end_rodata - start;
 
-	kernel_set_to_readonly = 1;
 	set_pages_ro(virt_to_page(start), size >> PAGE_SHIFT);
 	pr_info("Write protecting kernel text and read-only data: %luk\n",
 		size >> 10);
 
+	kernel_set_to_readonly = 1;
+
 #ifdef CONFIG_CPA_DEBUG
 	pr_info("Testing CPA: Reverting %lx-%lx\n", start, start + size);
 	set_pages_rw(virt_to_page(start), size >> PAGE_SHIFT);
diff --git a/arch/x86/mm/init_64.c b/arch/x86/mm/init_64.c
index fe5dcb476e0f..e2942335d143 100644
--- a/arch/x86/mm/init_64.c
+++ b/arch/x86/mm/init_64.c
@@ -1366,7 +1366,7 @@ int __init deferred_page_init_max_threads(const struct cpumask *node_cpumask)
 }
 #endif
 
-int kernel_set_to_readonly __ro_after_init;
+int kernel_set_to_readonly;
 
 void mark_rodata_ro(void)
 {
@@ -1379,9 +1379,10 @@ void mark_rodata_ro(void)
 
 	printk(KERN_INFO "Write protecting the kernel read-only data: %luk\n",
 	       (end - start) >> 10);
-	kernel_set_to_readonly = 1;
 	set_memory_ro(start, (end - start) >> PAGE_SHIFT);
 
+	kernel_set_to_readonly = 1;
+
 	/*
 	 * The rodata/data/bss/brk section (but not the kernel text!)
 	 * should also be not-executable.
-- 
2.36.1

From 37af19be3f21563bff3b21e5d83925cdfe38f4ed Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Sun, 14 May 2017 19:01:58 -0400
Subject: [PATCH 050/104] mark slub runtime configuration as __ro_after_init

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
(cherry picked from commit 4ffebadecf7e01912c7aeb30381fa78af17ec283)
---
 mm/slub.c | 14 +++++++-------
 1 file changed, 7 insertions(+), 7 deletions(-)

diff --git a/mm/slub.c b/mm/slub.c
index ed5c2c03a47a..27ae80da6bba 100644
--- a/mm/slub.c
+++ b/mm/slub.c
@@ -637,13 +637,13 @@ static inline void *restore_red_left(struct kmem_cache *s, void *p)
  * Debug settings:
  */
 #if defined(CONFIG_SLUB_DEBUG_ON)
-static slab_flags_t slub_debug = DEBUG_DEFAULT_FLAGS;
+static slab_flags_t slub_debug __ro_after_init = DEBUG_DEFAULT_FLAGS;
 #else
-static slab_flags_t slub_debug;
+static slab_flags_t slub_debug __ro_after_init;
 #endif
 
-static char *slub_debug_string;
-static int disable_higher_order_debug;
+static char *slub_debug_string __ro_after_init;
+static int disable_higher_order_debug __ro_after_init;
 
 /*
  * slub is about to manipulate internal object metadata.  This memory lies
@@ -3759,9 +3759,9 @@ EXPORT_SYMBOL(kmem_cache_alloc_bulk);
  * and increases the number of allocations possible without having to
  * take the list_lock.
  */
-static unsigned int slub_min_order;
-static unsigned int slub_max_order = PAGE_ALLOC_COSTLY_ORDER;
-static unsigned int slub_min_objects;
+static unsigned int slub_min_order __ro_after_init;
+static unsigned int slub_max_order __ro_after_init = PAGE_ALLOC_COSTLY_ORDER;
+static unsigned int slub_min_objects __ro_after_init;
 
 /*
  * Calculate the order of allocation given an slab object size.
-- 
2.36.1

From 923d130ce574f33d8151bf9375b64b0f4839e65c Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Wed, 3 May 2017 11:35:35 -0400
Subject: [PATCH 051/104] add __ro_after_init to slab_nomerge and slab_state

This was extracted from the PaX patch where it's part of the KERNEXEC
feature as __read_only.

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
(cherry picked from commit 4564ebba87eeead68e4516acb9cf62112a4905d3)
---
 mm/slab_common.c | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/mm/slab_common.c b/mm/slab_common.c
index 2b3206a2c3b5..3443c78e1c04 100644
--- a/mm/slab_common.c
+++ b/mm/slab_common.c
@@ -32,7 +32,7 @@
 
 #include "slab.h"
 
-enum slab_state slab_state;
+enum slab_state slab_state __ro_after_init;
 LIST_HEAD(slab_caches);
 DEFINE_MUTEX(slab_mutex);
 struct kmem_cache *kmem_cache;
@@ -55,7 +55,7 @@ static DECLARE_WORK(slab_caches_to_rcu_destroy_work,
 /*
  * Merge control. If this is set then no merging of slab caches will occur.
  */
-static bool slab_nomerge = !IS_ENABLED(CONFIG_SLAB_MERGE_DEFAULT);
+static bool slab_nomerge __ro_after_init = !IS_ENABLED(CONFIG_SLAB_MERGE_DEFAULT);
 
 static int __init setup_slab_nomerge(char *str)
 {
-- 
2.36.1

From 3ee2f508163c9f1f4dc2889c4a55b18f01e6ca20 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Sun, 28 May 2017 18:51:30 -0400
Subject: [PATCH 052/104] mark kmem_cache as __ro_after_init

(cherry picked from commit e66d120c37a2a6bf4eeb54c369bb616797f7d4cd)
---
 mm/slab_common.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/mm/slab_common.c b/mm/slab_common.c
index 3443c78e1c04..785d8daf0a9f 100644
--- a/mm/slab_common.c
+++ b/mm/slab_common.c
@@ -35,7 +35,7 @@
 enum slab_state slab_state __ro_after_init;
 LIST_HEAD(slab_caches);
 DEFINE_MUTEX(slab_mutex);
-struct kmem_cache *kmem_cache;
+struct kmem_cache *kmem_cache __ro_after_init;
 
 static LIST_HEAD(slab_caches_to_rcu_destroy);
 static void slab_caches_to_rcu_destroy_workfn(struct work_struct *work);
-- 
2.36.1

From 024965011ebb66ac701fd6345c6dca902967fa57 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Fri, 12 May 2017 00:06:16 -0400
Subject: [PATCH 053/104] mark __{supported,default_kernel}_pte_mask as
 __ro_after_init

These changes were initially extracted from PaX where it was part of
KERNEXEC as __read_only.

Before this linux-hardened commit was rebased onto v5.5, a call to
x86_configure_nx in cpu_init needed to be removed, and was not required
anyway since already set up earlier. This call was finally removed
upstream in 505b789996f64 ("x86/cpu: Unify cpu_init()").

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
Signed-off-by: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
Signed-off-by: Levente Polyak <levente@leventepolyak.net>
(cherry picked from commit 068d533648d8233290b45b3f7bd94d13f0297a42)
---
 arch/x86/mm/init_32.c | 4 ++--
 arch/x86/mm/init_64.c | 4 ++--
 2 files changed, 4 insertions(+), 4 deletions(-)

diff --git a/arch/x86/mm/init_32.c b/arch/x86/mm/init_32.c
index d4e2648a1dfb..880b8527ac46 100644
--- a/arch/x86/mm/init_32.c
+++ b/arch/x86/mm/init_32.c
@@ -529,9 +529,9 @@ static void __init pagetable_init(void)
 
 #define DEFAULT_PTE_MASK ~(_PAGE_NX | _PAGE_GLOBAL)
 /* Bits supported by the hardware: */
-pteval_t __supported_pte_mask __read_mostly = DEFAULT_PTE_MASK;
+pteval_t __supported_pte_mask __ro_after_init = DEFAULT_PTE_MASK;
 /* Bits allowed in normal kernel mappings: */
-pteval_t __default_kernel_pte_mask __read_mostly = DEFAULT_PTE_MASK;
+pteval_t __default_kernel_pte_mask __ro_after_init = DEFAULT_PTE_MASK;
 EXPORT_SYMBOL_GPL(__supported_pte_mask);
 /* Used in PAGE_KERNEL_* macros which are reasonably used out-of-tree: */
 EXPORT_SYMBOL(__default_kernel_pte_mask);
diff --git a/arch/x86/mm/init_64.c b/arch/x86/mm/init_64.c
index e2942335d143..ca26c23106c3 100644
--- a/arch/x86/mm/init_64.c
+++ b/arch/x86/mm/init_64.c
@@ -98,9 +98,9 @@ DEFINE_ENTRY(pte, pte, init)
  */
 
 /* Bits supported by the hardware: */
-pteval_t __supported_pte_mask __read_mostly = ~0;
+pteval_t __supported_pte_mask __ro_after_init = ~0;
 /* Bits allowed in normal kernel mappings: */
-pteval_t __default_kernel_pte_mask __read_mostly = ~0;
+pteval_t __default_kernel_pte_mask __ro_after_init = ~0;
 EXPORT_SYMBOL_GPL(__supported_pte_mask);
 /* Used in PAGE_KERNEL_* macros which are reasonably used out-of-tree: */
 EXPORT_SYMBOL(__default_kernel_pte_mask);
-- 
2.36.1

From 627f629bd906bde5c7e5cba42f77ace7c9bef4f6 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Tue, 4 Jul 2017 01:24:28 -0400
Subject: [PATCH 054/104] mark kobj_ns_type_register as only used for init

This allows kobj_ns_ops_tbl to be __ro_after_init.

Extracted from PaX.

(cherry picked from commit 0b31236361f8172d770557f11be57a0122561636)
---
 include/linux/kobject_ns.h | 2 +-
 lib/kobject.c              | 4 ++--
 2 files changed, 3 insertions(+), 3 deletions(-)

diff --git a/include/linux/kobject_ns.h b/include/linux/kobject_ns.h
index 2b5b64256cf4..8cdce21dce0f 100644
--- a/include/linux/kobject_ns.h
+++ b/include/linux/kobject_ns.h
@@ -45,7 +45,7 @@ struct kobj_ns_type_operations {
 	void (*drop_ns)(void *);
 };
 
-int kobj_ns_type_register(const struct kobj_ns_type_operations *ops);
+int __init kobj_ns_type_register(const struct kobj_ns_type_operations *ops);
 int kobj_ns_type_registered(enum kobj_ns_type type);
 const struct kobj_ns_type_operations *kobj_child_ns_ops(struct kobject *parent);
 const struct kobj_ns_type_operations *kobj_ns_ops(struct kobject *kobj);
diff --git a/lib/kobject.c b/lib/kobject.c
index 5f0e71ab292c..8a82b4fc5b20 100644
--- a/lib/kobject.c
+++ b/lib/kobject.c
@@ -991,9 +991,9 @@ EXPORT_SYMBOL_GPL(kset_create_and_add);
 
 
 static DEFINE_SPINLOCK(kobj_ns_type_lock);
-static const struct kobj_ns_type_operations *kobj_ns_ops_tbl[KOBJ_NS_TYPES];
+static const struct kobj_ns_type_operations *kobj_ns_ops_tbl[KOBJ_NS_TYPES] __ro_after_init;
 
-int kobj_ns_type_register(const struct kobj_ns_type_operations *ops)
+int __init kobj_ns_type_register(const struct kobj_ns_type_operations *ops)
 {
 	enum kobj_ns_type type = ops->type;
 	int error;
-- 
2.36.1

From 1e718999b84f38533bf4bf87ace353ab6c4e7f84 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Tue, 4 Jul 2017 01:32:30 -0400
Subject: [PATCH 055/104] mark open_softirq as only used for init

(cherry picked from commit a5d345e2f10bba40d0770de55dc25dcf2d607b71)
---
 include/linux/interrupt.h | 2 +-
 kernel/softirq.c          | 2 +-
 2 files changed, 2 insertions(+), 2 deletions(-)

diff --git a/include/linux/interrupt.h b/include/linux/interrupt.h
index f40754caaefa..692d7ec37d6f 100644
--- a/include/linux/interrupt.h
+++ b/include/linux/interrupt.h
@@ -607,7 +607,7 @@ struct softirq_action
 asmlinkage void do_softirq(void);
 asmlinkage void __do_softirq(void);
 
-extern void open_softirq(int nr, void (*action)(struct softirq_action *));
+extern void __init open_softirq(int nr, void (*action)(struct softirq_action *));
 extern void softirq_init(void);
 extern void __raise_softirq_irqoff(unsigned int nr);
 
diff --git a/kernel/softirq.c b/kernel/softirq.c
index fac801815554..104c092ba7e5 100644
--- a/kernel/softirq.c
+++ b/kernel/softirq.c
@@ -700,7 +700,7 @@ void __raise_softirq_irqoff(unsigned int nr)
 	or_softirq_pending(1UL << nr);
 }
 
-void open_softirq(int nr, void (*action)(struct softirq_action *))
+void __init open_softirq(int nr, void (*action)(struct softirq_action *))
 {
 	softirq_vec[nr].action = action;
 }
-- 
2.36.1

From 4bc4ff8174858297df329fd4da9207684540e754 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Tue, 4 Jul 2017 01:41:11 -0400
Subject: [PATCH 056/104] remove unused softirq_action callback parameter

Extracted from PaX.

(cherry picked from commit f4f4196100a076d22e14b92a63d591e3bdd259e2)
---
 block/blk-mq.c            |  2 +-
 include/linux/interrupt.h |  4 ++--
 kernel/rcu/tiny.c         |  2 +-
 kernel/rcu/tree.c         |  2 +-
 kernel/sched/fair.c       |  2 +-
 kernel/softirq.c          | 15 +++++++--------
 kernel/time/hrtimer.c     |  2 +-
 kernel/time/timer.c       |  2 +-
 lib/irq_poll.c            |  2 +-
 net/core/dev.c            |  4 ++--
 10 files changed, 18 insertions(+), 19 deletions(-)

diff --git a/block/blk-mq.c b/block/blk-mq.c
index 84d749511f55..d4817fbc907c 100644
--- a/block/blk-mq.c
+++ b/block/blk-mq.c
@@ -1012,7 +1012,7 @@ static void blk_complete_reqs(struct llist_head *list)
 		rq->q->mq_ops->complete(rq);
 }
 
-static __latent_entropy void blk_done_softirq(struct softirq_action *h)
+static __latent_entropy void blk_done_softirq(void)
 {
 	blk_complete_reqs(this_cpu_ptr(&blk_cpu_done));
 }
diff --git a/include/linux/interrupt.h b/include/linux/interrupt.h
index 692d7ec37d6f..f1f10d05dafa 100644
--- a/include/linux/interrupt.h
+++ b/include/linux/interrupt.h
@@ -601,13 +601,13 @@ extern const char * const softirq_to_name[NR_SOFTIRQS];
 
 struct softirq_action
 {
-	void	(*action)(struct softirq_action *);
+	void	(*action)(void);
 };
 
 asmlinkage void do_softirq(void);
 asmlinkage void __do_softirq(void);
 
-extern void __init open_softirq(int nr, void (*action)(struct softirq_action *));
+extern void __init open_softirq(int nr, void (*action)(void));
 extern void softirq_init(void);
 extern void __raise_softirq_irqoff(unsigned int nr);
 
diff --git a/kernel/rcu/tiny.c b/kernel/rcu/tiny.c
index 340b3f8b090d..e0ef77dc0564 100644
--- a/kernel/rcu/tiny.c
+++ b/kernel/rcu/tiny.c
@@ -104,7 +104,7 @@ static inline bool rcu_reclaim_tiny(struct rcu_head *head)
 }
 
 /* Invoke the RCU callbacks whose grace period has elapsed.  */
-static __latent_entropy void rcu_process_callbacks(struct softirq_action *unused)
+static __latent_entropy void rcu_process_callbacks(void)
 {
 	struct rcu_head *next, *list;
 	unsigned long flags;
diff --git a/kernel/rcu/tree.c b/kernel/rcu/tree.c
index a4b8189455d5..fc575e198e88 100644
--- a/kernel/rcu/tree.c
+++ b/kernel/rcu/tree.c
@@ -2798,7 +2798,7 @@ static __latent_entropy void rcu_core(void)
 		queue_work_on(rdp->cpu, rcu_gp_wq, &rdp->strict_work);
 }
 
-static void rcu_core_si(struct softirq_action *h)
+static void rcu_core_si(void)
 {
 	rcu_core();
 }
diff --git a/kernel/sched/fair.c b/kernel/sched/fair.c
index cc8daa3dcc8b..5b060f860935 100644
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@ -11024,7 +11024,7 @@ static int newidle_balance(struct rq *this_rq, struct rq_flags *rf)
  * run_rebalance_domains is triggered when needed from the scheduler tick.
  * Also triggered for nohz idle balancing (with nohz_balancing_kick set).
  */
-static __latent_entropy void run_rebalance_domains(struct softirq_action *h)
+static __latent_entropy void run_rebalance_domains(void)
 {
 	struct rq *this_rq = this_rq();
 	enum cpu_idle_type idle = this_rq->idle_balance ?
diff --git a/kernel/softirq.c b/kernel/softirq.c
index 104c092ba7e5..3a6702e2443e 100644
--- a/kernel/softirq.c
+++ b/kernel/softirq.c
@@ -555,7 +555,7 @@ asmlinkage __visible void __softirq_entry __do_softirq(void)
 		kstat_incr_softirqs_this_cpu(vec_nr);
 
 		trace_softirq_entry(vec_nr);
-		h->action(h);
+		h->action();
 		trace_softirq_exit(vec_nr);
 		if (unlikely(prev_count != preempt_count())) {
 			pr_err("huh, entered softirq %u %s %p with preempt_count %08x, exited with %08x?\n",
@@ -700,7 +700,7 @@ void __raise_softirq_irqoff(unsigned int nr)
 	or_softirq_pending(1UL << nr);
 }
 
-void __init open_softirq(int nr, void (*action)(struct softirq_action *))
+void __init open_softirq(int nr, void (*action)(void))
 {
 	softirq_vec[nr].action = action;
 }
@@ -760,8 +760,7 @@ static bool tasklet_clear_sched(struct tasklet_struct *t)
 	return false;
 }
 
-static void tasklet_action_common(struct softirq_action *a,
-				  struct tasklet_head *tl_head,
+static void tasklet_action_common(struct tasklet_head *tl_head,
 				  unsigned int softirq_nr)
 {
 	struct tasklet_struct *list;
@@ -800,14 +799,14 @@ static void tasklet_action_common(struct softirq_action *a,
 	}
 }
 
-static __latent_entropy void tasklet_action(struct softirq_action *a)
+static __latent_entropy void tasklet_action(void)
 {
-	tasklet_action_common(a, this_cpu_ptr(&tasklet_vec), TASKLET_SOFTIRQ);
+	tasklet_action_common(this_cpu_ptr(&tasklet_vec), TASKLET_SOFTIRQ);
 }
 
-static __latent_entropy void tasklet_hi_action(struct softirq_action *a)
+static __latent_entropy void tasklet_hi_action(void)
 {
-	tasklet_action_common(a, this_cpu_ptr(&tasklet_hi_vec), HI_SOFTIRQ);
+	tasklet_action_common(this_cpu_ptr(&tasklet_hi_vec), HI_SOFTIRQ);
 }
 
 void tasklet_setup(struct tasklet_struct *t,
diff --git a/kernel/time/hrtimer.c b/kernel/time/hrtimer.c
index 0ea8702eb516..a2303f3d10a2 100644
--- a/kernel/time/hrtimer.c
+++ b/kernel/time/hrtimer.c
@@ -1753,7 +1753,7 @@ static void __hrtimer_run_queues(struct hrtimer_cpu_base *cpu_base, ktime_t now,
 	}
 }
 
-static __latent_entropy void hrtimer_run_softirq(struct softirq_action *h)
+static __latent_entropy void hrtimer_run_softirq(void)
 {
 	struct hrtimer_cpu_base *cpu_base = this_cpu_ptr(&hrtimer_bases);
 	unsigned long flags;
diff --git a/kernel/time/timer.c b/kernel/time/timer.c
index 9dd2a39cb3b0..28966697389d 100644
--- a/kernel/time/timer.c
+++ b/kernel/time/timer.c
@@ -1743,7 +1743,7 @@ static inline void __run_timers(struct timer_base *base)
 /*
  * This function runs timers and the timer-tq in bottom half context.
  */
-static __latent_entropy void run_timer_softirq(struct softirq_action *h)
+static __latent_entropy void run_timer_softirq(void)
 {
 	struct timer_base *base = this_cpu_ptr(&timer_bases[BASE_STD]);
 
diff --git a/lib/irq_poll.c b/lib/irq_poll.c
index 2f17b488d58e..b6e7996a0058 100644
--- a/lib/irq_poll.c
+++ b/lib/irq_poll.c
@@ -75,7 +75,7 @@ void irq_poll_complete(struct irq_poll *iop)
 }
 EXPORT_SYMBOL(irq_poll_complete);
 
-static void __latent_entropy irq_poll_softirq(struct softirq_action *h)
+static void __latent_entropy irq_poll_softirq(void)
 {
 	struct list_head *list = this_cpu_ptr(&blk_cpu_iopoll);
 	int rearm = 0, budget = irq_poll_budget;
diff --git a/net/core/dev.c b/net/core/dev.c
index 0784c339cd7d..2b46e703a0a8 100644
--- a/net/core/dev.c
+++ b/net/core/dev.c
@@ -4934,7 +4934,7 @@ int netif_rx(struct sk_buff *skb)
 }
 EXPORT_SYMBOL(netif_rx);
 
-static __latent_entropy void net_tx_action(struct softirq_action *h)
+static __latent_entropy void net_tx_action(void)
 {
 	struct softnet_data *sd = this_cpu_ptr(&softnet_data);
 
@@ -6545,7 +6545,7 @@ static int napi_threaded_poll(void *data)
 	return 0;
 }
 
-static __latent_entropy void net_rx_action(struct softirq_action *h)
+static __latent_entropy void net_rx_action(void)
 {
 	struct softnet_data *sd = this_cpu_ptr(&softnet_data);
 	unsigned long time_limit = jiffies +
-- 
2.36.1

From 0b021951d37e5bbd65b96485cbd365fe44d88b8e Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Tue, 4 Jul 2017 01:42:33 -0400
Subject: [PATCH 057/104] mark softirq_vec as __ro_after_init

Note: __cacheline_aligned_in_smp conflicts with __ro_after_init on x86.

Extracted from PaX.

(cherry picked from commit 8e3eab1796da06d2fe7b30b29c79e7d453584f9d)
---
 kernel/softirq.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/kernel/softirq.c b/kernel/softirq.c
index 3a6702e2443e..6058493f461b 100644
--- a/kernel/softirq.c
+++ b/kernel/softirq.c
@@ -56,7 +56,7 @@ DEFINE_PER_CPU_ALIGNED(irq_cpustat_t, irq_stat);
 EXPORT_PER_CPU_SYMBOL(irq_stat);
 #endif
 
-static struct softirq_action softirq_vec[NR_SOFTIRQS] __cacheline_aligned_in_smp;
+static struct softirq_action softirq_vec[NR_SOFTIRQS] __ro_after_init __aligned(PAGE_SIZE);
 
 DEFINE_PER_CPU(struct task_struct *, ksoftirqd);
 
-- 
2.36.1

From 4f75f4e26db4c68a667edf47b8f84338d55b82f9 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Tue, 17 Sep 2019 18:00:54 +0200
Subject: [PATCH 058/104] mm: slab: BUG on page type confusion under
 BUG_ON_DATA_CORRUPTION

This change was extracted from PaX.

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
Signed-off-by: Levente Polyak <levente@leventepolyak.net>
Signed-off-by: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
(cherry picked from commit a8cbecc853fb788614b794e044410a68d6291484)
---
 mm/slab.h | 4 ++++
 1 file changed, 4 insertions(+)

diff --git a/mm/slab.h b/mm/slab.h
index 95eb34174c1b..dc6ab73aa5aa 100644
--- a/mm/slab.h
+++ b/mm/slab.h
@@ -639,9 +639,13 @@ static inline struct kmem_cache *virt_to_cache(const void *obj)
 	struct slab *slab;
 
 	slab = virt_to_slab(obj);
+#ifdef CONFIG_BUG_ON_DATA_CORRUPTION
+	BUG_ON(!slab);
+#else
 	if (WARN_ONCE(!slab, "%s: Object is not a Slab page!\n",
 					__func__))
 		return NULL;
+#endif
 	return slab->slab_cache;
 }
 
-- 
2.36.1

From 523b333ec43f2abb07bbcb260669285891bea3a6 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Wed, 3 May 2017 11:50:53 -0400
Subject: [PATCH 059/104] bug on kmem_cache_free with the wrong cache

At least when CONFIG_BUG_ON_DATA_CORRUPTION is enabled.

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
Signed-off-by: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
Signed-off-by: Levente Polyak <levente@leventepolyak.net>
(cherry picked from commit 76d561b9be356bdcf6043cd3682bfeea48f2434b)
---
 mm/slab.h | 11 ++++++++---
 1 file changed, 8 insertions(+), 3 deletions(-)

diff --git a/mm/slab.h b/mm/slab.h
index dc6ab73aa5aa..ec8a07ff71e6 100644
--- a/mm/slab.h
+++ b/mm/slab.h
@@ -678,10 +678,15 @@ static inline struct kmem_cache *cache_from_obj(struct kmem_cache *s, void *x)
 		return s;
 
 	cachep = virt_to_cache(x);
-	if (WARN(cachep && cachep != s,
-		  "%s: Wrong slab cache. %s but object is from %s\n",
-		  __func__, s->name, cachep->name))
+	if (cachep && cachep != s) {
+#ifdef CONFIG_BUG_ON_DATA_CORRUPTION
+		BUG();
+#else
+		WARN(1, "%s: Wrong slab cache. %s but object is from %s\n",
+			__func__, s->name, cachep->name);
 		print_tracking(cachep, x);
+#endif
+	}
 	return cachep;
 }
 #endif /* CONFIG_SLOB */
-- 
2.36.1

From 30dba9e137a844d33acd616ebc729c24fded5356 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Wed, 3 May 2017 21:54:56 -0400
Subject: [PATCH 060/104] mm: add support for verifying page sanitization

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
Signed-off-by: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
Signed-off-by: Levente Polyak <levente@leventepolyak.net>
(cherry picked from commit c6a6fde86f7eeaa292b8fd2e80970adb85ca0bbe)
---
 include/linux/highmem.h    | 7 +++++++
 mm/page_alloc.c            | 6 ++++++
 security/Kconfig.hardening | 7 +++++++
 3 files changed, 20 insertions(+)

diff --git a/include/linux/highmem.h b/include/linux/highmem.h
index 39bb9b47fa9c..f680cd4bcafe 100644
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@ -226,6 +226,13 @@ static inline void tag_clear_highpage(struct page *page)
 
 #endif
 
+static inline void verify_zero_highpage(struct page *page)
+{
+	void *kaddr = kmap_atomic(page);
+	BUG_ON(memchr_inv(kaddr, 0, PAGE_SIZE));
+	kunmap_atomic(kaddr);
+}
+
 /*
  * If we pass in a base or tail page, we can zero up to PAGE_SIZE.
  * If we pass in a head page, we can zero up to the size of the compound page.
diff --git a/mm/page_alloc.c b/mm/page_alloc.c
index 5ced6cb260ed..50b50096c3f2 100644
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@ -2396,6 +2396,12 @@ inline void post_alloc_hook(struct page *page, unsigned int order,
 	 */
 	kernel_unpoison_pages(page, 1 << order);
 
+	if (IS_ENABLED(CONFIG_PAGE_SANITIZE_VERIFY) && want_init_on_free()) {
+		int i;
+		for (i = 0; i < (1 << order); i++)
+			verify_zero_highpage(page + i);
+	}
+
 	/*
 	 * As memory initialization might be integrated into KASAN,
 	 * KASAN unpoisoning and memory initializion code must be
diff --git a/security/Kconfig.hardening b/security/Kconfig.hardening
index 82e586293c91..cf0f98bf2935 100644
--- a/security/Kconfig.hardening
+++ b/security/Kconfig.hardening
@@ -266,6 +266,13 @@ config ZERO_CALL_USED_REGS
 	  be evaluated for suitability. For example, x86_64 grows by less
 	  than 1%, and arm64 grows by about 5%.
 
+config PAGE_SANITIZE_VERIFY
+	bool "Verify sanitized pages"
+	default y
+	help
+	  When init_on_free is enabled, verify that newly allocated pages
+	  are zeroed to detect write-after-free bugs.
+
 endmenu
 
 endmenu
-- 
2.36.1

From a977485659edac8fcff35fb39afb2dc3f66ac8a7 Mon Sep 17 00:00:00 2001
From: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
Date: Fri, 20 Sep 2019 14:02:42 +0200
Subject: [PATCH 061/104] slub: Extend init_on_free to slab caches with
 constructors

This is the remaining non-upstream part of SLAB_SANITIZE, which was a
partial port, from Daniel Micay, of the feature from PaX without the
default fast mode based on passing SLAB_NO_SANITIZE in
performance-critical cases that are not particularly security sensitive.

Signed-off-by: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
[levente@leventepolyak.net: Adapt to kasan init_on_free with HW_TAGS changes]
Signed-off-by: Levente Polyak <levente@leventepolyak.net>
(cherry picked from commit 05ee5a21f92ff9395e50e740a88054c31a5154e9)
---
 mm/slab.h | 12 +++++++++---
 mm/slub.c | 18 ++++++++++++++++++
 2 files changed, 27 insertions(+), 3 deletions(-)

diff --git a/mm/slab.h b/mm/slab.h
index ec8a07ff71e6..cf491f947289 100644
--- a/mm/slab.h
+++ b/mm/slab.h
@@ -853,9 +853,15 @@ static inline bool slab_want_init_on_alloc(gfp_t flags, struct kmem_cache *c)
 static inline bool slab_want_init_on_free(struct kmem_cache *c)
 {
 	if (static_branch_maybe(CONFIG_INIT_ON_FREE_DEFAULT_ON,
-				&init_on_free))
-		return !(c->ctor ||
-			 (c->flags & (SLAB_TYPESAFE_BY_RCU | SLAB_POISON)));
+				&init_on_free)) {
+#ifndef CONFIG_SLUB
+		if (c->ctor)
+			return false;
+#endif
+		if (c->flags & (SLAB_TYPESAFE_BY_RCU | SLAB_POISON))
+			return false;
+		return true;
+	}
 	return false;
 }
 
diff --git a/mm/slub.c b/mm/slub.c
index 27ae80da6bba..abbc233ca357 100644
--- a/mm/slub.c
+++ b/mm/slub.c
@@ -1723,6 +1723,8 @@ static __always_inline bool slab_free_hook(struct kmem_cache *s,
 		rsize = (s->flags & SLAB_RED_ZONE) ? s->red_left_pad : 0;
 		memset((char *)kasan_reset_tag(x) + s->inuse, 0,
 		       s->size - s->inuse - rsize);
+		if (s->ctor)
+			s->ctor(x);
 	}
 	/* KASAN might put x into memory quarantine, delaying its reuse. */
 	return kasan_slab_free(s, x, init);
@@ -1763,6 +1765,22 @@ static inline bool slab_free_freelist_hook(struct kmem_cache *s,
 			 * accordingly if object's reuse is delayed.
 			 */
 			--(*cnt);
+
+			/* Objects that are put into quarantine by KASAN will
+			 * still undergo free_consistency_checks(), which
+			 * checks whether the freelist pointer is valid if it
+			 * is located after the object (see check_object()).
+			 * Since this is the case for slab caches with
+			 * constructors, we need to fix the freelist pointer
+			 * after init_on_free has overwritten it.
+			 *
+			 * Note that doing this for all caches (not just ctor
+			 * ones) would cause a GPF due to KASAN poisoning and
+			 * the way set_freepointer() eventually dereferences
+			 * the freepointer.
+			 */
+			if (slab_want_init_on_free(s) && s->ctor)
+				set_freepointer(s, object, NULL);
 		}
 	} while (object != old_tail);
 
-- 
2.36.1

From 3cc717f71c389b45c14363b085943cfb67d65b6a Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Thu, 4 May 2017 15:58:57 -0400
Subject: [PATCH 062/104] slub: Add support for verifying slab sanitization

This is an extension to the sanitization feature in PaX for when
sacricifing more performance for security is acceptable.

The initial version from Daniel Micay was relying on PAGE_SANITIZE. It
now relies on upstream's init_on_free.

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
Signed-off-by: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
Signed-off-by: Levente Polyak <levente@leventepolyak.net>
(cherry picked from commit 59bb3067992827fefb23d1d010263437e39cb263)
---
 mm/slub.c                  | 45 +++++++++++++++++++++++++++++++++-----
 security/Kconfig.hardening |  8 +++++++
 2 files changed, 48 insertions(+), 5 deletions(-)

diff --git a/mm/slub.c b/mm/slub.c
index abbc233ca357..bd2c2e85a134 100644
--- a/mm/slub.c
+++ b/mm/slub.c
@@ -189,6 +189,12 @@ static inline bool kmem_cache_debug(struct kmem_cache *s)
 	return kmem_cache_debug_flags(s, SLAB_DEBUG_FLAGS);
 }
 
+static inline bool has_sanitize_verify(struct kmem_cache *s)
+{
+	return IS_ENABLED(CONFIG_SLAB_SANITIZE_VERIFY) &&
+	       slab_want_init_on_free(s);
+}
+
 void *fixup_red_left(struct kmem_cache *s, void *p)
 {
 	if (kmem_cache_debug_flags(s, SLAB_RED_ZONE))
@@ -1723,7 +1729,7 @@ static __always_inline bool slab_free_hook(struct kmem_cache *s,
 		rsize = (s->flags & SLAB_RED_ZONE) ? s->red_left_pad : 0;
 		memset((char *)kasan_reset_tag(x) + s->inuse, 0,
 		       s->size - s->inuse - rsize);
-		if (s->ctor)
+		if (!IS_ENABLED(CONFIG_SLAB_SANITIZE_VERIFY) && s->ctor)
 			s->ctor(x);
 	}
 	/* KASAN might put x into memory quarantine, delaying its reuse. */
@@ -1795,7 +1801,7 @@ static void *setup_object(struct kmem_cache *s, struct slab *slab,
 {
 	setup_object_debug(s, slab, object);
 	object = kasan_init_slab_obj(s, object);
-	if (unlikely(s->ctor)) {
+	if (unlikely(s->ctor) && !has_sanitize_verify(s)) {
 		kasan_unpoison_object_data(s, object);
 		s->ctor(object);
 		kasan_poison_object_data(s, object);
@@ -3229,7 +3235,19 @@ static __always_inline void *slab_alloc_node(struct kmem_cache *s, struct list_l
 	}
 
 	maybe_wipe_obj_freeptr(s, object);
-	init = slab_want_init_on_alloc(gfpflags, s);
+
+	if (has_sanitize_verify(s) && object) {
+		/* KASAN hasn't unpoisoned the object yet (this is done in the
+		 * post-alloc hook), so let's do it temporarily.
+		 */
+		kasan_unpoison_object_data(s, object);
+		BUG_ON(memchr_inv(object, 0, s->object_size));
+		if (s->ctor)
+			s->ctor(object);
+		kasan_poison_object_data(s, object);
+	} else {
+		init = slab_want_init_on_alloc(gfpflags, s);
+	}
 
 out:
 	slab_post_alloc_hook(s, objcg, gfpflags, 1, &object, init);
@@ -3684,6 +3702,7 @@ int kmem_cache_alloc_bulk(struct kmem_cache *s, gfp_t flags, size_t size,
 	struct kmem_cache_cpu *c;
 	int i;
 	struct obj_cgroup *objcg = NULL;
+	bool init = false;
 
 	/* memcg and kmem_cache debug support */
 	s = slab_pre_alloc_hook(s, NULL, &objcg, size, flags);
@@ -3742,12 +3761,28 @@ int kmem_cache_alloc_bulk(struct kmem_cache *s, gfp_t flags, size_t size,
 	local_unlock_irq(&s->cpu_slab->lock);
 	slub_put_cpu_ptr(s->cpu_slab);
 
+	if (has_sanitize_verify(s)) {
+		int j;
+
+		for (j = 0; j < i; j++) {
+			/* KASAN hasn't unpoisoned the object yet (this is done in the
+			 * post-alloc hook), so let's do it temporarily.
+			 */
+			kasan_unpoison_object_data(s, p[j]);
+			BUG_ON(memchr_inv(p[j], 0, s->object_size));
+			if (s->ctor)
+				s->ctor(p[j]);
+			kasan_poison_object_data(s, p[j]);
+		}
+	} else {
+		init = slab_want_init_on_alloc(flags, s);
+	}
+
 	/*
 	 * memcg and kmem_cache debug support and memory initialization.
 	 * Done outside of the IRQ disabled fastpath loop.
 	 */
-	slab_post_alloc_hook(s, objcg, flags, size, p,
-				slab_want_init_on_alloc(flags, s));
+	slab_post_alloc_hook(s, objcg, flags, size, p, init);
 	return i;
 error:
 	slub_put_cpu_ptr(s->cpu_slab);
diff --git a/security/Kconfig.hardening b/security/Kconfig.hardening
index cf0f98bf2935..48924888a0f4 100644
--- a/security/Kconfig.hardening
+++ b/security/Kconfig.hardening
@@ -273,6 +273,14 @@ config PAGE_SANITIZE_VERIFY
 	  When init_on_free is enabled, verify that newly allocated pages
 	  are zeroed to detect write-after-free bugs.
 
+config SLAB_SANITIZE_VERIFY
+	bool "Verify sanitized SLAB allocations"
+	default y
+	depends on !KASAN
+	help
+	  When init_on_free is enabled, verify that newly allocated slab
+	  objects are zeroed to detect write-after-free bugs.
+
 endmenu
 
 endmenu
-- 
2.36.1

From ed0e18703ebe55fe2728530f196fc15d0d95ea0b Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Wed, 3 May 2017 16:16:58 -0400
Subject: [PATCH 063/104] slub: add multi-purpose random canaries

Place canaries at the end of kernel slab allocations, sacrificing
some performance and memory usage for security.

Canaries can detect some forms of heap corruption when allocations
are freed and as part of the HARDENED_USERCOPY feature. It provides
basic use-after-free detection for HARDENED_USERCOPY.

Canaries absorb small overflows (rendering them harmless), mitigate
non-NUL terminated C string overflows on 64-bit via a guaranteed zero
byte and provide basic double-free detection.

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
[levente@leventepolyak.net: make canaries work without SLUB_DEBUG]
[levente@leventepolyak.net: fix compatibility with KFENCE]
Signed-off-by: Levente Polyak <levente@leventepolyak.net>
(cherry picked from commit 3c69752745823144d1b6c2fc40f5a141b20e055c)
---
 include/linux/slub_def.h |   5 ++
 init/Kconfig             |  17 +++++
 mm/slab.h                |   2 +-
 mm/slub.c                | 130 +++++++++++++++++++++++++++++++--------
 4 files changed, 126 insertions(+), 28 deletions(-)

diff --git a/include/linux/slub_def.h b/include/linux/slub_def.h
index 33c5c0e3bd8d..0660dccedef8 100644
--- a/include/linux/slub_def.h
+++ b/include/linux/slub_def.h
@@ -122,6 +122,11 @@ struct kmem_cache {
 	unsigned long random;
 #endif
 
+#ifdef CONFIG_SLAB_CANARY
+	unsigned long random_active;
+	unsigned long random_inactive;
+#endif
+
 #ifdef CONFIG_NUMA
 	/*
 	 * Defragmentation by allocating from a remote node.
diff --git a/init/Kconfig b/init/Kconfig
index f7e2a1c273b7..15dbf94f3a30 100644
--- a/init/Kconfig
+++ b/init/Kconfig
@@ -1967,6 +1967,23 @@ config SLAB_FREELIST_HARDENED
 	  sanity-checking than others. This option is most effective with
 	  CONFIG_SLUB.
 
+config SLAB_CANARY
+	depends on SLUB
+	depends on !SLAB_MERGE_DEFAULT
+	bool "SLAB canaries"
+	default y
+	help
+	  Place canaries at the end of kernel slab allocations, sacrificing
+	  some performance and memory usage for security.
+
+	  Canaries can detect some forms of heap corruption when allocations
+	  are freed and as part of the HARDENED_USERCOPY feature. It provides
+	  basic use-after-free detection for HARDENED_USERCOPY.
+
+	  Canaries absorb small overflows (rendering them harmless), mitigate
+	  non-NUL terminated C string overflows on 64-bit via a guaranteed zero
+	  byte and provide basic double-free detection.
+
 config SHUFFLE_PAGE_ALLOCATOR
 	bool "Page allocator randomization"
 	default SLAB_FREELIST_RANDOM && ACPI_NUMA
diff --git a/mm/slab.h b/mm/slab.h
index cf491f947289..9f3cc0074aa3 100644
--- a/mm/slab.h
+++ b/mm/slab.h
@@ -712,7 +712,7 @@ static inline size_t slab_ksize(const struct kmem_cache *s)
 	 * back there or track user information then we can
 	 * only use the space before that information.
 	 */
-	if (s->flags & (SLAB_TYPESAFE_BY_RCU | SLAB_STORE_USER))
+	if ((s->flags & (SLAB_TYPESAFE_BY_RCU | SLAB_STORE_USER)) || IS_ENABLED(CONFIG_SLAB_CANARY))
 		return s->inuse;
 	/*
 	 * Else we can use all the padding etc for the allocation
diff --git a/mm/slub.c b/mm/slub.c
index bd2c2e85a134..07b5d66f0044 100644
--- a/mm/slub.c
+++ b/mm/slub.c
@@ -563,6 +563,55 @@ static inline bool cmpxchg_double_slab(struct kmem_cache *s, struct slab *slab,
 	return false;
 }
 
+#if defined(CONFIG_SLUB_DEBUG) || defined(CONFIG_SLAB_CANARY)
+/*
+ * See comment in calculate_sizes().
+ */
+static inline bool freeptr_outside_object(struct kmem_cache *s)
+{
+	return s->offset >= s->inuse;
+}
+
+/*
+ * Return offset of the end of info block which is inuse + free pointer if
+ * not overlapping with object.
+ */
+static inline unsigned int get_info_end(struct kmem_cache *s)
+{
+	if (freeptr_outside_object(s))
+		return s->inuse + sizeof(void *);
+	else
+		return s->inuse;
+}
+#endif
+
+#ifdef CONFIG_SLAB_CANARY
+static inline unsigned long *get_canary(struct kmem_cache *s, void *object)
+{
+	return object + get_info_end(s);
+}
+
+static inline unsigned long get_canary_value(const void *canary, unsigned long value)
+{
+	return (value ^ (unsigned long)canary) & CANARY_MASK;
+}
+
+static inline void set_canary(struct kmem_cache *s, void *object, unsigned long value)
+{
+	unsigned long *canary = get_canary(s, object);
+	*canary = get_canary_value(canary, value);
+}
+
+static inline void check_canary(struct kmem_cache *s, void *object, unsigned long value)
+{
+	unsigned long *canary = get_canary(s, object);
+	BUG_ON(*canary != get_canary_value(canary, value));
+}
+#else
+#define set_canary(s, object, value)
+#define check_canary(s, object, value)
+#endif
+
 #ifdef CONFIG_SLUB_DEBUG
 static unsigned long object_map[BITS_TO_LONGS(MAX_OBJS_PER_PAGE)];
 static DEFINE_RAW_SPINLOCK(object_map_lock);
@@ -700,26 +749,6 @@ static void print_section(char *level, char *text, u8 *addr,
 	metadata_access_disable();
 }
 
-/*
- * See comment in calculate_sizes().
- */
-static inline bool freeptr_outside_object(struct kmem_cache *s)
-{
-	return s->offset >= s->inuse;
-}
-
-/*
- * Return offset of the end of info block which is inuse + free pointer if
- * not overlapping with object.
- */
-static inline unsigned int get_info_end(struct kmem_cache *s)
-{
-	if (freeptr_outside_object(s))
-		return s->inuse + sizeof(void *);
-	else
-		return s->inuse;
-}
-
 static struct track *get_track(struct kmem_cache *s, void *object,
 	enum track_item alloc)
 {
@@ -727,6 +756,9 @@ static struct track *get_track(struct kmem_cache *s, void *object,
 
 	p = object + get_info_end(s);
 
+	if (IS_ENABLED(CONFIG_SLAB_CANARY))
+		p = (void *)p + sizeof(void *);
+
 	return kasan_reset_tag(p + alloc);
 }
 
@@ -859,6 +891,9 @@ static void print_trailer(struct kmem_cache *s, struct slab *slab, u8 *p)
 
 	off = get_info_end(s);
 
+	if (IS_ENABLED(CONFIG_SLAB_CANARY))
+		off += sizeof(void *);
+
 	if (s->flags & SLAB_STORE_USER)
 		off += 2 * sizeof(struct track);
 
@@ -994,8 +1029,9 @@ static int check_bytes_and_report(struct kmem_cache *s, struct slab *slab,
  * 	Meta data starts here.
  *
  * 	A. Free pointer (if we cannot overwrite object on free)
- * 	B. Tracking data for SLAB_STORE_USER
- *	C. Padding to reach required alignment boundary or at minimum
+ * 	B. Canary for SLAB_CANARY
+ * 	C. Tracking data for SLAB_STORE_USER
+ *	D. Padding to reach required alignment boundary or at minimum
  * 		one word if debugging is on to be able to detect writes
  * 		before the word boundary.
  *
@@ -1013,6 +1049,9 @@ static int check_pad_bytes(struct kmem_cache *s, struct slab *slab, u8 *p)
 {
 	unsigned long off = get_info_end(s);	/* The end of info */
 
+	if (IS_ENABLED(CONFIG_SLAB_CANARY))
+		off += sizeof(void *);
+
 	if (s->flags & SLAB_STORE_USER)
 		/* We also have user information there */
 		off += 2 * sizeof(struct track);
@@ -1699,8 +1738,16 @@ static __always_inline void kfree_hook(void *x)
 }
 
 static __always_inline bool slab_free_hook(struct kmem_cache *s,
-						void *x, bool init)
+						void *x, bool init, bool canary)
 {
+	/*
+	 * Postpone setting the inactive canary until the metadata
+	 * has potentially been cleared at the end of this function.
+	 */
+	if (canary) {
+		check_canary(s, x, s->random_active);
+	}
+
 	kmemleak_free_recursive(x, s->flags);
 
 	debug_check_no_locks_freed(x, s->object_size);
@@ -1732,6 +1779,11 @@ static __always_inline bool slab_free_hook(struct kmem_cache *s,
 		if (!IS_ENABLED(CONFIG_SLAB_SANITIZE_VERIFY) && s->ctor)
 			s->ctor(x);
 	}
+
+	if (canary) {
+		set_canary(s, x, s->random_inactive);
+	}
+
 	/* KASAN might put x into memory quarantine, delaying its reuse. */
 	return kasan_slab_free(s, x, init);
 }
@@ -1746,7 +1798,7 @@ static inline bool slab_free_freelist_hook(struct kmem_cache *s,
 	void *old_tail = *tail ? *tail : *head;
 
 	if (is_kfence_address(next)) {
-		slab_free_hook(s, next, false);
+		slab_free_hook(s, next, false, false);
 		return true;
 	}
 
@@ -1759,7 +1811,7 @@ static inline bool slab_free_freelist_hook(struct kmem_cache *s,
 		next = get_freepointer(s, object);
 
 		/* If object's reuse doesn't have to be delayed */
-		if (!slab_free_hook(s, object, slab_want_init_on_free(s))) {
+		if (!slab_free_hook(s, object, slab_want_init_on_free(s), true)) {
 			/* Move object to the new freelist */
 			set_freepointer(s, object, *head);
 			*head = object;
@@ -1800,6 +1852,7 @@ static void *setup_object(struct kmem_cache *s, struct slab *slab,
 				void *object)
 {
 	setup_object_debug(s, slab, object);
+	set_canary(s, object, s->random_inactive);
 	object = kasan_init_slab_obj(s, object);
 	if (unlikely(s->ctor) && !has_sanitize_verify(s)) {
 		kasan_unpoison_object_data(s, object);
@@ -3249,6 +3302,11 @@ static __always_inline void *slab_alloc_node(struct kmem_cache *s, struct list_l
 		init = slab_want_init_on_alloc(gfpflags, s);
 	}
 
+	if (object) {
+		check_canary(s, object, s->random_inactive);
+		set_canary(s, object, s->random_active);
+	}
+
 out:
 	slab_post_alloc_hook(s, objcg, gfpflags, 1, &object, init);
 
@@ -3635,7 +3693,7 @@ int build_detached_freelist(struct kmem_cache *s, size_t size,
 	}
 
 	if (is_kfence_address(object)) {
-		slab_free_hook(df->s, object, false);
+		slab_free_hook(df->s, object, false, false);
 		__kfence_free(object);
 		p[size] = NULL; /* mark object processed */
 		return size;
@@ -3700,7 +3758,7 @@ int kmem_cache_alloc_bulk(struct kmem_cache *s, gfp_t flags, size_t size,
 			  void **p)
 {
 	struct kmem_cache_cpu *c;
-	int i;
+	int i, k;
 	struct obj_cgroup *objcg = NULL;
 	bool init = false;
 
@@ -3778,6 +3836,13 @@ int kmem_cache_alloc_bulk(struct kmem_cache *s, gfp_t flags, size_t size,
 		init = slab_want_init_on_alloc(flags, s);
 	}
 
+	for (k = 0; k < i; k++) {
+		if (!is_kfence_address(p[k])) {
+			check_canary(s, p[k], s->random_inactive);
+			set_canary(s, p[k], s->random_active);
+		}
+	}
+
 	/*
 	 * memcg and kmem_cache debug support and memory initialization.
 	 * Done outside of the IRQ disabled fastpath loop.
@@ -3996,6 +4061,7 @@ static void early_kmem_cache_node_alloc(int node)
 	init_object(kmem_cache_node, n, SLUB_RED_ACTIVE);
 	init_tracking(kmem_cache_node, n);
 #endif
+	set_canary(kmem_cache_node, n, kmem_cache_node->random_active);
 	n = kasan_slab_alloc(kmem_cache_node, n, GFP_KERNEL, false);
 	slab->freelist = get_freepointer(kmem_cache_node, n);
 	slab->inuse = 1;
@@ -4160,6 +4226,9 @@ static int calculate_sizes(struct kmem_cache *s)
 		s->offset = ALIGN_DOWN(s->object_size / 2, sizeof(void *));
 	}
 
+	if (IS_ENABLED(CONFIG_SLAB_CANARY))
+		size += sizeof(void *);
+
 #ifdef CONFIG_SLUB_DEBUG
 	if (flags & SLAB_STORE_USER)
 		/*
@@ -4230,6 +4299,10 @@ static int kmem_cache_open(struct kmem_cache *s, slab_flags_t flags)
 #ifdef CONFIG_SLAB_FREELIST_HARDENED
 	s->random = get_random_long();
 #endif
+#ifdef CONFIG_SLAB_CANARY
+	s->random_active = get_random_long();
+	s->random_inactive = get_random_long();
+#endif
 
 	if (!calculate_sizes(s))
 		goto error;
@@ -4559,6 +4632,9 @@ void __check_heap_object(const void *ptr, unsigned long n,
 		offset -= s->red_left_pad;
 	}
 
+	if (!is_kfence)
+		check_canary(s, (void *)ptr - offset, s->random_active);
+
 	/* Allow address range falling entirely within usercopy region. */
 	if (offset >= s->useroffset &&
 	    offset - s->useroffset <= s->usersize &&
-- 
2.36.1

From 3a4e5a866827f6ca0cbad14e7985d57525b56cec Mon Sep 17 00:00:00 2001
From: Ben Hutchings <ben@decadent.org.uk>
Date: Mon, 11 Jan 2016 15:23:55 +0000
Subject: [PATCH 064/104] security,perf: Allow further restriction of
 perf_event_open

When kernel.perf_event_open is set to 3 (or greater), disallow all
access to performance events by users without CAP_SYS_ADMIN or
CAP_PERFMON.
Add a Kconfig symbol CONFIG_SECURITY_PERF_EVENTS_RESTRICT that
makes this value the default.

This is based on a similar feature in grsecurity
(CONFIG_GRKERNSEC_PERF_HARDEN).  This version doesn't include making
the variable read-only.  It also allows enabling further restriction
at run-time regardless of whether the default is changed.

As part of the v5.5 linux-hardened rebase, this commit was adapted to
work with the new perf_event LSM hooks, introduced in da97e18458fb42
("perf_event: Add support for LSM and SELinux checks").

As part of the v5.8 linux-hardened rebase, this commit was adapted to
work with the new CAP_PERFMON capability.

Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
[levente@leventepolyak.net: Adapt to work with the new perf_event LSM hooks]
Signed-off-by: Levente Polyak <levente@leventepolyak.net>
[thibaut.sautereau@ssi.gouv.fr: Adapt to work with the new CAP_PERFMON capability]
Signed-off-by: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
Signed-off-by: Levente Polyak <levente@leventepolyak.net>
(cherry picked from commit 6e975f6f25f9327b7d96967457ff388ed15b3246)
---
 Documentation/admin-guide/sysctl/kernel.rst | 2 ++
 include/linux/perf_event.h                  | 8 ++++++++
 kernel/events/core.c                        | 7 ++++++-
 security/Kconfig                            | 9 +++++++++
 tools/perf/Documentation/security.txt       | 1 +
 tools/perf/util/evsel.c                     | 1 +
 6 files changed, 27 insertions(+), 1 deletion(-)

diff --git a/Documentation/admin-guide/sysctl/kernel.rst b/Documentation/admin-guide/sysctl/kernel.rst
index e9c18dabc552..19aa8fb16533 100644
--- a/Documentation/admin-guide/sysctl/kernel.rst
+++ b/Documentation/admin-guide/sysctl/kernel.rst
@@ -838,6 +838,8 @@ with respect to CAP_PERFMON use cases.
 >=1  Disallow CPU event access by users without ``CAP_PERFMON``.
 
 >=2  Disallow kernel profiling by users without ``CAP_PERFMON``.
+
+>=3  Disallow use of any event by users without ``CAP_PERFMON``.
 ===  ==================================================================
 
 
diff --git a/include/linux/perf_event.h b/include/linux/perf_event.h
index af97dd427501..27197a8e5c80 100644
--- a/include/linux/perf_event.h
+++ b/include/linux/perf_event.h
@@ -1348,6 +1348,14 @@ static inline int perf_is_paranoid(void)
 	return sysctl_perf_event_paranoid > -1;
 }
 
+static inline int perf_allow_open(struct perf_event_attr *attr)
+{
+	if (sysctl_perf_event_paranoid > 2 && !perfmon_capable())
+		return -EACCES;
+
+	return security_perf_event_open(attr, PERF_SECURITY_OPEN);
+}
+
 static inline int perf_allow_kernel(struct perf_event_attr *attr)
 {
 	if (sysctl_perf_event_paranoid > 1 && !perfmon_capable())
diff --git a/kernel/events/core.c b/kernel/events/core.c
index 950b25c3f210..693e6f359837 100644
--- a/kernel/events/core.c
+++ b/kernel/events/core.c
@@ -414,8 +414,13 @@ static struct kmem_cache *perf_event_cache;
  *   0 - disallow raw tracepoint access for unpriv
  *   1 - disallow cpu events for unpriv
  *   2 - disallow kernel profiling for unpriv
+ *   3 - disallow all unpriv perf event use
  */
+#ifdef CONFIG_SECURITY_PERF_EVENTS_RESTRICT
+int sysctl_perf_event_paranoid __read_mostly = 3;
+#else
 int sysctl_perf_event_paranoid __read_mostly = 2;
+#endif
 
 /* Minimum for 512 kiB + 1 user control page */
 int sysctl_perf_event_mlock __read_mostly = 512 + (PAGE_SIZE / 1024); /* 'free' kiB per user */
@@ -12034,7 +12039,7 @@ SYSCALL_DEFINE5(perf_event_open,
 		return -EINVAL;
 
 	/* Do we allow access to perf_event_open(2) ? */
-	err = security_perf_event_open(&attr, PERF_SECURITY_OPEN);
+	err = perf_allow_open(&attr);
 	if (err)
 		return err;
 
diff --git a/security/Kconfig b/security/Kconfig
index 9eda95bba06a..c2a58216f029 100644
--- a/security/Kconfig
+++ b/security/Kconfig
@@ -19,6 +19,15 @@ config SECURITY_DMESG_RESTRICT
 
 	  If you are unsure how to answer this question, answer N.
 
+config SECURITY_PERF_EVENTS_RESTRICT
+	bool "Restrict unprivileged use of performance events"
+	depends on PERF_EVENTS
+	help
+	  If you say Y here, the kernel.perf_event_paranoid sysctl
+	  will be set to 3 by default, and no unprivileged use of the
+	  perf_event_open syscall will be permitted unless it is
+	  changed.
+
 config SECURITY
 	bool "Enable different security models"
 	depends on SYSFS
diff --git a/tools/perf/Documentation/security.txt b/tools/perf/Documentation/security.txt
index 4fe3b8b1958f..a7d88cc23a70 100644
--- a/tools/perf/Documentation/security.txt
+++ b/tools/perf/Documentation/security.txt
@@ -148,6 +148,7 @@ Perf tool provides a message similar to the one below:
    >= 0: Disallow raw and ftrace function tracepoint access
    >= 1: Disallow CPU event access
    >= 2: Disallow kernel profiling
+   >= 3: Disallow use of any event
    To make the adjusted perf_event_paranoid setting permanent preserve it
    in /etc/sysctl.conf (e.g. kernel.perf_event_paranoid = <setting>)
 
diff --git a/tools/perf/util/evsel.c b/tools/perf/util/evsel.c
index deb428ee5e50..b345f42545bc 100644
--- a/tools/perf/util/evsel.c
+++ b/tools/perf/util/evsel.c
@@ -2898,6 +2898,7 @@ int evsel__open_strerror(struct evsel *evsel, struct target *target,
 		 ">= 0: Disallow raw and ftrace function tracepoint access\n"
 		 ">= 1: Disallow CPU event access\n"
 		 ">= 2: Disallow kernel profiling\n"
+		 ">= 3: Disallow use of any event\n"
 		 "To make the adjusted perf_event_paranoid setting permanent preserve it\n"
 		 "in /etc/sysctl.conf (e.g. kernel.perf_event_paranoid = <setting>)",
 		 perf_event_paranoid());
-- 
2.36.1

From 599b0dd2953fb2d154a29f372f9ecd10d47b790d Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Thu, 4 May 2017 14:45:59 -0400
Subject: [PATCH 065/104] enable SECURITY_PERF_EVENTS_RESTRICT by default

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
(cherry picked from commit 22801d4b7d2d226086bec8647078aa236fd05bca)
---
 security/Kconfig | 1 +
 1 file changed, 1 insertion(+)

diff --git a/security/Kconfig b/security/Kconfig
index c2a58216f029..eddea71f67e4 100644
--- a/security/Kconfig
+++ b/security/Kconfig
@@ -22,6 +22,7 @@ config SECURITY_DMESG_RESTRICT
 config SECURITY_PERF_EVENTS_RESTRICT
 	bool "Restrict unprivileged use of performance events"
 	depends on PERF_EVENTS
+	default y
 	help
 	  If you say Y here, the kernel.perf_event_paranoid sysctl
 	  will be set to 3 by default, and no unprivileged use of the
-- 
2.36.1

From 84f9c470a3b0fc3dd11aef1bdf01530629ec0d92 Mon Sep 17 00:00:00 2001
From: Serge Hallyn <serge.hallyn@canonical.com>
Date: Fri, 31 May 2013 19:12:12 +0100
Subject: [PATCH 066/104] userns: add sysctl to disallow unprivileged
 CLONE_NEWUSER by default

Signed-off-by: Serge Hallyn <serge.hallyn@ubuntu.com>
[bwh: Remove unneeded binary sysctl bits]
Signed-off-by: Daniel Micay <danielmicay@gmail.com>
[thibaut.sautereau@ssi.gouv.fr: Adapt to sysctl code refactoring]
Signed-off-by: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
Signed-off-by: Levente Polyak <levente@leventepolyak.net>
(cherry picked from commit d3ccd8b19b05cc944964c5bcb0ade49213e139b5)
---
 include/linux/user_namespace.h |  4 ++++
 kernel/fork.c                  | 11 +++++++++++
 kernel/sysctl.c                | 12 ++++++++++++
 kernel/user_namespace.c        |  3 +++
 4 files changed, 30 insertions(+)

diff --git a/include/linux/user_namespace.h b/include/linux/user_namespace.h
index 33a4240e6a6f..82213f9c4c17 100644
--- a/include/linux/user_namespace.h
+++ b/include/linux/user_namespace.h
@@ -139,6 +139,8 @@ static inline void set_rlimit_ucount_max(struct user_namespace *ns,
 
 #ifdef CONFIG_USER_NS
 
+extern int unprivileged_userns_clone;
+
 static inline struct user_namespace *get_user_ns(struct user_namespace *ns)
 {
 	if (ns)
@@ -172,6 +174,8 @@ extern bool current_in_userns(const struct user_namespace *target_ns);
 struct ns_common *ns_get_owner(struct ns_common *ns);
 #else
 
+#define unprivileged_userns_clone 0
+
 static inline struct user_namespace *get_user_ns(struct user_namespace *ns)
 {
 	return &init_user_ns;
diff --git a/kernel/fork.c b/kernel/fork.c
index 0d8abfb9e0f4..edfa5185a88f 100644
--- a/kernel/fork.c
+++ b/kernel/fork.c
@@ -82,6 +82,7 @@
 #include <linux/perf_event.h>
 #include <linux/posix-timers.h>
 #include <linux/user-return-notifier.h>
+#include <linux/user_namespace.h>
 #include <linux/oom.h>
 #include <linux/khugepaged.h>
 #include <linux/signalfd.h>
@@ -1992,6 +1993,10 @@ static __latent_entropy struct task_struct *copy_process(
 	if ((clone_flags & (CLONE_NEWUSER|CLONE_FS)) == (CLONE_NEWUSER|CLONE_FS))
 		return ERR_PTR(-EINVAL);
 
+	if ((clone_flags & CLONE_NEWUSER) && !unprivileged_userns_clone)
+		if (!capable(CAP_SYS_ADMIN))
+			return ERR_PTR(-EPERM);
+
 	/*
 	 * Thread groups must share signals as well, and detached threads
 	 * can only be started up within the thread group.
@@ -3128,6 +3133,12 @@ int ksys_unshare(unsigned long unshare_flags)
 	if (unshare_flags & CLONE_NEWNS)
 		unshare_flags |= CLONE_FS;
 
+	if ((unshare_flags & CLONE_NEWUSER) && !unprivileged_userns_clone) {
+		err = -EPERM;
+		if (!capable(CAP_SYS_ADMIN))
+			goto bad_unshare_out;
+	}
+
 	err = check_unshare_flags(unshare_flags);
 	if (err)
 		goto bad_unshare_out;
diff --git a/kernel/sysctl.c b/kernel/sysctl.c
index 830aaf8ca08e..af4c0806bd8e 100644
--- a/kernel/sysctl.c
+++ b/kernel/sysctl.c
@@ -91,6 +91,9 @@
 #if defined(CONFIG_PROVE_LOCKING) || defined(CONFIG_LOCK_STAT)
 #include <linux/lockdep.h>
 #endif
+#ifdef CONFIG_USER_NS
+#include <linux/user_namespace.h>
+#endif
 
 #if defined(CONFIG_SYSCTL)
 
@@ -1803,6 +1806,15 @@ static struct ctl_table kern_table[] = {
 		.mode		= 0644,
 		.proc_handler	= proc_dointvec,
 	},
+#ifdef CONFIG_USER_NS
+	{
+		.procname	= "unprivileged_userns_clone",
+		.data		= &unprivileged_userns_clone,
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec,
+	},
+#endif
 #ifdef CONFIG_PROC_SYSCTL
 	{
 		.procname	= "tainted",
diff --git a/kernel/user_namespace.c b/kernel/user_namespace.c
index 5481ba44a8d6..78b9a05ce206 100644
--- a/kernel/user_namespace.c
+++ b/kernel/user_namespace.c
@@ -21,6 +21,9 @@
 #include <linux/bsearch.h>
 #include <linux/sort.h>
 
+/* sysctl */
+int unprivileged_userns_clone;
+
 static struct kmem_cache *user_ns_cachep __read_mostly;
 static DEFINE_MUTEX(userns_state_mutex);
 
-- 
2.36.1

From 3b6e74b86db1c4c80483d6460a1322ddc584aaec Mon Sep 17 00:00:00 2001
From: Levente Polyak <levente@leventepolyak.net>
Date: Wed, 31 Jul 2019 20:50:48 +0100
Subject: [PATCH 067/104] userns: add kconfig to set default for unprivileged
 CLONE_NEWUSER

When disabled, unprivileged users will not be able to create
new namespaces. Allowing users to create their own namespaces
has been part of several recent local privilege escalation
exploits, so if you need user namespaces but are
paranoid^Wsecurity-conscious you want to disable this.

By default unprivileged user namespaces are disabled.

Co-authored-by: Jan Alexander Steffens (heftig) <jan.steffens@gmail.com>
Signed-off-by: Jan Alexander Steffens (heftig) <jan.steffens@gmail.com>
Co-authored-by: Levente Polyak <levente@leventepolyak.net>
Signed-off-by: Levente Polyak <levente@leventepolyak.net>
(cherry picked from commit 1c963c8e1d5d0cace4ca6ca77bc53ba40a7f3a7f)
---
 init/Kconfig            | 16 ++++++++++++++++
 kernel/user_namespace.c |  4 ++++
 2 files changed, 20 insertions(+)

diff --git a/init/Kconfig b/init/Kconfig
index 15dbf94f3a30..1f59b26a39eb 100644
--- a/init/Kconfig
+++ b/init/Kconfig
@@ -1241,6 +1241,22 @@ config USER_NS
 
 	  If unsure, say N.
 
+config USER_NS_UNPRIVILEGED
+	bool "Allow unprivileged users to create namespaces"
+	depends on USER_NS
+	default n
+	help
+	  When disabled, unprivileged users will not be able to create
+	  new namespaces. Allowing users to create their own namespaces
+	  has been part of several recent local privilege escalation
+	  exploits, so if you need user namespaces but are
+	  paranoid^Wsecurity-conscious you want to disable this.
+
+	  This setting can be overridden at runtime via the
+	  kernel.unprivileged_userns_clone sysctl.
+
+	  If unsure, say N.
+
 config PID_NS
 	bool "PID Namespaces"
 	default y
diff --git a/kernel/user_namespace.c b/kernel/user_namespace.c
index 78b9a05ce206..423ab2563ad7 100644
--- a/kernel/user_namespace.c
+++ b/kernel/user_namespace.c
@@ -22,7 +22,11 @@
 #include <linux/sort.h>
 
 /* sysctl */
+#ifdef CONFIG_USER_NS_UNPRIVILEGED
+int unprivileged_userns_clone = 1;
+#else
 int unprivileged_userns_clone;
+#endif
 
 static struct kmem_cache *user_ns_cachep __read_mostly;
 static DEFINE_MUTEX(userns_state_mutex);
-- 
2.36.1

From 4dabe94c0138d52379d0e7a9964fe3d4686a145f Mon Sep 17 00:00:00 2001
From: Emese Revfy <re.emese@gmail.com>
Date: Tue, 31 May 2016 01:34:02 +0200
Subject: [PATCH 068/104] Add the extra_latent_entropy kernel parameter

When extra_latent_entropy is passed on the kernel command line,
entropy will be extracted from up to the first 4GB of RAM while the
runtime memory allocator is being initialized.

Based on work created by the PaX Team.

Signed-off-by: Emese Revfy <re.emese@gmail.com>
Signed-off-by: Daniel Micay <danielmicay@gmail.com>
Signed-off-by: Levente Polyak <levente@leventepolyak.net>
(cherry picked from commit 9937a46474a93561cc92137ffecfb22bf3ee62a3)
---
 .../admin-guide/kernel-parameters.txt         |  5 ++++
 mm/page_alloc.c                               | 24 +++++++++++++++++++
 scripts/gcc-plugins/Kconfig                   |  5 ++++
 3 files changed, 34 insertions(+)

diff --git a/Documentation/admin-guide/kernel-parameters.txt b/Documentation/admin-guide/kernel-parameters.txt
index 3f1cc5e317ed..7dfb382ab13d 100644
--- a/Documentation/admin-guide/kernel-parameters.txt
+++ b/Documentation/admin-guide/kernel-parameters.txt
@@ -3946,6 +3946,11 @@
 			the specified number of seconds.  This is to be used if
 			your oopses keep scrolling off the screen.
 
+	extra_latent_entropy
+			Enable a very simple form of latent entropy extraction
+			from the first 4GB of memory as the bootmem allocator
+			passes the memory pages to the buddy allocator.
+
 	pcbit=		[HW,ISDN]
 
 	pcd.		[PARIDE]
diff --git a/mm/page_alloc.c b/mm/page_alloc.c
index 50b50096c3f2..3e4368ca2a68 100644
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@ -158,6 +158,15 @@ struct pcpu_drain {
 static DEFINE_MUTEX(pcpu_drain_mutex);
 static DEFINE_PER_CPU(struct pcpu_drain, pcpu_drain);
 
+bool __meminitdata extra_latent_entropy;
+
+static int __init setup_extra_latent_entropy(char *str)
+{
+	extra_latent_entropy = true;
+	return 0;
+}
+early_param("extra_latent_entropy", setup_extra_latent_entropy);
+
 #ifdef CONFIG_GCC_PLUGIN_LATENT_ENTROPY
 volatile unsigned long latent_entropy __latent_entropy;
 EXPORT_SYMBOL(latent_entropy);
@@ -1648,6 +1657,21 @@ void __free_pages_core(struct page *page, unsigned int order)
 	__ClearPageReserved(p);
 	set_page_count(p, 0);
 
+	if (extra_latent_entropy && !PageHighMem(page) && page_to_pfn(page) < 0x100000) {
+		unsigned long hash = 0;
+		size_t index, end = PAGE_SIZE * nr_pages / sizeof hash;
+		const unsigned long *data = lowmem_page_address(page);
+
+		for (index = 0; index < end; index++)
+			hash ^= hash + data[index];
+#ifdef CONFIG_GCC_PLUGIN_LATENT_ENTROPY
+		latent_entropy ^= hash;
+		add_device_randomness((const void *)&latent_entropy, sizeof(latent_entropy));
+#else
+		add_device_randomness((const void *)&hash, sizeof(hash));
+#endif
+	}
+
 	atomic_long_add(nr_pages, &page_zone(page)->managed_pages);
 
 	/*
diff --git a/scripts/gcc-plugins/Kconfig b/scripts/gcc-plugins/Kconfig
index 51d81c3f03d6..521bfe279abd 100644
--- a/scripts/gcc-plugins/Kconfig
+++ b/scripts/gcc-plugins/Kconfig
@@ -39,6 +39,11 @@ config GCC_PLUGIN_LATENT_ENTROPY
 	  is some slowdown of the boot process (about 0.5%) and fork and
 	  irq processing.
 
+	  When extra_latent_entropy is passed on the kernel command line,
+	  entropy will be extracted from up to the first 4GB of RAM while the
+	  runtime memory allocator is being initialized.  This costs even more
+	  slowdown of the boot process.
+
 	  Note that entropy extracted this way is not cryptographically
 	  secure!
 
-- 
2.36.1

From b59deb95405246bacdbc6bc0e2fa0829fba5048e Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Mon, 15 May 2017 23:45:34 -0400
Subject: [PATCH 069/104] ata: avoid null pointer dereference on bug

Extracted from PaX.

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
(cherry picked from commit f7962a0a4a18c7eec14dbcede109adca9c7a1e94)
---
 drivers/ata/libata-core.c | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/drivers/ata/libata-core.c b/drivers/ata/libata-core.c
index ca64837641be..a9aae34dadb0 100644
--- a/drivers/ata/libata-core.c
+++ b/drivers/ata/libata-core.c
@@ -4617,7 +4617,7 @@ void ata_qc_free(struct ata_queued_cmd *qc)
 	struct ata_port *ap;
 	unsigned int tag;
 
-	WARN_ON_ONCE(qc == NULL); /* ata_qc_from_tag _might_ return NULL */
+	BUG_ON(qc == NULL); /* ata_qc_from_tag _might_ return NULL */
 	ap = qc->ap;
 
 	qc->flags = 0;
@@ -4634,7 +4634,7 @@ void __ata_qc_complete(struct ata_queued_cmd *qc)
 	struct ata_port *ap;
 	struct ata_link *link;
 
-	WARN_ON_ONCE(qc == NULL); /* ata_qc_from_tag _might_ return NULL */
+	BUG_ON(qc == NULL); /* ata_qc_from_tag _might_ return NULL */
 	WARN_ON_ONCE(!(qc->flags & ATA_QCFLAG_ACTIVE));
 	ap = qc->ap;
 	link = qc->dev->link;
-- 
2.36.1

From 0af66245a77df8dfb1c626708285fcaf06f4022f Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Mon, 15 May 2017 23:51:12 -0400
Subject: [PATCH 070/104] sanity check for negative length in nla_memcpy

Extracted from PaX.

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
(cherry picked from commit 256d66c4a9280c80ddaeaee92754413b99a9bef7)
---
 lib/nlattr.c | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/lib/nlattr.c b/lib/nlattr.c
index 86029ad5ead4..232d4604bb92 100644
--- a/lib/nlattr.c
+++ b/lib/nlattr.c
@@ -790,6 +790,8 @@ int nla_memcpy(void *dest, const struct nlattr *src, int count)
 {
 	int minlen = min_t(int, count, nla_len(src));
 
+	BUG_ON(minlen < 0);
+
 	memcpy(dest, nla_data(src), minlen);
 	if (count > minlen)
 		memset(dest + minlen, 0, count - minlen);
-- 
2.36.1

From 0cb67cd1ef8bd9aca2405f2d017a054f209cfe30 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Mon, 15 May 2017 23:59:18 -0400
Subject: [PATCH 071/104] add page destructor sanity check

Taken from the public PaX patches.

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
[thibaut.sautereau@ssi.gouv.fr: Restore get_compound_page_dtor()]
Signed-off-by: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
Reviewd-by: Levente Polyak <levente@leventepolyak.net>
(cherry picked from commit 7f38e7fc77816e904901f1a579404105a61daf63)
---
 include/linux/mm.h |  9 +++++++--
 mm/swap.c          | 12 +++++++++++-
 2 files changed, 18 insertions(+), 3 deletions(-)

diff --git a/include/linux/mm.h b/include/linux/mm.h
index b0183450e484..a750f3591b11 100644
--- a/include/linux/mm.h
+++ b/include/linux/mm.h
@@ -892,10 +892,15 @@ static inline void set_compound_page_dtor(struct page *page,
 	page[1].compound_dtor = compound_dtor;
 }
 
-static inline void destroy_compound_page(struct page *page)
+static inline compound_page_dtor *get_compound_page_dtor(struct page *page)
 {
 	VM_BUG_ON_PAGE(page[1].compound_dtor >= NR_COMPOUND_DTORS, page);
-	compound_page_dtors[page[1].compound_dtor](page);
+	return compound_page_dtors[page[1].compound_dtor];
+}
+
+static inline void destroy_compound_page(struct page *page)
+{
+	(*get_compound_page_dtor(page))(page);
 }
 
 static inline int head_compound_pincount(struct page *head)
diff --git a/mm/swap.c b/mm/swap.c
index 7e320ec08c6a..28fc20c01079 100644
--- a/mm/swap.c
+++ b/mm/swap.c
@@ -108,6 +108,8 @@ static void __put_single_page(struct page *page)
 
 static void __put_compound_page(struct page *page)
 {
+	compound_page_dtor *dtor;
+
 	/*
 	 * __page_cache_release() is supposed to be called for thp, not for
 	 * hugetlb. This is because hugetlb page does never have PageLRU set
@@ -116,7 +118,15 @@ static void __put_compound_page(struct page *page)
 	 */
 	if (!PageHuge(page))
 		__page_cache_release(page);
-	destroy_compound_page(page);
+	dtor = get_compound_page_dtor(page);
+	if (!PageHuge(page))
+		BUG_ON(dtor != free_compound_page
+#ifdef CONFIG_TRANSPARENT_HUGEPAGE
+			&& dtor != free_transhuge_page
+#endif
+		);
+
+	(*dtor)(page);
 }
 
 void __put_page(struct page *page)
-- 
2.36.1

From 55e8c12b571ecc4b12a041783ef4b72fdc45d201 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Tue, 16 May 2017 00:59:48 -0400
Subject: [PATCH 072/104] PaX shadow cr4 sanity check (essentially a revert)

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
[levente@leventepolyak.net: Adapt to cpu_tlbstate moved out-of-line]
Signed-off-by: Levente Polyak <levente@leventepolyak.net>
[thibaut.sautereau@ssi.gouv.fr: Move BUG_ON from native_flush_tlb_global() to
				new __native_tlb_flush_global() helper]
Signed-off-by: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
(cherry picked from commit 23d60aa5cb74ffe8639de831023df19ee4ede797)
---
 arch/x86/include/asm/tlbflush.h | 1 +
 arch/x86/kernel/cpu/common.c    | 1 +
 arch/x86/kernel/process.c       | 1 +
 3 files changed, 3 insertions(+)

diff --git a/arch/x86/include/asm/tlbflush.h b/arch/x86/include/asm/tlbflush.h
index 98fa0a114074..6c3d26de91d6 100644
--- a/arch/x86/include/asm/tlbflush.h
+++ b/arch/x86/include/asm/tlbflush.h
@@ -263,6 +263,7 @@ extern void arch_tlbbatch_flush(struct arch_tlbflush_unmap_batch *batch);
 
 static inline void __native_tlb_flush_global(unsigned long cr4)
 {
+	BUG_ON(cr4 != __read_cr4());
 	native_write_cr4(cr4 ^ X86_CR4_PGE);
 	native_write_cr4(cr4);
 }
diff --git a/arch/x86/kernel/cpu/common.c b/arch/x86/kernel/cpu/common.c
index e342ae4db3c4..4777cdf098b5 100644
--- a/arch/x86/kernel/cpu/common.c
+++ b/arch/x86/kernel/cpu/common.c
@@ -488,6 +488,7 @@ EXPORT_SYMBOL_GPL(native_write_cr4);
 void cr4_update_irqsoff(unsigned long set, unsigned long clear)
 {
 	unsigned long newval, cr4 = this_cpu_read(cpu_tlbstate.cr4);
+	BUG_ON(cr4 != __read_cr4());
 
 	lockdep_assert_irqs_disabled();
 
diff --git a/arch/x86/kernel/process.c b/arch/x86/kernel/process.c
index b370767f5b19..d89b9cf293c4 100644
--- a/arch/x86/kernel/process.c
+++ b/arch/x86/kernel/process.c
@@ -641,6 +641,7 @@ void speculation_ctrl_update_current(void)
 static inline void cr4_toggle_bits_irqsoff(unsigned long mask)
 {
 	unsigned long newval, cr4 = this_cpu_read(cpu_tlbstate.cr4);
+	BUG_ON(cr4 != __read_cr4());
 
 	newval = cr4 ^ mask;
 	if (newval != cr4) {
-- 
2.36.1

From e5b1fa101d59de0b82d1d1f9847482bcb427b4e3 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Sun, 9 Jul 2017 17:53:23 -0400
Subject: [PATCH 073/104] add writable function pointer detection

Taken from the public PaX patches.

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
Signed-off-by: Levente Polyak <levente@leventepolyak.net>
(cherry picked from commit e9acaeb8dab7e35571d1cccc571be33853f41c83)
---
 scripts/mod/modpost.c | 28 +++++++++++++++++++++++++---
 1 file changed, 25 insertions(+), 3 deletions(-)

diff --git a/scripts/mod/modpost.c b/scripts/mod/modpost.c
index ed9d056d2108..b053aee4886f 100644
--- a/scripts/mod/modpost.c
+++ b/scripts/mod/modpost.c
@@ -33,6 +33,7 @@ static int warn_unresolved = 0;
 /* How a symbol is exported */
 static int sec_mismatch_count = 0;
 static int sec_mismatch_warn_only = true;
+static int writable_fptr_count = 0;
 /* ignore missing files */
 static int ignore_missing_files;
 /* If set to 1, only warn (instead of error) about missing ns imports */
@@ -1003,6 +1004,7 @@ enum mismatch {
 	ANY_EXIT_TO_ANY_INIT,
 	EXPORT_TO_INIT_EXIT,
 	EXTABLE_TO_NON_TEXT,
+	DATA_TO_TEXT
 };
 
 /**
@@ -1129,6 +1131,12 @@ static const struct sectioncheck sectioncheck[] = {
 	.good_tosec = {ALL_TEXT_SECTIONS , NULL},
 	.mismatch = EXTABLE_TO_NON_TEXT,
 	.handler = extable_mismatch_handler,
+},
+/* Do not reference code from writable data */
+{
+	.fromsec = { DATA_SECTIONS, NULL },
+	.bad_tosec = { ALL_TEXT_SECTIONS, NULL },
+	.mismatch = DATA_TO_TEXT
 }
 };
 
@@ -1316,10 +1324,10 @@ static Elf_Sym *find_elf_symbol(struct elf_info *elf, Elf64_Sword addr,
 			continue;
 		if (!is_valid_name(elf, sym))
 			continue;
-		if (sym->st_value == addr)
-			return sym;
 		/* Find a symbol nearby - addr are maybe negative */
 		d = sym->st_value - addr;
+		if (d == 0)
+			return sym;
 		if (d < 0)
 			d = addr - sym->st_value;
 		if (d < distance) {
@@ -1454,7 +1462,10 @@ static void report_sec_mismatch(const char *modname,
 	char *prl_from;
 	char *prl_to;
 
-	sec_mismatch_count++;
+	if (mismatch->mismatch == DATA_TO_TEXT)
+		writable_fptr_count++;
+	else
+		sec_mismatch_count++;
 
 	get_pretty_name(from_is_func, &from, &from_p);
 	get_pretty_name(to_is_func, &to, &to_p);
@@ -1576,6 +1587,14 @@ static void report_sec_mismatch(const char *modname,
 		fatal("There's a special handler for this mismatch type, "
 		      "we should never get here.");
 		break;
+	case DATA_TO_TEXT:
+#if 0
+		fprintf(stderr,
+		"The %s %s:%s references\n"
+		"the %s %s:%s%s\n",
+		from, fromsec, fromsym, to, tosec, tosym, to_p);
+#endif
+		break;
 	}
 	fprintf(stderr, "\n");
 }
@@ -2631,6 +2650,9 @@ int main(int argc, char **argv)
 		     nr_unresolved - MAX_UNRESOLVED_REPORTS);
 
 	free(buf.p);
+	if (writable_fptr_count)
+		warn("modpost: Found %d writable function pointer(s).\n",
+		     writable_fptr_count);
 
 	return error_occurred ? 1 : 0;
 }
-- 
2.36.1

From 8ceada23ffb4527b93cf515c61f8524790a5fd86 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Sun, 9 Jul 2017 17:20:29 -0400
Subject: [PATCH 074/104] support overriding early audit kernel cmdline

(cherry picked from commit 5f00196c8e58d8eeba8e376f613670ee60094cc1)
---
 kernel/audit.c | 3 +++
 1 file changed, 3 insertions(+)

diff --git a/kernel/audit.c b/kernel/audit.c
index 7690c29d4ee4..98b47f6990ac 100644
--- a/kernel/audit.c
+++ b/kernel/audit.c
@@ -1730,6 +1730,9 @@ static int __init audit_enable(char *str)
 
 	if (audit_default == AUDIT_OFF)
 		audit_initialized = AUDIT_DISABLED;
+	else if (!audit_ever_enabled)
+		audit_initialized = AUDIT_UNINITIALIZED;
+
 	if (audit_set_enabled(audit_default))
 		pr_err("audit: error setting audit state (%d)\n",
 		       audit_default);
-- 
2.36.1

From 719c71899b173614317fb26c3632b0fc8033d35b Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Sat, 26 Aug 2017 20:16:03 -0400
Subject: [PATCH 075/104] Revert "mm: revert x86_64 and arm64 ELF_ET_DYN_BASE
 base changes"

This reverts commit aab425db4279aeb83b7911693f0cccbd3644c9fd.

(cherry picked from commit 7106016e896e2fe3914ab52274801cd2f7861304)
---
 arch/arm64/include/asm/elf.h | 8 ++------
 arch/x86/include/asm/elf.h   | 4 ++--
 2 files changed, 4 insertions(+), 8 deletions(-)

diff --git a/arch/arm64/include/asm/elf.h b/arch/arm64/include/asm/elf.h
index 97932fbf973d..1dfce3fcb823 100644
--- a/arch/arm64/include/asm/elf.h
+++ b/arch/arm64/include/asm/elf.h
@@ -124,14 +124,10 @@
 
 /*
  * This is the base location for PIE (ET_DYN with INTERP) loads. On
- * 64-bit, this is above 4GB to leave the entire 32-bit address
+ * 64-bit, this is raised to 4GB to leave the entire 32-bit address
  * space open for things that want to use the area for 32-bit pointers.
  */
-#ifdef CONFIG_ARM64_FORCE_52BIT
-#define ELF_ET_DYN_BASE		(2 * TASK_SIZE_64 / 3)
-#else
-#define ELF_ET_DYN_BASE		(2 * DEFAULT_MAP_WINDOW_64 / 3)
-#endif /* CONFIG_ARM64_FORCE_52BIT */
+#define ELF_ET_DYN_BASE		0x100000000UL
 
 #ifndef __ASSEMBLY__
 
diff --git a/arch/x86/include/asm/elf.h b/arch/x86/include/asm/elf.h
index 29fea180a665..a36bac0e6dbd 100644
--- a/arch/x86/include/asm/elf.h
+++ b/arch/x86/include/asm/elf.h
@@ -247,11 +247,11 @@ extern int force_personality32;
 
 /*
  * This is the base location for PIE (ET_DYN with INTERP) loads. On
- * 64-bit, this is above 4GB to leave the entire 32-bit address
+ * 64-bit, this is raised to 4GB to leave the entire 32-bit address
  * space open for things that want to use the area for 32-bit pointers.
  */
 #define ELF_ET_DYN_BASE		(mmap_is_ia32() ? 0x000400000UL : \
-						  (DEFAULT_MAP_WINDOW / 3 * 2))
+						  0x100000000UL)
 
 /* This yields a mask that user programs can use to figure out what
    instruction set this CPU supports.  This could be done in user space,
-- 
2.36.1

From 4449ed57458ff64022e2d8ac02e3fee2980a6bcd Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Thu, 11 May 2017 16:52:00 -0400
Subject: [PATCH 076/104] x86_64: move vdso to mmap region from stack region

This removes the only executable code from the stack region and gives
the vdso the same randomized base as other mmap mappings including the
linker and other shared objects. It results in a sane amount of entropy
being provided and there's little to no advantage in separating this
from the existing executable code there.

It's sensible for userspace to reserve the initial mmap base as a region
for executable code with a random gap for other mmap allocations, along
with providing randomization within that region. However, there isn't
much the kernel can do to help due to how dynamic linkers load the
shared objects.

This was extracted from the PaX RANDMMAP feature.

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
(cherry picked from commit 23cf3c0b9daf65671e199b112247e3918f9c53b6)
---
 arch/x86/entry/vdso/vma.c    | 48 +-----------------------------------
 arch/x86/include/asm/elf.h   |  1 -
 arch/x86/kernel/sys_x86_64.c |  7 ------
 3 files changed, 1 insertion(+), 55 deletions(-)

diff --git a/arch/x86/entry/vdso/vma.c b/arch/x86/entry/vdso/vma.c
index 1000d457c332..18d38955bc20 100644
--- a/arch/x86/entry/vdso/vma.c
+++ b/arch/x86/entry/vdso/vma.c
@@ -298,55 +298,9 @@ static int map_vdso(const struct vdso_image *image, unsigned long addr)
 }
 
 #ifdef CONFIG_X86_64
-/*
- * Put the vdso above the (randomized) stack with another randomized
- * offset.  This way there is no hole in the middle of address space.
- * To save memory make sure it is still in the same PTE as the stack
- * top.  This doesn't give that many random bits.
- *
- * Note that this algorithm is imperfect: the distribution of the vdso
- * start address within a PMD is biased toward the end.
- *
- * Only used for the 64-bit and x32 vdsos.
- */
-static unsigned long vdso_addr(unsigned long start, unsigned len)
-{
-	unsigned long addr, end;
-	unsigned offset;
-
-	/*
-	 * Round up the start address.  It can start out unaligned as a result
-	 * of stack start randomization.
-	 */
-	start = PAGE_ALIGN(start);
-
-	/* Round the lowest possible end address up to a PMD boundary. */
-	end = (start + len + PMD_SIZE - 1) & PMD_MASK;
-	if (end >= TASK_SIZE_MAX)
-		end = TASK_SIZE_MAX;
-	end -= len;
-
-	if (end > start) {
-		offset = get_random_int() % (((end - start) >> PAGE_SHIFT) + 1);
-		addr = start + (offset << PAGE_SHIFT);
-	} else {
-		addr = start;
-	}
-
-	/*
-	 * Forcibly align the final address in case we have a hardware
-	 * issue that requires alignment for performance reasons.
-	 */
-	addr = align_vdso_addr(addr);
-
-	return addr;
-}
-
 static int map_vdso_randomized(const struct vdso_image *image)
 {
-	unsigned long addr = vdso_addr(current->mm->start_stack, image->size-image->sym_vvar_start);
-
-	return map_vdso(image, addr);
+	return map_vdso(image, 0);
 }
 #endif
 
diff --git a/arch/x86/include/asm/elf.h b/arch/x86/include/asm/elf.h
index a36bac0e6dbd..d97778088053 100644
--- a/arch/x86/include/asm/elf.h
+++ b/arch/x86/include/asm/elf.h
@@ -407,5 +407,4 @@ struct va_alignment {
 } ____cacheline_aligned;
 
 extern struct va_alignment va_align;
-extern unsigned long align_vdso_addr(unsigned long);
 #endif /* _ASM_X86_ELF_H */
diff --git a/arch/x86/kernel/sys_x86_64.c b/arch/x86/kernel/sys_x86_64.c
index 8cc653ffdccd..24fa72bd7c4d 100644
--- a/arch/x86/kernel/sys_x86_64.c
+++ b/arch/x86/kernel/sys_x86_64.c
@@ -52,13 +52,6 @@ static unsigned long get_align_bits(void)
 	return va_align.bits & get_align_mask();
 }
 
-unsigned long align_vdso_addr(unsigned long addr)
-{
-	unsigned long align_mask = get_align_mask();
-	addr = (addr + align_mask) & ~align_mask;
-	return addr | get_align_bits();
-}
-
 static int __init control_va_addr_alignment(char *str)
 {
 	/* guard against enabling this on other CPU families */
-- 
2.36.1

From d3cb5fbb7d6c1485052424da244b3d5cd2413c58 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Sun, 21 May 2017 20:30:44 -0400
Subject: [PATCH 077/104] x86: determine stack entropy based on mmap entropy

Stack mapping entropy is currently hard-wired to 11 bits of entropy on
32-bit and 22 bits of entropy on 64-bit. The stack itself gains an extra
8 bits of entropy from lower bit randomization within 16 byte alignment
constraints. The argument block could have all lower bits randomized but
it currently only gets the mapping randomization.

Rather than hard-wiring values this switches to using the mmap entropy
configuration like the mmap base and executable base, resulting in a
range of 8 to 16 bits on 32-bit and 28 to 32 bits on 64-bit depending on
kernel configuration and overridable via the sysctl entries.

It's worth noting that since these kernel configuration options default
to the minimum supported entropy value, the entropy on 32-bit will drop
from 11 to 8 bits for builds using the defaults. However, following the
configuration seems like the right thing to do regardless. At the very
least, changing the defaults for COMPAT (32-bit processes on 64-bit)
should be considered due to the larger address space compared to real
32-bit.

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
(cherry picked from commit afc4ba0c860fe5223a25cfe26fcda93cc6a04185)
---
 arch/x86/include/asm/elf.h | 10 +++++++---
 1 file changed, 7 insertions(+), 3 deletions(-)

diff --git a/arch/x86/include/asm/elf.h b/arch/x86/include/asm/elf.h
index d97778088053..28d86671b089 100644
--- a/arch/x86/include/asm/elf.h
+++ b/arch/x86/include/asm/elf.h
@@ -333,8 +333,8 @@ extern unsigned long get_sigframe_size(void);
 
 #ifdef CONFIG_X86_32
 
-#define __STACK_RND_MASK(is32bit) (0x7ff)
-#define STACK_RND_MASK (0x7ff)
+#define __STACK_RND_MASK(is32bit) ((1UL << mmap_rnd_bits) - 1)
+#define STACK_RND_MASK ((1UL << mmap_rnd_bits) - 1)
 
 #define ARCH_DLINFO		ARCH_DLINFO_IA32
 
@@ -343,7 +343,11 @@ extern unsigned long get_sigframe_size(void);
 #else /* CONFIG_X86_32 */
 
 /* 1GB for 64bit, 8MB for 32bit */
-#define __STACK_RND_MASK(is32bit) ((is32bit) ? 0x7ff : 0x3fffff)
+#ifdef CONFIG_COMPAT
+#define __STACK_RND_MASK(is32bit) ((is32bit) ? (1UL << mmap_rnd_compat_bits) - 1 : (1UL << mmap_rnd_bits) - 1)
+#else
+#define __STACK_RND_MASK(is32bit) ((1UL << mmap_rnd_bits) - 1)
+#endif
 #define STACK_RND_MASK __STACK_RND_MASK(mmap_is_ia32())
 
 #define ARCH_DLINFO							\
-- 
2.36.1

From d1538b9702b1c766a6ad6a3482841da328770e97 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Mon, 22 May 2017 05:06:20 -0400
Subject: [PATCH 078/104] arm64: determine stack entropy based on mmap entropy

Stack mapping entropy is currently hard-wired to 11 bits of entropy on
32-bit and 18 bits of entropy on 64-bit. The stack itself gains an extra
8 bits of entropy from lower bit randomization within 16 byte alignment
constraints. The argument block could have all lower bits randomized but
it currently only gets the mapping randomization.

Rather than hard-wiring values this switches to using the mmap entropy
configuration like the mmap base and executable base, resulting in a
range of 8 to 16 bits on 32-bit and 18 to 24 bits on 64-bit (with 4k
pages and 3 level page tables) depending on kernel configuration and
overridable via the sysctl entries.

It's worth noting that since these kernel configuration options default
to the minimum supported entropy value, the entropy on 32-bit will drop
from 11 to 8 bits for builds using the defaults. However, following the
configuration seems like the right thing to do regardless. At the very
least, changing the defaults for COMPAT (32-bit processes on 64-bit)
should be considered due to the larger address space compared to real
32-bit.

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
(cherry picked from commit a20c9bb7410d8fe5b3c4e678876d257833bf12dc)
---
 arch/arm64/include/asm/elf.h | 6 +++---
 1 file changed, 3 insertions(+), 3 deletions(-)

diff --git a/arch/arm64/include/asm/elf.h b/arch/arm64/include/asm/elf.h
index 1dfce3fcb823..40c6468c093a 100644
--- a/arch/arm64/include/asm/elf.h
+++ b/arch/arm64/include/asm/elf.h
@@ -185,10 +185,10 @@ extern int arch_setup_additional_pages(struct linux_binprm *bprm,
 /* 1GB of VA */
 #ifdef CONFIG_COMPAT
 #define STACK_RND_MASK			(test_thread_flag(TIF_32BIT) ? \
-						0x7ff >> (PAGE_SHIFT - 12) : \
-						0x3ffff >> (PAGE_SHIFT - 12))
+						((1UL << mmap_rnd_compat_bits) - 1) >> (PAGE_SHIFT - 12) : \
+						((1UL << mmap_rnd_bits) - 1) >> (PAGE_SHIFT - 12))
 #else
-#define STACK_RND_MASK			(0x3ffff >> (PAGE_SHIFT - 12))
+#define STACK_RND_MASK			(((1UL << mmap_rnd_bits) - 1) >> (PAGE_SHIFT - 12))
 #endif
 
 #ifdef __AARCH64EB__
-- 
2.36.1

From 4179de670bde54600ea8625f0fa47248b2b4d8fd Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Thu, 11 May 2017 16:02:49 -0400
Subject: [PATCH 079/104] randomize lower bits of the argument block

This was based on the PaX RANDUSTACK feature in grsecurity, where all of
the lower bits are randomized. PaX keeps 16-byte alignment.

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
[levente@leventepolyak.net: do not randomize with ADDR_NO_RANDOMIZE personality]
Signed-off-by: Levente Polyak <levente@leventepolyak.net>
(cherry picked from commit e09b66b1800d891918a5f77a00028645af3aef12)
---
 fs/exec.c | 3 +++
 1 file changed, 3 insertions(+)

diff --git a/fs/exec.c b/fs/exec.c
index 75eb6e0ee7b2..0f1f071693d2 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -65,6 +65,7 @@
 #include <linux/io_uring.h>
 #include <linux/syscall_user_dispatch.h>
 #include <linux/coredump.h>
+#include <linux/random.h>
 
 #include <linux/uaccess.h>
 #include <asm/mmu_context.h>
@@ -280,6 +281,8 @@ static int __bprm_mm_init(struct linux_binprm *bprm)
 	mm->stack_vm = mm->total_vm = 1;
 	mmap_write_unlock(mm);
 	bprm->p = vma->vm_end - sizeof(void *);
+	if (!(current->personality & ADDR_NO_RANDOMIZE) && randomize_va_space)
+		bprm->p ^= get_random_int() & ~PAGE_MASK;
 	return 0;
 err:
 	mmap_write_unlock(mm);
-- 
2.36.1

From 7f6b2e89180f50dd129e6d597c9e6a7c321f9096 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Tue, 30 May 2017 07:19:48 -0400
Subject: [PATCH 080/104] x86_64: match arm64 brk randomization entropy

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
(cherry picked from commit 90cb0de2da62b73c78a652fc3d0e541d83bc1a24)
---
 arch/x86/kernel/process.c | 7 ++++++-
 1 file changed, 6 insertions(+), 1 deletion(-)

diff --git a/arch/x86/kernel/process.c b/arch/x86/kernel/process.c
index d89b9cf293c4..9ad527d13e5d 100644
--- a/arch/x86/kernel/process.c
+++ b/arch/x86/kernel/process.c
@@ -46,6 +46,8 @@
 #include <asm/proto.h>
 #include <asm/frame.h>
 #include <asm/unwind.h>
+#include <asm/elf.h>
+#include <linux/sizes.h>
 
 #include "process.h"
 
@@ -954,7 +956,10 @@ unsigned long arch_align_stack(unsigned long sp)
 
 unsigned long arch_randomize_brk(struct mm_struct *mm)
 {
-	return randomize_page(mm->brk, 0x02000000);
+	if (mmap_is_ia32())
+		return randomize_page(mm->brk, SZ_32M);
+	else
+		return randomize_page(mm->brk, SZ_1G);
 }
 
 /*
-- 
2.36.1

From f50406b45dcb105132a06d28f7ba06fadd4f3e58 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Tue, 30 May 2017 18:03:30 -0400
Subject: [PATCH 081/104] support randomizing the lower bits of brk

This adds support for arch_randomize_brk implementations not performing
page alignment in order to randomize the lower bits of the brk heap.

This idea is taken from PaX but the approach is different. This reuses
the existing code and avoids forcing early creation of the heap mapping,
avoiding mapping it if it's not used which is the case with many modern
allocators based solely on mmap.

The malloc implementation can be relied upon to align this as needed to
the requirements it has, so using 16 byte alignment here is unnecessary.

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
(cherry picked from commit c77c7ac57a60feb4b8c36ee4e97f20c02c48048a)
---
 mm/mmap.c | 7 +++++++
 1 file changed, 7 insertions(+)

diff --git a/mm/mmap.c b/mm/mmap.c
index 313b57d55a63..df2b1320dd14 100644
--- a/mm/mmap.c
+++ b/mm/mmap.c
@@ -235,6 +235,13 @@ SYSCALL_DEFINE1(brk, unsigned long, brk)
 
 	newbrk = PAGE_ALIGN(brk);
 	oldbrk = PAGE_ALIGN(mm->brk);
+	/* properly handle unaligned min_brk as an empty heap */
+	if (min_brk & ~PAGE_MASK) {
+		if (brk == min_brk)
+			newbrk -= PAGE_SIZE;
+		if (mm->brk == min_brk)
+			oldbrk -= PAGE_SIZE;
+	}
 	if (oldbrk == newbrk) {
 		mm->brk = brk;
 		goto success;
-- 
2.36.1

From 9ee7c9089466fffbc888c6cd84496cecb3dba08e Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Thu, 1 Jun 2017 03:22:38 -0400
Subject: [PATCH 082/104] mm: randomize lower bits of brk

Per PaX, but for this alternate brk randomization approach.

As part of the v5.4 linux-hardened rebase, this commit was adapted from
the arm64 specific brk randomization to all arches that use the generic
topdown mmap layout functions, introduced in e7142bf5d231 ("arm64, mm:
make randomization selected by generic topdown mmap layout").

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
Signed-off-by: Levente Polyak <levente@leventepolyak.net>
(cherry picked from commit 496082e73ccf639a82005f3349fb1108aeaa67ab)
---
 mm/util.c | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/mm/util.c b/mm/util.c
index ac63e5ca8b21..7608cfddaa10 100644
--- a/mm/util.c
+++ b/mm/util.c
@@ -380,9 +380,9 @@ unsigned long arch_randomize_brk(struct mm_struct *mm)
 {
 	/* Is the current task 32bit ? */
 	if (!IS_ENABLED(CONFIG_64BIT) || is_compat_task())
-		return randomize_page(mm->brk, SZ_32M);
+		return mm->brk + get_random_long() % SZ_32M;
 
-	return randomize_page(mm->brk, SZ_1G);
+	return mm->brk + get_random_long() % SZ_1G;
 }
 
 unsigned long arch_mmap_rnd(void)
-- 
2.36.1

From 93b987879638a56ad525ceda7f3da666da346e73 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Thu, 1 Jun 2017 03:23:06 -0400
Subject: [PATCH 083/104] x86: randomize lower bits of brk

Per PaX, but for this alternate brk randomization approach.

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
(cherry picked from commit d564ab17af0998189c6ff9e7c24209ee25e312a6)
---
 arch/x86/kernel/process.c | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/arch/x86/kernel/process.c b/arch/x86/kernel/process.c
index 9ad527d13e5d..d4776da41dd7 100644
--- a/arch/x86/kernel/process.c
+++ b/arch/x86/kernel/process.c
@@ -957,9 +957,9 @@ unsigned long arch_align_stack(unsigned long sp)
 unsigned long arch_randomize_brk(struct mm_struct *mm)
 {
 	if (mmap_is_ia32())
-		return randomize_page(mm->brk, SZ_32M);
+		return mm->brk + get_random_long() % SZ_32M;
 	else
-		return randomize_page(mm->brk, SZ_1G);
+		return mm->brk + get_random_long() % SZ_1G;
 }
 
 /*
-- 
2.36.1

From 757a8e075f88df5d1d7c7ad810af25ca49ed4af1 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Thu, 1 Jun 2017 03:23:39 -0400
Subject: [PATCH 084/104] mm: guarantee brk gap is at least one page

Per PaX, but for this alternate brk randomization approach.

As part of the v5.4 linux-hardened rebase, this commit was adapted from
the arm64 specific brk randomization to all arches that use the generic
topdown mmap layout functions, introduced in e7142bf5d231 ("arm64, mm:
make randomization selected by generic topdown mmap layout").

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
Signed-off-by: Levente Polyak <levente@leventepolyak.net>
(cherry picked from commit 1a25661b8734a3cc517c23cbcf45f598e16affcf)
---
 mm/util.c | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/mm/util.c b/mm/util.c
index 7608cfddaa10..216e1a81d2b0 100644
--- a/mm/util.c
+++ b/mm/util.c
@@ -380,9 +380,9 @@ unsigned long arch_randomize_brk(struct mm_struct *mm)
 {
 	/* Is the current task 32bit ? */
 	if (!IS_ENABLED(CONFIG_64BIT) || is_compat_task())
-		return mm->brk + get_random_long() % SZ_32M;
+		return mm->brk + get_random_long() % SZ_32M + PAGE_SIZE;
 
-	return mm->brk + get_random_long() % SZ_1G;
+	return mm->brk + get_random_long() % SZ_1G + PAGE_SIZE;
 }
 
 unsigned long arch_mmap_rnd(void)
-- 
2.36.1

From f81763408f5682392bbbbca9a0cbda1c9fc0acce Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Thu, 1 Jun 2017 03:23:48 -0400
Subject: [PATCH 085/104] x86: guarantee brk gap is at least one page

Per PaX, but for this alternate brk randomization approach.

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
(cherry picked from commit c4b815aaa9c6a0ddd9411d7ac2bbfdb5a620a741)
---
 arch/x86/kernel/process.c | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/arch/x86/kernel/process.c b/arch/x86/kernel/process.c
index d4776da41dd7..b9bd907b94f5 100644
--- a/arch/x86/kernel/process.c
+++ b/arch/x86/kernel/process.c
@@ -957,9 +957,9 @@ unsigned long arch_align_stack(unsigned long sp)
 unsigned long arch_randomize_brk(struct mm_struct *mm)
 {
 	if (mmap_is_ia32())
-		return mm->brk + get_random_long() % SZ_32M;
+		return mm->brk + get_random_long() % SZ_32M + PAGE_SIZE;
 	else
-		return mm->brk + get_random_long() % SZ_1G;
+		return mm->brk + get_random_long() % SZ_1G + PAGE_SIZE;
 }
 
 /*
-- 
2.36.1

From 89db7edffe703ee2520c6751510abf16f136f803 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Tue, 4 Jul 2017 14:50:54 -0400
Subject: [PATCH 086/104] x86_64: bound mmap between legacy/modern bases

(cherry picked from commit 829111749be406ca785a54955ccfeb8f32d6eafb)
---
 arch/x86/kernel/sys_x86_64.c | 7 ++-----
 1 file changed, 2 insertions(+), 5 deletions(-)

diff --git a/arch/x86/kernel/sys_x86_64.c b/arch/x86/kernel/sys_x86_64.c
index 24fa72bd7c4d..77e8a88ba3b3 100644
--- a/arch/x86/kernel/sys_x86_64.c
+++ b/arch/x86/kernel/sys_x86_64.c
@@ -106,10 +106,7 @@ static void find_start_end(unsigned long addr, unsigned long flags,
 	}
 
 	*begin	= get_mmap_base(1);
-	if (in_32bit_syscall())
-		*end = task_size_32bit();
-	else
-		*end = task_size_64bit(addr > DEFAULT_MAP_WINDOW);
+	*end	= get_mmap_base(0);
 }
 
 unsigned long
@@ -186,7 +183,7 @@ arch_get_unmapped_area_topdown(struct file *filp, const unsigned long addr0,
 
 	info.flags = VM_UNMAPPED_AREA_TOPDOWN;
 	info.length = len;
-	info.low_limit = PAGE_SIZE;
+	info.low_limit = get_mmap_base(1);
 	info.high_limit = get_mmap_base(0);
 
 	/*
-- 
2.36.1

From 7b269a374433ae08a373d8ac7f8736fb3d359c8d Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Tue, 16 May 2017 18:26:10 -0400
Subject: [PATCH 087/104] restrict device timing side channels

Based on the public grsecurity patches.

Signed-off-by: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
[levente@leventepolyak.net: move sysctl from kernel into fs]
Signed-off-by: Levente Polyak <levente@leventepolyak.net>
(cherry picked from commit d06e52e2a28bcfea1dd240e81ff3c7706f2200d5)
---
 fs/inode.c                 | 13 +++++++++++++
 fs/stat.c                  | 20 +++++++++++++++-----
 include/linux/capability.h |  5 +++++
 include/linux/fs.h         | 11 +++++++++++
 include/linux/fsnotify.h   |  3 +++
 kernel/capability.c        |  6 ++++++
 6 files changed, 53 insertions(+), 5 deletions(-)

diff --git a/fs/inode.c b/fs/inode.c
index 9d9b422504d1..505a572fbedf 100644
--- a/fs/inode.c
+++ b/fs/inode.c
@@ -97,6 +97,10 @@ long get_nr_dirty_inodes(void)
 	return nr_dirty > 0 ? nr_dirty : 0;
 }
 
+/* sysctl */
+int device_sidechannel_restrict __read_mostly = 1;
+EXPORT_SYMBOL(device_sidechannel_restrict);
+
 /*
  * Handle nr_inode sysctl
  */
@@ -129,6 +133,15 @@ static struct ctl_table inodes_sysctls[] = {
 		.mode		= 0444,
 		.proc_handler	= proc_nr_inodes,
 	},
+	{
+		.procname	= "device_sidechannel_restrict",
+		.data		= &device_sidechannel_restrict,
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec_minmax_sysadmin,
+		.extra1		= SYSCTL_ZERO,
+		.extra2		= SYSCTL_ONE,
+	},
 	{ }
 };
 
diff --git a/fs/stat.c b/fs/stat.c
index 5c2c94464e8b..69202affa0ea 100644
--- a/fs/stat.c
+++ b/fs/stat.c
@@ -51,8 +51,13 @@ void generic_fillattr(struct user_namespace *mnt_userns, struct inode *inode,
 	stat->gid = i_gid_into_mnt(mnt_userns, inode);
 	stat->rdev = inode->i_rdev;
 	stat->size = i_size_read(inode);
-	stat->atime = inode->i_atime;
-	stat->mtime = inode->i_mtime;
+	if (is_sidechannel_device(inode) && !capable_noaudit(CAP_MKNOD)) {
+		stat->atime = inode->i_ctime;
+		stat->mtime = inode->i_ctime;
+	} else {
+		stat->atime = inode->i_atime;
+		stat->mtime = inode->i_mtime;
+	}
 	stat->ctime = inode->i_ctime;
 	stat->blksize = i_blocksize(inode);
 	stat->blocks = inode->i_blocks;
@@ -119,9 +124,14 @@ int vfs_getattr_nosec(const struct path *path, struct kstat *stat,
 				  STATX_ATTR_DAX);
 
 	mnt_userns = mnt_user_ns(path->mnt);
-	if (inode->i_op->getattr)
-		return inode->i_op->getattr(mnt_userns, path, stat,
-					    request_mask, query_flags);
+	if (inode->i_op->getattr) {
+		int retval = inode->i_op->getattr(mnt_userns, path, stat, request_mask, query_flags);
+		if (!retval && is_sidechannel_device(inode) && !capable_noaudit(CAP_MKNOD)) {
+			stat->atime = stat->ctime;
+			stat->mtime = stat->ctime;
+		}
+		return retval;
+	}
 
 	generic_fillattr(mnt_userns, inode, stat);
 	return 0;
diff --git a/include/linux/capability.h b/include/linux/capability.h
index 65efb74c3585..7fca4dd7f3b1 100644
--- a/include/linux/capability.h
+++ b/include/linux/capability.h
@@ -208,6 +208,7 @@ extern bool has_capability_noaudit(struct task_struct *t, int cap);
 extern bool has_ns_capability_noaudit(struct task_struct *t,
 				      struct user_namespace *ns, int cap);
 extern bool capable(int cap);
+extern bool capable_noaudit(int cap);
 extern bool ns_capable(struct user_namespace *ns, int cap);
 extern bool ns_capable_noaudit(struct user_namespace *ns, int cap);
 extern bool ns_capable_setid(struct user_namespace *ns, int cap);
@@ -234,6 +235,10 @@ static inline bool capable(int cap)
 {
 	return true;
 }
+static inline bool capable_noaudit(int cap)
+{
+	return true;
+}
 static inline bool ns_capable(struct user_namespace *ns, int cap)
 {
 	return true;
diff --git a/include/linux/fs.h b/include/linux/fs.h
index bbde95387a23..e525e7388b9f 100644
--- a/include/linux/fs.h
+++ b/include/linux/fs.h
@@ -3466,4 +3466,15 @@ extern int vfs_fadvise(struct file *file, loff_t offset, loff_t len,
 extern int generic_fadvise(struct file *file, loff_t offset, loff_t len,
 			   int advice);
 
+extern int device_sidechannel_restrict;
+
+static inline bool is_sidechannel_device(const struct inode *inode)
+{
+	umode_t mode;
+	if (!device_sidechannel_restrict)
+		return false;
+	mode = inode->i_mode;
+	return ((S_ISCHR(mode) || S_ISBLK(mode)) && (mode & (S_IROTH | S_IWOTH)));
+}
+
 #endif /* _LINUX_FS_H */
diff --git a/include/linux/fsnotify.h b/include/linux/fsnotify.h
index bb8467cd11ae..1029912679a6 100644
--- a/include/linux/fsnotify.h
+++ b/include/linux/fsnotify.h
@@ -96,6 +96,9 @@ static inline int fsnotify_file(struct file *file, __u32 mask)
 	if (file->f_mode & FMODE_NONOTIFY)
 		return 0;
 
+	if (mask & (FS_ACCESS | FS_MODIFY) && is_sidechannel_device(file_inode(file)))
+		return 0;
+
 	return fsnotify_parent(path->dentry, mask, path, FSNOTIFY_EVENT_PATH);
 }
 
diff --git a/kernel/capability.c b/kernel/capability.c
index 765194f5d678..6a6e53edef46 100644
--- a/kernel/capability.c
+++ b/kernel/capability.c
@@ -450,6 +450,12 @@ bool capable(int cap)
 	return ns_capable(&init_user_ns, cap);
 }
 EXPORT_SYMBOL(capable);
+
+bool capable_noaudit(int cap)
+{
+	return ns_capable_noaudit(&init_user_ns, cap);
+}
+EXPORT_SYMBOL(capable_noaudit);
 #endif /* CONFIG_MULTIUSER */
 
 /**
-- 
2.36.1

From 9c67c02bb94b9c9b8c0a16d34362c0dd135283a9 Mon Sep 17 00:00:00 2001
From: Levente Polyak <levente@leventepolyak.net>
Date: Sun, 6 Sep 2020 20:28:32 +0200
Subject: [PATCH 088/104] sysctl: expose proc_dointvec_minmax_sysadmin as API
 function

Orthogonal to the other sysctl proc functions expose the variant that is
checking CAP_SYS_ADMIN on write for consumption in external subsystem's
sysctl tables.

Signed-off-by: Levente Polyak <levente@leventepolyak.net>
(cherry picked from commit 9cd432afce595fe76479f10a7d88cfd8c6b2a529)
---
 include/linux/sysctl.h |  2 ++
 kernel/printk/sysctl.c |  9 ---------
 kernel/sysctl.c        | 36 ++++++++++++++++++++++++++++++++++++
 3 files changed, 38 insertions(+), 9 deletions(-)

diff --git a/include/linux/sysctl.h b/include/linux/sysctl.h
index 6353d6db69b2..0e1b83d7580a 100644
--- a/include/linux/sysctl.h
+++ b/include/linux/sysctl.h
@@ -73,6 +73,8 @@ int proc_douintvec_minmax(struct ctl_table *table, int write, void *buffer,
 		size_t *lenp, loff_t *ppos);
 int proc_dou8vec_minmax(struct ctl_table *table, int write, void *buffer,
 			size_t *lenp, loff_t *ppos);
+int proc_dointvec_minmax_sysadmin(struct ctl_table *table, int write,
+				  void *buffer, size_t *lenp, loff_t *ppos);
 int proc_dointvec_jiffies(struct ctl_table *, int, void *, size_t *, loff_t *);
 int proc_dointvec_userhz_jiffies(struct ctl_table *, int, void *, size_t *,
 		loff_t *);
diff --git a/kernel/printk/sysctl.c b/kernel/printk/sysctl.c
index c228343eeb97..c7129428ee9b 100644
--- a/kernel/printk/sysctl.c
+++ b/kernel/printk/sysctl.c
@@ -11,15 +11,6 @@
 
 static const int ten_thousand = 10000;
 
-static int proc_dointvec_minmax_sysadmin(struct ctl_table *table, int write,
-				void *buffer, size_t *lenp, loff_t *ppos)
-{
-	if (write && !capable(CAP_SYS_ADMIN))
-		return -EPERM;
-
-	return proc_dointvec_minmax(table, write, buffer, lenp, ppos);
-}
-
 static struct ctl_table printk_sysctls[] = {
 	{
 		.procname	= "printk",
diff --git a/kernel/sysctl.c b/kernel/sysctl.c
index af4c0806bd8e..fd9e1ab78c32 100644
--- a/kernel/sysctl.c
+++ b/kernel/sysctl.c
@@ -898,6 +898,35 @@ static int proc_taint(struct ctl_table *table, int write,
 	return err;
 }
 
+/**
+ * proc_dointvec_minmax_sysadmin - read a vector of integers with min/max values
+ * checking CAP_SYS_ADMIN on write
+ * @table: the sysctl table
+ * @write: %TRUE if this is a write to the sysctl file
+ * @buffer: the user buffer
+ * @lenp: the size of the user buffer
+ * @ppos: file position
+ *
+ * Reads/writes up to table->maxlen/sizeof(unsigned int) integer
+ * values from/to the user buffer, treated as an ASCII string.
+ *
+ * This routine will ensure the values are within the range specified by
+ * table->extra1 (min) and table->extra2 (max).
+ *
+ * Writing is only allowed when the current task has CAP_SYS_ADMIN.
+ *
+ * Returns 0 on success, -EPERM on permission failure or -EINVAL on write
+ * when the range check fails.
+ */
+int proc_dointvec_minmax_sysadmin(struct ctl_table *table, int write,
+				  void *buffer, size_t *lenp, loff_t *ppos)
+{
+	if (write && !capable(CAP_SYS_ADMIN))
+		return -EPERM;
+
+	return proc_dointvec_minmax(table, write, buffer, lenp, ppos);
+}
+
 /**
  * struct do_proc_dointvec_minmax_conv_param - proc_dointvec_minmax() range checking structure
  * @min: pointer to minimum allowable value
@@ -1592,6 +1621,12 @@ int proc_dou8vec_minmax(struct ctl_table *table, int write,
 	return -ENOSYS;
 }
 
+int proc_dointvec_minmax_sysadmin(struct ctl_table *table, int write,
+				  void *buffer, size_t *lenp, loff_t *ppos)
+{
+	return -ENOSYS;
+}
+
 int proc_dointvec_jiffies(struct ctl_table *table, int write,
 		    void *buffer, size_t *lenp, loff_t *ppos)
 {
@@ -2856,6 +2891,7 @@ EXPORT_SYMBOL(proc_douintvec);
 EXPORT_SYMBOL(proc_dointvec_jiffies);
 EXPORT_SYMBOL(proc_dointvec_minmax);
 EXPORT_SYMBOL_GPL(proc_douintvec_minmax);
+EXPORT_SYMBOL(proc_dointvec_minmax_sysadmin);
 EXPORT_SYMBOL(proc_dointvec_userhz_jiffies);
 EXPORT_SYMBOL(proc_dointvec_ms_jiffies);
 EXPORT_SYMBOL(proc_dostring);
-- 
2.36.1

From fb1ed7d2a6f4a0c483ec89334069f668d78a19d5 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Tue, 16 May 2017 17:51:48 -0400
Subject: [PATCH 089/104] usb: add toggle for disabling newly added USB devices

Based on the public grsecurity patches.

[thibaut.sautereau@ssi.gouv.fr: Adapt to sysctl code refactoring]
Signed-off-by: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
Signed-off-by: Levente Polyak <levente@leventepolyak.net>
(cherry picked from commit 4250b547bc602ca4ec329b26fe8374139dc4865e)
---
 drivers/usb/core/hub.c |  9 +++++++++
 include/linux/usb.h    |  3 +++
 kernel/sysctl.c        | 14 ++++++++++++++
 3 files changed, 26 insertions(+)

diff --git a/drivers/usb/core/hub.c b/drivers/usb/core/hub.c
index 1460857026e0..bfd3f3ac1ff6 100644
--- a/drivers/usb/core/hub.c
+++ b/drivers/usb/core/hub.c
@@ -5187,6 +5187,9 @@ static int descriptors_changed(struct usb_device *udev,
 	return changed;
 }
 
+/* sysctl */
+int deny_new_usb __read_mostly = 0;
+
 static void hub_port_connect(struct usb_hub *hub, int port1, u16 portstatus,
 		u16 portchange)
 {
@@ -5248,6 +5251,12 @@ static void hub_port_connect(struct usb_hub *hub, int port1, u16 portstatus,
 			goto done;
 		return;
 	}
+
+	if (deny_new_usb) {
+		dev_err(&port_dev->dev, "denied insert of USB device on port %d\n", port1);
+		goto done;
+	}
+
 	if (hub_is_superspeed(hub->hdev))
 		unit_load = 150;
 	else
diff --git a/include/linux/usb.h b/include/linux/usb.h
index 200b7b79acb5..2f9fe848aa68 100644
--- a/include/linux/usb.h
+++ b/include/linux/usb.h
@@ -2030,6 +2030,9 @@ extern void usb_led_activity(enum usb_led_event ev);
 static inline void usb_led_activity(enum usb_led_event ev) {}
 #endif
 
+/* sysctl */
+extern int deny_new_usb;
+
 #endif  /* __KERNEL__ */
 
 #endif
diff --git a/kernel/sysctl.c b/kernel/sysctl.c
index fd9e1ab78c32..cb38cd7311fb 100644
--- a/kernel/sysctl.c
+++ b/kernel/sysctl.c
@@ -94,6 +94,9 @@
 #ifdef CONFIG_USER_NS
 #include <linux/user_namespace.h>
 #endif
+#if IS_ENABLED(CONFIG_USB)
+#include <linux/usb.h>
+#endif
 
 #if defined(CONFIG_SYSCTL)
 
@@ -2130,6 +2133,17 @@ static struct ctl_table kern_table[] = {
 		.mode		= 0644,
 		.proc_handler	= proc_doulongvec_minmax,
 	},
+#if IS_ENABLED(CONFIG_USB)
+	{
+		.procname	= "deny_new_usb",
+		.data		= &deny_new_usb,
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec_minmax_sysadmin,
+		.extra1		= SYSCTL_ZERO,
+		.extra2		= SYSCTL_ONE,
+	},
+#endif
 	{
 		.procname	= "ngroups_max",
 		.data		= (void *)&ngroups_max,
-- 
2.36.1

From 494cce28b91c1db92e3f2a776cfc76a60fa7c369 Mon Sep 17 00:00:00 2001
From: Levente Polyak <levente@leventepolyak.net>
Date: Sun, 6 Sep 2020 21:08:16 +0200
Subject: [PATCH 090/104] usb: implement dedicated subsystem sysctl tables

This moves the usb related sysctl knobs to an own usb local sysctl table
in order to clean up the global sysctl as well as allow the knob to be
exported and referenced appropriately when building the usb components
as dedicated modules.

Signed-off-by: Levente Polyak <levente@leventepolyak.net>
(cherry picked from commit 19d2d10e442c0f528124748f074f3fbbafaf8642)
---
 drivers/usb/core/Makefile |  1 +
 drivers/usb/core/hub.c    |  3 ---
 drivers/usb/core/sysctl.c | 43 +++++++++++++++++++++++++++++++++++++++
 drivers/usb/core/usb.c    |  9 ++++++++
 include/linux/usb.h       | 10 ++++++++-
 kernel/sysctl.c           | 14 -------------
 6 files changed, 62 insertions(+), 18 deletions(-)
 create mode 100644 drivers/usb/core/sysctl.c

diff --git a/drivers/usb/core/Makefile b/drivers/usb/core/Makefile
index 18e874b0441e..fc7a3a9aa72a 100644
--- a/drivers/usb/core/Makefile
+++ b/drivers/usb/core/Makefile
@@ -11,6 +11,7 @@ usbcore-y += phy.o port.o
 usbcore-$(CONFIG_OF)		+= of.o
 usbcore-$(CONFIG_USB_PCI)		+= hcd-pci.o
 usbcore-$(CONFIG_ACPI)		+= usb-acpi.o
+usbcore-$(CONFIG_SYSCTL)		+= sysctl.o
 
 obj-$(CONFIG_USB)		+= usbcore.o
 
diff --git a/drivers/usb/core/hub.c b/drivers/usb/core/hub.c
index bfd3f3ac1ff6..c80ac05fae1b 100644
--- a/drivers/usb/core/hub.c
+++ b/drivers/usb/core/hub.c
@@ -5187,9 +5187,6 @@ static int descriptors_changed(struct usb_device *udev,
 	return changed;
 }
 
-/* sysctl */
-int deny_new_usb __read_mostly = 0;
-
 static void hub_port_connect(struct usb_hub *hub, int port1, u16 portstatus,
 		u16 portchange)
 {
diff --git a/drivers/usb/core/sysctl.c b/drivers/usb/core/sysctl.c
new file mode 100644
index 000000000000..16f68ff8205c
--- /dev/null
+++ b/drivers/usb/core/sysctl.c
@@ -0,0 +1,43 @@
+#include <linux/errno.h>
+#include <linux/printk.h>
+#include <linux/init.h>
+#include <linux/sysctl.h>
+#include <linux/usb.h>
+
+static struct ctl_table usb_table[] = {
+	{
+		.procname	= "deny_new_usb",
+		.data		= &deny_new_usb,
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec_minmax_sysadmin,
+		.extra1		= SYSCTL_ZERO,
+		.extra2		= SYSCTL_ONE,
+	},
+	{ }
+};
+
+static struct ctl_table usb_root_table[] = {
+	{ .procname	= "kernel",
+	  .mode		= 0555,
+	  .child	= usb_table },
+	{ }
+};
+
+static struct ctl_table_header *usb_table_header;
+
+int __init usb_init_sysctl(void)
+{
+	usb_table_header = register_sysctl_table(usb_root_table);
+	if (!usb_table_header) {
+		pr_warn("usb: sysctl registration failed\n");
+		return -ENOMEM;
+	}
+
+	return 0;
+}
+
+void usb_exit_sysctl(void)
+{
+	unregister_sysctl_table(usb_table_header);
+}
diff --git a/drivers/usb/core/usb.c b/drivers/usb/core/usb.c
index 2f71636af6e1..49bdb2320b87 100644
--- a/drivers/usb/core/usb.c
+++ b/drivers/usb/core/usb.c
@@ -71,6 +71,9 @@ MODULE_PARM_DESC(autosuspend, "default autosuspend delay");
 #define usb_autosuspend_delay		0
 #endif
 
+int deny_new_usb __read_mostly = 0;
+EXPORT_SYMBOL(deny_new_usb);
+
 static bool match_endpoint(struct usb_endpoint_descriptor *epd,
 		struct usb_endpoint_descriptor **bulk_in,
 		struct usb_endpoint_descriptor **bulk_out,
@@ -1016,6 +1019,9 @@ static int __init usb_init(void)
 	usb_debugfs_init();
 
 	usb_acpi_register();
+	retval = usb_init_sysctl();
+	if (retval)
+		goto sysctl_init_failed;
 	retval = bus_register(&usb_bus_type);
 	if (retval)
 		goto bus_register_failed;
@@ -1050,6 +1056,8 @@ static int __init usb_init(void)
 bus_notifier_failed:
 	bus_unregister(&usb_bus_type);
 bus_register_failed:
+	usb_exit_sysctl();
+sysctl_init_failed:
 	usb_acpi_unregister();
 	usb_debugfs_cleanup();
 out:
@@ -1073,6 +1081,7 @@ static void __exit usb_exit(void)
 	usb_hub_cleanup();
 	bus_unregister_notifier(&usb_bus_type, &usb_bus_nb);
 	bus_unregister(&usb_bus_type);
+	usb_exit_sysctl();
 	usb_acpi_unregister();
 	usb_debugfs_cleanup();
 	idr_destroy(&usb_bus_idr);
diff --git a/include/linux/usb.h b/include/linux/usb.h
index 2f9fe848aa68..f992d3f86905 100644
--- a/include/linux/usb.h
+++ b/include/linux/usb.h
@@ -2030,8 +2030,16 @@ extern void usb_led_activity(enum usb_led_event ev);
 static inline void usb_led_activity(enum usb_led_event ev) {}
 #endif
 
-/* sysctl */
+/* sysctl.c */
 extern int deny_new_usb;
+#ifdef CONFIG_SYSCTL
+extern int usb_init_sysctl(void);
+extern void usb_exit_sysctl(void);
+#else
+static inline int usb_init_sysctl(void) { return 0; }
+static inline void usb_exit_sysctl(void) { }
+#endif /* CONFIG_SYSCTL */
+
 
 #endif  /* __KERNEL__ */
 
diff --git a/kernel/sysctl.c b/kernel/sysctl.c
index cb38cd7311fb..fd9e1ab78c32 100644
--- a/kernel/sysctl.c
+++ b/kernel/sysctl.c
@@ -94,9 +94,6 @@
 #ifdef CONFIG_USER_NS
 #include <linux/user_namespace.h>
 #endif
-#if IS_ENABLED(CONFIG_USB)
-#include <linux/usb.h>
-#endif
 
 #if defined(CONFIG_SYSCTL)
 
@@ -2133,17 +2130,6 @@ static struct ctl_table kern_table[] = {
 		.mode		= 0644,
 		.proc_handler	= proc_doulongvec_minmax,
 	},
-#if IS_ENABLED(CONFIG_USB)
-	{
-		.procname	= "deny_new_usb",
-		.data		= &deny_new_usb,
-		.maxlen		= sizeof(int),
-		.mode		= 0644,
-		.proc_handler	= proc_dointvec_minmax_sysadmin,
-		.extra1		= SYSCTL_ZERO,
-		.extra2		= SYSCTL_ONE,
-	},
-#endif
 	{
 		.procname	= "ngroups_max",
 		.data		= (void *)&ngroups_max,
-- 
2.36.1

From 9056da3fcc93b3cfe4da133ec445828bc2f71f7d Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Sun, 25 Feb 2018 03:26:45 -0500
Subject: [PATCH 091/104] hard-wire legacy checkreqprot option to 0

The userspace API is left intact for compatibility.

Signed-off-by: Levente Polyak <levente@leventepolyak.net>
(cherry picked from commit ecb7b142a510f650d38ba5849ebf32127ed37c00)
---
 .../admin-guide/kernel-parameters.txt         | 11 ---------
 security/selinux/Kconfig                      | 23 -------------------
 security/selinux/hooks.c                      | 16 +------------
 security/selinux/selinuxfs.c                  | 11 +--------
 4 files changed, 2 insertions(+), 59 deletions(-)

diff --git a/Documentation/admin-guide/kernel-parameters.txt b/Documentation/admin-guide/kernel-parameters.txt
index 7dfb382ab13d..60f13c2cb92f 100644
--- a/Documentation/admin-guide/kernel-parameters.txt
+++ b/Documentation/admin-guide/kernel-parameters.txt
@@ -550,17 +550,6 @@
 			nosocket -- Disable socket memory accounting.
 			nokmem -- Disable kernel memory accounting.
 
-	checkreqprot	[SELINUX] Set initial checkreqprot flag value.
-			Format: { "0" | "1" }
-			See security/selinux/Kconfig help text.
-			0 -- check protection applied by kernel (includes
-				any implied execute protection).
-			1 -- check protection requested by application.
-			Default value is set via a kernel config option.
-			Value can be changed at runtime via
-				/sys/fs/selinux/checkreqprot.
-			Setting checkreqprot to 1 is deprecated.
-
 	cio_ignore=	[S390]
 			See Documentation/s390/common_io.rst for details.
 	clk_ignore_unused
diff --git a/security/selinux/Kconfig b/security/selinux/Kconfig
index 76d7ed11513c..ae851a826c26 100644
--- a/security/selinux/Kconfig
+++ b/security/selinux/Kconfig
@@ -70,29 +70,6 @@ config SECURITY_SELINUX_AVC_STATS
 	  /sys/fs/selinux/avc/cache_stats, which may be monitored via
 	  tools such as avcstat.
 
-config SECURITY_SELINUX_CHECKREQPROT_VALUE
-	int "NSA SELinux checkreqprot default value"
-	depends on SECURITY_SELINUX
-	range 0 1
-	default 0
-	help
-	  This option sets the default value for the 'checkreqprot' flag
-	  that determines whether SELinux checks the protection requested
-	  by the application or the protection that will be applied by the
-	  kernel (including any implied execute for read-implies-exec) for
-	  mmap and mprotect calls.  If this option is set to 0 (zero),
-	  SELinux will default to checking the protection that will be applied
-	  by the kernel.  If this option is set to 1 (one), SELinux will
-	  default to checking the protection requested by the application.
-	  The checkreqprot flag may be changed from the default via the
-	  'checkreqprot=' boot parameter.  It may also be changed at runtime
-	  via /sys/fs/selinux/checkreqprot if authorized by policy.
-
-	  WARNING: this option is deprecated and will be removed in a future
-	  kernel release.
-
-	  If you are unsure how to answer this question, answer 0.
-
 config SECURITY_SELINUX_SIDTAB_HASH_BITS
 	int "NSA SELinux sidtab hashtable size"
 	depends on SECURITY_SELINUX
diff --git a/security/selinux/hooks.c b/security/selinux/hooks.c
index e9e959343de9..fb86a303c8d1 100644
--- a/security/selinux/hooks.c
+++ b/security/selinux/hooks.c
@@ -135,21 +135,7 @@ static int __init selinux_enabled_setup(char *str)
 __setup("selinux=", selinux_enabled_setup);
 #endif
 
-static unsigned int selinux_checkreqprot_boot =
-	CONFIG_SECURITY_SELINUX_CHECKREQPROT_VALUE;
-
-static int __init checkreqprot_setup(char *str)
-{
-	unsigned long checkreqprot;
-
-	if (!kstrtoul(str, 0, &checkreqprot)) {
-		selinux_checkreqprot_boot = checkreqprot ? 1 : 0;
-		if (checkreqprot)
-			pr_warn("SELinux: checkreqprot set to 1 via kernel parameter.  This is deprecated and will be rejected in a future kernel release.\n");
-	}
-	return 1;
-}
-__setup("checkreqprot=", checkreqprot_setup);
+static const unsigned int selinux_checkreqprot_boot;
 
 /**
  * selinux_secmark_enabled - Check to see if SECMARK is currently enabled
diff --git a/security/selinux/selinuxfs.c b/security/selinux/selinuxfs.c
index 097c6d866ec4..1448040387d8 100644
--- a/security/selinux/selinuxfs.c
+++ b/security/selinux/selinuxfs.c
@@ -748,18 +748,9 @@ static ssize_t sel_write_checkreqprot(struct file *file, const char __user *buf,
 		return PTR_ERR(page);
 
 	length = -EINVAL;
-	if (sscanf(page, "%u", &new_value) != 1)
+	if (sscanf(page, "%u", &new_value) != 1 || new_value)
 		goto out;
 
-	if (new_value) {
-		char comm[sizeof(current->comm)];
-
-		memcpy(comm, current->comm, sizeof(comm));
-		pr_warn_once("SELinux: %s (%d) set checkreqprot to 1. This is deprecated and will be rejected in a future kernel release.\n",
-			     comm, current->pid);
-	}
-
-	checkreqprot_set(fsi->state, (new_value ? 1 : 0));
 	length = count;
 
 	selinux_ima_measure_state(fsi->state);
-- 
2.36.1

From 39580310fea3adfdc62f973a01fe6855beeb5965 Mon Sep 17 00:00:00 2001
From: Matt Brown <matt@nmatt.com>
Date: Mon, 29 May 2017 17:37:59 -0400
Subject: [PATCH 092/104] security: tty: Add owner user namespace to tty_struct

This patch adds struct user_namespace *owner_user_ns to the tty_struct.
Then it is set to current_user_ns() in the alloc_tty_struct function.

This is done to facilitate capability checks against the original user
namespace that allocated the tty.

E.g. ns_capable(tty->owner_user_ns,CAP_SYS_ADMIN)

This combined with the use of user namespace's will allow hardening
protections to be built to mitigate container escapes that utilize TTY
ioctls such as TIOCSTI.

See: https://bugzilla.redhat.com/show_bug.cgi?id=1411256

Acked-by: Serge Hallyn <serge@hallyn.com>
Reviewed-by: Kees Cook <keescook@chromium.org>
Signed-off-by: Matt Brown <matt@nmatt.com>
(cherry picked from commit 7bb28c92ab785eb664fc54a1ff585d5aaad360b6)
---
 drivers/tty/tty_io.c | 2 ++
 include/linux/tty.h  | 2 ++
 2 files changed, 4 insertions(+)

diff --git a/drivers/tty/tty_io.c b/drivers/tty/tty_io.c
index 8fec1d8648f5..459d5b86c075 100644
--- a/drivers/tty/tty_io.c
+++ b/drivers/tty/tty_io.c
@@ -171,6 +171,7 @@ static void free_tty_struct(struct tty_struct *tty)
 	put_device(tty->dev);
 	kvfree(tty->write_buf);
 	tty->magic = 0xDEADDEAD;
+	put_user_ns(tty->owner_user_ns);
 	kfree(tty);
 }
 
@@ -3120,6 +3121,7 @@ struct tty_struct *alloc_tty_struct(struct tty_driver *driver, int idx)
 	tty->index = idx;
 	tty_line_name(driver, idx, tty->name);
 	tty->dev = tty_get_device(tty);
+	tty->owner_user_ns = get_user_ns(current_user_ns());
 
 	return tty;
 }
diff --git a/include/linux/tty.h b/include/linux/tty.h
index 7b0a5d478ef6..2602b272e9fd 100644
--- a/include/linux/tty.h
+++ b/include/linux/tty.h
@@ -15,6 +15,7 @@
 #include <uapi/linux/tty.h>
 #include <linux/rwsem.h>
 #include <linux/llist.h>
+#include <linux/user_namespace.h>
 
 
 /*
@@ -251,6 +252,7 @@ struct tty_struct {
 	int write_cnt;
 	struct work_struct SAK_work;
 	struct tty_port *port;
+	struct user_namespace *owner_user_ns;
 } __randomize_layout;
 
 /* Each of a tty's open files has private_data pointing to tty_file_private */
-- 
2.36.1

From a6623c82a4ecb15c5dd155074821968074929ff7 Mon Sep 17 00:00:00 2001
From: Matt Brown <matt@nmatt.com>
Date: Mon, 29 May 2017 17:38:00 -0400
Subject: [PATCH 093/104] security: tty: make TIOCSTI ioctl require
 CAP_SYS_ADMIN

This introduces the tiocsti_restrict sysctl, whose default is controlled
via CONFIG_SECURITY_TIOCSTI_RESTRICT. When activated, this control
restricts all TIOCSTI ioctl calls from non CAP_SYS_ADMIN users.

This patch depends on patch 1/2

This patch was inspired from GRKERNSEC_HARDEN_TTY.

This patch would have prevented
https://bugzilla.redhat.com/show_bug.cgi?id=1411256 under the following
conditions:
* non-privileged container
* container run inside new user namespace

Possible effects on userland:

There could be a few user programs that would be effected by this
change.
See: <https://codesearch.debian.net/search?q=ioctl%5C%28.*TIOCSTI>
notable programs are: agetty, csh, xemacs and tcsh

However, I still believe that this change is worth it given that the
Kconfig defaults to n. This will be a feature that is turned on for the
same reason that people activate it when using grsecurity. Users of this
opt-in feature will realize that they are choosing security over some OS
features like unprivileged TIOCSTI ioctls, as should be clear in the
Kconfig help message.

Threat Model/Patch Rational:

>From grsecurity's config for GRKERNSEC_HARDEN_TTY.

 | There are very few legitimate uses for this functionality and it
 | has made vulnerabilities in several 'su'-like programs possible in
 | the past.  Even without these vulnerabilities, it provides an
 | attacker with an easy mechanism to move laterally among other
 | processes within the same user's compromised session.

So if one process within a tty session becomes compromised it can follow
that additional processes, that are thought to be in different security
boundaries, can be compromised as a result. When using a program like su
or sudo, these additional processes could be in a tty session where TTY
file descriptors are indeed shared over privilege boundaries.

This is also an excellent writeup about the issue:
<http://www.halfdog.net/Security/2012/TtyPushbackPrivilegeEscalation/>

When user namespaces are in use, the check for the capability
CAP_SYS_ADMIN is done against the user namespace that originally opened
the tty.

Acked-by: Serge Hallyn <serge@hallyn.com>
Reviewed-by: Kees Cook <keescook@chromium.org>
Signed-off-by: Matt Brown <matt@nmatt.com>
Signed-off-by: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
Signed-off-by: Levente Polyak <levente@leventepolyak.net>
(cherry picked from commit eb7960d0f306ce0c6ad505d2ed4a1b4ded7d91f4)
---
 Documentation/admin-guide/sysctl/kernel.rst | 20 ++++++++++++++++++++
 drivers/tty/tty_io.c                        |  8 ++++++++
 drivers/tty/tty_ldisc.c                     |  9 +++++++++
 include/linux/tty.h                         |  2 ++
 security/Kconfig                            | 13 +++++++++++++
 5 files changed, 52 insertions(+)

diff --git a/Documentation/admin-guide/sysctl/kernel.rst b/Documentation/admin-guide/sysctl/kernel.rst
index 19aa8fb16533..5edf4bb5d7e7 100644
--- a/Documentation/admin-guide/sysctl/kernel.rst
+++ b/Documentation/admin-guide/sysctl/kernel.rst
@@ -1376,6 +1376,26 @@ If a value outside of this range is written to ``threads-max`` an
 ``EINVAL`` error occurs.
 
 
+tiocsti_restrict
+================
+
+This toggle indicates whether unprivileged users are prevented from using the
+``TIOCSTI`` ioctl to inject commands into other processes which share a tty
+session.
+
+= ============================================================================
+0 No restriction, except the default one of only being able to inject commands
+  into one's own tty.
+1 Users must have ``CAP_SYS_ADMIN`` to use the ``TIOCSTI`` ioctl.
+= ============================================================================
+
+When user namespaces are in use, the check for ``CAP_SYS_ADMIN`` is done
+against the user namespace that originally opened the tty.
+
+The kernel config option ``CONFIG_SECURITY_TIOCSTI_RESTRICT`` sets the default
+value of ``tiocsti_restrict``.
+
+
 traceoff_on_warning
 ===================
 
diff --git a/drivers/tty/tty_io.c b/drivers/tty/tty_io.c
index 459d5b86c075..ff809fbaf585 100644
--- a/drivers/tty/tty_io.c
+++ b/drivers/tty/tty_io.c
@@ -2263,6 +2263,8 @@ static int tty_fasync(int fd, struct file *filp, int on)
 	return retval;
 }
 
+int tiocsti_restrict = IS_ENABLED(CONFIG_SECURITY_TIOCSTI_RESTRICT);
+
 /**
  * tiocsti		-	fake input character
  * @tty: tty to fake input into
@@ -2281,6 +2283,12 @@ static int tiocsti(struct tty_struct *tty, char __user *p)
 	char ch, mbz = 0;
 	struct tty_ldisc *ld;
 
+	if (tiocsti_restrict &&
+		!ns_capable(tty->owner_user_ns, CAP_SYS_ADMIN)) {
+		dev_warn_ratelimited(tty->dev,
+			"Denied TIOCSTI ioctl for non-privileged process\n");
+		return -EPERM;
+	}
 	if ((current->signal->tty != tty) && !capable(CAP_SYS_ADMIN))
 		return -EPERM;
 	if (get_user(ch, p))
diff --git a/drivers/tty/tty_ldisc.c b/drivers/tty/tty_ldisc.c
index 776d8a62f77c..08f664a086d6 100644
--- a/drivers/tty/tty_ldisc.c
+++ b/drivers/tty/tty_ldisc.c
@@ -828,6 +828,15 @@ static struct ctl_table tty_table[] = {
 		.extra1		= SYSCTL_ZERO,
 		.extra2		= SYSCTL_ONE,
 	},
+	{
+		.procname	= "tiocsti_restrict",
+		.data		= &tiocsti_restrict,
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec_minmax_sysadmin,
+		.extra1		= SYSCTL_ZERO,
+		.extra2		= SYSCTL_ONE,
+	},
 	{ }
 };
 
diff --git a/include/linux/tty.h b/include/linux/tty.h
index 2602b272e9fd..ec75344c3566 100644
--- a/include/linux/tty.h
+++ b/include/linux/tty.h
@@ -262,6 +262,8 @@ struct tty_file_private {
 	struct list_head list;
 };
 
+extern int tiocsti_restrict;
+
 /* tty magic number */
 #define TTY_MAGIC		0x5401
 
diff --git a/security/Kconfig b/security/Kconfig
index eddea71f67e4..122bff693d3a 100644
--- a/security/Kconfig
+++ b/security/Kconfig
@@ -29,6 +29,19 @@ config SECURITY_PERF_EVENTS_RESTRICT
 	  perf_event_open syscall will be permitted unless it is
 	  changed.
 
+config SECURITY_TIOCSTI_RESTRICT
+	bool "Restrict unprivileged use of tiocsti command injection"
+	default n
+	help
+	  This enforces restrictions on unprivileged users injecting commands
+	  into other processes which share a tty session using the TIOCSTI
+	  ioctl. This option makes TIOCSTI use require CAP_SYS_ADMIN.
+
+	  If this option is not selected, no restrictions will be enforced
+	  unless the tiocsti_restrict sysctl is explicitly set to (1).
+
+	  If you are unsure how to answer this question, answer N.
+
 config SECURITY
 	bool "Enable different security models"
 	depends on SYSFS
-- 
2.36.1

From 4348150f5733779a6994f7429828614e7f3e7f48 Mon Sep 17 00:00:00 2001
From: Daniel Micay <danielmicay@gmail.com>
Date: Wed, 3 May 2017 23:36:14 -0400
Subject: [PATCH 094/104] enable SECURITY_TIOCSTI_RESTRICT by default

Signed-off-by: Daniel Micay <danielmicay@gmail.com>
(cherry picked from commit 123c3da6cb70ed566634a01dab76cf905b2ac7c8)
---
 security/Kconfig | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/security/Kconfig b/security/Kconfig
index 122bff693d3a..537d686a4db2 100644
--- a/security/Kconfig
+++ b/security/Kconfig
@@ -31,7 +31,7 @@ config SECURITY_PERF_EVENTS_RESTRICT
 
 config SECURITY_TIOCSTI_RESTRICT
 	bool "Restrict unprivileged use of tiocsti command injection"
-	default n
+	default y
 	help
 	  This enforces restrictions on unprivileged users injecting commands
 	  into other processes which share a tty session using the TIOCSTI
-- 
2.36.1

From 2b0b2a3d1078e3b7eaa0501c06651f2c6b33510f Mon Sep 17 00:00:00 2001
From: Levente Polyak <levente@leventepolyak.net>
Date: Mon, 7 May 2018 20:37:55 +0200
Subject: [PATCH 095/104] enable BPF JIT hardening by default (if available)

(cherry picked from commit 075fea48e973d19df4e15df71b1fccf9a346a3b6)
---
 kernel/bpf/core.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/kernel/bpf/core.c b/kernel/bpf/core.c
index 05e701f0da81..0135cb644e9c 100644
--- a/kernel/bpf/core.c
+++ b/kernel/bpf/core.c
@@ -532,7 +532,7 @@ void bpf_prog_kallsyms_del_all(struct bpf_prog *fp)
 /* All BPF JIT sysctl knobs here. */
 int bpf_jit_enable   __read_mostly = IS_BUILTIN(CONFIG_BPF_JIT_DEFAULT_ON);
 int bpf_jit_kallsyms __read_mostly = IS_BUILTIN(CONFIG_BPF_JIT_DEFAULT_ON);
-int bpf_jit_harden   __read_mostly;
+int bpf_jit_harden   __read_mostly = 2;
 long bpf_jit_limit   __read_mostly;
 long bpf_jit_limit_max __read_mostly;
 
-- 
2.36.1

From 7773d42ad531a7c6ac1cc00af7e998c5bdfbf169 Mon Sep 17 00:00:00 2001
From: Levente Polyak <levente@leventepolyak.net>
Date: Sun, 4 Nov 2018 18:48:53 +0100
Subject: [PATCH 096/104] enable protected_{fifos,regular} by default

(cherry picked from commit d3d9371763c9722a9c34f7c86d7639900e159f1f)
---
 fs/namei.c | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/fs/namei.c b/fs/namei.c
index 5f711e9520f7..0b1c99e561cb 100644
--- a/fs/namei.c
+++ b/fs/namei.c
@@ -1022,8 +1022,8 @@ static inline void put_link(struct nameidata *nd)
 
 static int sysctl_protected_symlinks __read_mostly = 1;
 static int sysctl_protected_hardlinks __read_mostly = 1;
-static int sysctl_protected_fifos __read_mostly;
-static int sysctl_protected_regular __read_mostly;
+static int sysctl_protected_fifos __read_mostly = 2;
+static int sysctl_protected_regular __read_mostly = 2;
 
 #ifdef CONFIG_SYSCTL
 static struct ctl_table namei_sysctls[] = {
-- 
2.36.1

From 8781f5a98f36343b430f09d671302f8907a18a28 Mon Sep 17 00:00:00 2001
From: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
Date: Mon, 6 May 2019 17:07:11 +0200
Subject: [PATCH 097/104] modpost: Add
 CONFIG_DEBUG_WRITABLE_FUNCTION_POINTERS_VERBOSE

With 46c7dd56d541 ("modpost: always show verbose warning for section
mismatch"), sec_mismatch_verbose was removed which would have printed
errors for all writable function pointers during compilation if it
hadn't been "#if 0"ed out for quite some time now.

Let's introduce a new DEBUG_WRITABLE_FUNCTION_POINTERS_VERBOSE Kconfig
option to cleanly control this linux-hardened functionality.

Signed-off-by: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
Signed-off-by: Levente Polyak <levente@leventepolyak.net>
(cherry picked from commit 1238076ce5726c217722bf29af3e3c967ac2ff70)
---
 lib/Kconfig.debug        |  3 +++
 scripts/Makefile.modpost |  1 +
 scripts/mod/modpost.c    | 23 +++++++++++++++--------
 3 files changed, 19 insertions(+), 8 deletions(-)

diff --git a/lib/Kconfig.debug b/lib/Kconfig.debug
index 4fa4df798182..b1c778034830 100644
--- a/lib/Kconfig.debug
+++ b/lib/Kconfig.debug
@@ -456,6 +456,9 @@ config SECTION_MISMATCH_WARN_ONLY
 
 	  If unsure, say Y.
 
+config DEBUG_WRITABLE_FUNCTION_POINTERS_VERBOSE
+	bool "Enable verbose reporting of writable function pointers"
+
 config DEBUG_FORCE_FUNCTION_ALIGN_64B
 	bool "Force all function address 64B aligned"
 	depends on EXPERT && (X86_64 || ARM64 || PPC32 || PPC64 || ARC)
diff --git a/scripts/Makefile.modpost b/scripts/Makefile.modpost
index 48585c4d04ad..383c165fa0e2 100644
--- a/scripts/Makefile.modpost
+++ b/scripts/Makefile.modpost
@@ -48,6 +48,7 @@ MODPOST = scripts/mod/modpost								\
 	$(if $(CONFIG_MODVERSIONS),-m)							\
 	$(if $(CONFIG_MODULE_SRCVERSION_ALL),-a)					\
 	$(if $(CONFIG_SECTION_MISMATCH_WARN_ONLY),,-E)					\
+	$(if $(CONFIG_DEBUG_WRITABLE_FUNCTION_POINTERS_VERBOSE),-f)			\
 	-o $@
 
 ifdef MODPOST_VMLINUX
diff --git a/scripts/mod/modpost.c b/scripts/mod/modpost.c
index b053aee4886f..18efada59c12 100644
--- a/scripts/mod/modpost.c
+++ b/scripts/mod/modpost.c
@@ -34,6 +34,7 @@ static int warn_unresolved = 0;
 static int sec_mismatch_count = 0;
 static int sec_mismatch_warn_only = true;
 static int writable_fptr_count = 0;
+static int writable_fptr_verbose = false;
 /* ignore missing files */
 static int ignore_missing_files;
 /* If set to 1, only warn (instead of error) about missing ns imports */
@@ -1462,10 +1463,13 @@ static void report_sec_mismatch(const char *modname,
 	char *prl_from;
 	char *prl_to;
 
-	if (mismatch->mismatch == DATA_TO_TEXT)
+	if (mismatch->mismatch == DATA_TO_TEXT) {
 		writable_fptr_count++;
-	else
+		if (!writable_fptr_verbose)
+			return;
+	} else {
 		sec_mismatch_count++;
+	}
 
 	get_pretty_name(from_is_func, &from, &from_p);
 	get_pretty_name(to_is_func, &to, &to_p);
@@ -1588,12 +1592,10 @@ static void report_sec_mismatch(const char *modname,
 		      "we should never get here.");
 		break;
 	case DATA_TO_TEXT:
-#if 0
 		fprintf(stderr,
 		"The %s %s:%s references\n"
 		"the %s %s:%s%s\n",
 		from, fromsec, fromsym, to, tosec, tosym, to_p);
-#endif
 		break;
 	}
 	fprintf(stderr, "\n");
@@ -2544,7 +2546,7 @@ int main(int argc, char **argv)
 	struct dump_list *dump_read_start = NULL;
 	struct dump_list **dump_read_iter = &dump_read_start;
 
-	while ((opt = getopt(argc, argv, "ei:mnT:o:awENd:")) != -1) {
+	while ((opt = getopt(argc, argv, "ei:fmnT:o:awENd:")) != -1) {
 		switch (opt) {
 		case 'e':
 			external_module = 1;
@@ -2555,6 +2557,9 @@ int main(int argc, char **argv)
 			(*dump_read_iter)->file = optarg;
 			dump_read_iter = &(*dump_read_iter)->next;
 			break;
+		case 'f':
+			writable_fptr_verbose = true;
+			break;
 		case 'm':
 			modversions = 1;
 			break;
@@ -2650,9 +2655,11 @@ int main(int argc, char **argv)
 		     nr_unresolved - MAX_UNRESOLVED_REPORTS);
 
 	free(buf.p);
-	if (writable_fptr_count)
-		warn("modpost: Found %d writable function pointer(s).\n",
-		     writable_fptr_count);
+	if (writable_fptr_count && !writable_fptr_verbose)
+		warn("modpost: Found %d writable function pointer%s.\n"
+		     "To see full details build your kernel with:\n"
+		     "'make CONFIG_DEBUG_WRITABLE_FUNCTION_POINTERS_VERBOSE=y'\n",
+		     writable_fptr_count, (writable_fptr_count == 1 ? "" : "s"));
 
 	return error_occurred ? 1 : 0;
 }
-- 
2.36.1

From dc04311b9b87b26fbb910008babb518f63f8a02f Mon Sep 17 00:00:00 2001
From: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
Date: Tue, 7 May 2019 11:46:21 +0200
Subject: [PATCH 098/104] mm: Fix extra_latent_entropy

Commit a9cd410a3d29 ("mm/page_alloc.c: memory hotplug: free pages as
higher order") changed `static void __init __free_pages_boot_core()`
into `void __free_pages_core()`, causing the following section mismatch
warning at compile time:

    WARNING: vmlinux.o(.text+0x180fe4): Section mismatch in reference from the function __free_pages_core() to the variable .meminit.data:extra_latent_entropy
    The function __free_pages_core() references the variable __meminitdata extra_latent_entropy.
    This is often because __free_pages_core lacks a __meminitdata annotation or the annotation of extra_latent_entropy is wrong.

This commit is an attempt at fixing this issue. I'm not sure it's OK as
we are accessing pages that are still managed by the memblock allocator.
The prefetching part is not an issue as it only affects struct pages.

Signed-off-by: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
(cherry picked from commit ff5c76ea665abb14fdb1c03ebce410b744735aa0)
---
 mm/page_alloc.c | 38 ++++++++++++++++++++++----------------
 1 file changed, 22 insertions(+), 16 deletions(-)

diff --git a/mm/page_alloc.c b/mm/page_alloc.c
index 3e4368ca2a68..bed050e3a0f9 100644
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@ -1637,6 +1637,25 @@ static void __free_pages_ok(struct page *page, unsigned int order,
 	__count_vm_events(PGFREE, 1 << order);
 }
 
+static void __init __gather_extra_latent_entropy(struct page *page,
+						 unsigned int nr_pages)
+{
+	if (extra_latent_entropy && !PageHighMem(page) && page_to_pfn(page) < 0x100000) {
+		unsigned long hash = 0;
+		size_t index, end = PAGE_SIZE * nr_pages / sizeof hash;
+		const unsigned long *data = lowmem_page_address(page);
+
+		for (index = 0; index < end; index++)
+			hash ^= hash + data[index];
+#ifdef CONFIG_GCC_PLUGIN_LATENT_ENTROPY
+		latent_entropy ^= hash;
+		add_device_randomness((const void *)&latent_entropy, sizeof(latent_entropy));
+#else
+		add_device_randomness((const void *)&hash, sizeof(hash));
+#endif
+	}
+}
+
 void __free_pages_core(struct page *page, unsigned int order)
 {
 	unsigned int nr_pages = 1 << order;
@@ -1656,22 +1675,6 @@ void __free_pages_core(struct page *page, unsigned int order)
 	}
 	__ClearPageReserved(p);
 	set_page_count(p, 0);
-
-	if (extra_latent_entropy && !PageHighMem(page) && page_to_pfn(page) < 0x100000) {
-		unsigned long hash = 0;
-		size_t index, end = PAGE_SIZE * nr_pages / sizeof hash;
-		const unsigned long *data = lowmem_page_address(page);
-
-		for (index = 0; index < end; index++)
-			hash ^= hash + data[index];
-#ifdef CONFIG_GCC_PLUGIN_LATENT_ENTROPY
-		latent_entropy ^= hash;
-		add_device_randomness((const void *)&latent_entropy, sizeof(latent_entropy));
-#else
-		add_device_randomness((const void *)&hash, sizeof(hash));
-#endif
-	}
-
 	atomic_long_add(nr_pages, &page_zone(page)->managed_pages);
 
 	/*
@@ -1738,6 +1741,7 @@ void __init memblock_free_pages(struct page *page, unsigned long pfn,
 {
 	if (early_page_uninitialised(pfn))
 		return;
+	__gather_extra_latent_entropy(page, 1 << order);
 	__free_pages_core(page, order);
 }
 
@@ -1827,6 +1831,7 @@ static void __init deferred_free_range(unsigned long pfn,
 	if (nr_pages == pageblock_nr_pages &&
 	    (pfn & (pageblock_nr_pages - 1)) == 0) {
 		set_pageblock_migratetype(page, MIGRATE_MOVABLE);
+		__gather_extra_latent_entropy(page, 1 << pageblock_order);
 		__free_pages_core(page, pageblock_order);
 		return;
 	}
@@ -1834,6 +1839,7 @@ static void __init deferred_free_range(unsigned long pfn,
 	for (i = 0; i < nr_pages; i++, page++, pfn++) {
 		if ((pfn & (pageblock_nr_pages - 1)) == 0)
 			set_pageblock_migratetype(page, MIGRATE_MOVABLE);
+		__gather_extra_latent_entropy(page, 1);
 		__free_pages_core(page, 0);
 	}
 }
-- 
2.36.1

From 7abcc0328dcdf1124f6b0fddbc379b4f6c8dd9ee Mon Sep 17 00:00:00 2001
From: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
Date: Fri, 29 Nov 2019 16:27:14 +0100
Subject: [PATCH 099/104] slub: Extend init_on_alloc to slab caches with
 constructors

This has required some rework during the port to 5.13, due to
da844b787245 ("kasan, mm: integrate slab init_on_alloc with HW_TAGS"),
and the patch is actually quite simpler now since we do not need to
unpoison objects anymore.

Signed-off-by: Levente Polyak <levente@leventepolyak.net>
Signed-off-by: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
(cherry picked from commit 129f2e8b1bd01e20ebd1ec231ef148ebdf8cab2c)
---
 mm/slab.h | 4 ++++
 1 file changed, 4 insertions(+)

diff --git a/mm/slab.h b/mm/slab.h
index 9f3cc0074aa3..70895f119142 100644
--- a/mm/slab.h
+++ b/mm/slab.h
@@ -758,6 +758,8 @@ static inline void slab_post_alloc_hook(struct kmem_cache *s,
 		p[i] = kasan_slab_alloc(s, p[i], flags, init);
 		if (p[i] && init && !kasan_has_integrated_init())
 			memset(p[i], 0, s->object_size);
+		if (p[i] && init && s->ctor)
+			s->ctor(p[i]);
 		kmemleak_alloc_recursive(p[i], s->object_size, 1,
 					 s->flags, flags);
 	}
@@ -841,8 +843,10 @@ static inline bool slab_want_init_on_alloc(gfp_t flags, struct kmem_cache *c)
 {
 	if (static_branch_maybe(CONFIG_INIT_ON_ALLOC_DEFAULT_ON,
 				&init_on_alloc)) {
+#ifndef CONFIG_SLUB
 		if (c->ctor)
 			return false;
+#endif
 		if (c->flags & (SLAB_TYPESAFE_BY_RCU | SLAB_POISON))
 			return flags & __GFP_ZERO;
 		return true;
-- 
2.36.1

From d57ba3b360062377e8ed42311d03f33e8328ecb4 Mon Sep 17 00:00:00 2001
From: madaidan <50278627+madaidan@users.noreply.github.com>
Date: Sun, 9 Feb 2020 00:03:41 +0000
Subject: [PATCH 100/104] net: tcp: add option to disable TCP simultaneous
 connect

This is modified from Brad Spengler/PaX Team's code in the last public
patch of grsecurity/PaX based on my understanding of the code. Changes
or omissions from the original code are mine and don't reflect the
original grsecurity/PaX code.

TCP simultaneous connect adds a weakness in Linux's implementation of
TCP that allows two clients to connect to each other without either
entering a listening state. The weakness allows an attacker to easily
prevent a client from connecting to a known server provided the source
port for the connection is guessed correctly.

As the weakness could be used to prevent an antivirus or IPS from
fetching updates, or prevent an SSL gateway from fetching a CRL, it
should be eliminated.

This creates a net.ipv4.tcp_simult_connect sysctl that when disabled,
disables TCP simultaneous connect.

Reviewed-by: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
Reviewed-by: Levente Polyak <levente@leventepolyak.net>
Signed-off-by: Levente Polyak <levente@leventepolyak.net>
(cherry picked from commit 7f2258f639ce2b1215fed51d565098e1f4fb83be)
---
 Documentation/networking/ip-sysctl.rst | 18 ++++++++++++++++++
 include/net/tcp.h                      |  1 +
 net/ipv4/Kconfig                       | 23 +++++++++++++++++++++++
 net/ipv4/sysctl_net_ipv4.c             |  9 +++++++++
 net/ipv4/tcp_input.c                   |  3 ++-
 5 files changed, 53 insertions(+), 1 deletion(-)

diff --git a/Documentation/networking/ip-sysctl.rst b/Documentation/networking/ip-sysctl.rst
index 66828293d9cb..8183540faeeb 100644
--- a/Documentation/networking/ip-sysctl.rst
+++ b/Documentation/networking/ip-sysctl.rst
@@ -723,6 +723,24 @@ tcp_comp_sack_nr - INTEGER
 
 	Default : 44
 
+tcp_simult_connect - BOOLEAN
+	Enable TCP simultaneous connect that adds a weakness in Linux's strict
+	implementation of TCP that allows two clients to connect to each other
+	without either entering a listening state. The weakness allows an attacker
+	to easily prevent a client from connecting to a known server provided the
+	source port for the connection is guessed correctly.
+
+	As the weakness could be used to prevent an antivirus or IPS from fetching
+	updates, or prevent an SSL gateway from fetching a CRL, it should be
+	eliminated by disabling this option. Though Linux is one of few operating
+	systems supporting simultaneous connect, it has no legitimate use in
+	practice and is rarely supported by firewalls.
+
+	Disabling this may break TCP STUNT which is used by some applications for
+	NAT traversal.
+
+	Default: Value of CONFIG_TCP_SIMULT_CONNECT_DEFAULT_ON
+
 tcp_slow_start_after_idle - BOOLEAN
 	If set, provide RFC2861 behavior and time out the congestion
 	window after an idle period.  An idle period is defined at
diff --git a/include/net/tcp.h b/include/net/tcp.h
index cc1295037533..21cae3ebcbb2 100644
--- a/include/net/tcp.h
+++ b/include/net/tcp.h
@@ -247,6 +247,7 @@ void tcp_time_wait(struct sock *sk, int state, int timeo);
 /* sysctl variables for tcp */
 extern int sysctl_tcp_max_orphans;
 extern long sysctl_tcp_mem[3];
+extern int sysctl_tcp_simult_connect;
 
 #define TCP_RACK_LOSS_DETECTION  0x1 /* Use RACK to detect losses */
 #define TCP_RACK_STATIC_REO_WND  0x2 /* Use static RACK reo wnd */
diff --git a/net/ipv4/Kconfig b/net/ipv4/Kconfig
index 989e005bf698..d1584b4b39f9 100644
--- a/net/ipv4/Kconfig
+++ b/net/ipv4/Kconfig
@@ -743,3 +743,26 @@ config TCP_MD5SIG
 	  on the Internet.
 
 	  If unsure, say N.
+
+config TCP_SIMULT_CONNECT_DEFAULT_ON
+	bool "Enable TCP simultaneous connect"
+	help
+	  Enable TCP simultaneous connect that adds a weakness in Linux's strict
+	  implementation of TCP that allows two clients to connect to each other
+	  without either entering a listening state. The weakness allows an
+	  attacker to easily prevent a client from connecting to a known server
+	  provided the source port for the connection is guessed correctly.
+
+	  As the weakness could be used to prevent an antivirus or IPS from
+	  fetching updates, or prevent an SSL gateway from fetching a CRL, it
+	  should be eliminated by disabling this option. Though Linux is one of
+	  few operating systems supporting simultaneous connect, it has no
+	  legitimate use in practice and is rarely supported by firewalls.
+
+	  Disabling this may break TCP STUNT which is used by some applications
+	  for NAT traversal.
+
+	  This setting can be overridden at runtime via the
+	  net.ipv4.tcp_simult_connect sysctl.
+
+	  If unsure, say N.
diff --git a/net/ipv4/sysctl_net_ipv4.c b/net/ipv4/sysctl_net_ipv4.c
index ad80d180b60b..4ff3e6d95c85 100644
--- a/net/ipv4/sysctl_net_ipv4.c
+++ b/net/ipv4/sysctl_net_ipv4.c
@@ -585,6 +585,15 @@ static struct ctl_table ipv4_table[] = {
 		.extra1		= &sysctl_fib_sync_mem_min,
 		.extra2		= &sysctl_fib_sync_mem_max,
 	},
+	{
+		.procname	= "tcp_simult_connect",
+		.data		= &sysctl_tcp_simult_connect,
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec_minmax,
+		.extra1		= SYSCTL_ZERO,
+		.extra2		= SYSCTL_ONE,
+	},
 	{ }
 };
 
diff --git a/net/ipv4/tcp_input.c b/net/ipv4/tcp_input.c
index 1f3ce7aea716..19d00e7dae1d 100644
--- a/net/ipv4/tcp_input.c
+++ b/net/ipv4/tcp_input.c
@@ -82,6 +82,7 @@
 #include <net/mptcp.h>
 
 int sysctl_tcp_max_orphans __read_mostly = NR_FILE;
+int sysctl_tcp_simult_connect __read_mostly = IS_ENABLED(CONFIG_TCP_SIMULT_CONNECT_DEFAULT_ON);
 
 #define FLAG_DATA		0x01 /* Incoming frame contained data.		*/
 #define FLAG_WIN_UPDATE		0x02 /* Incoming ACK was a window update.	*/
@@ -6309,7 +6310,7 @@ static int tcp_rcv_synsent_state_process(struct sock *sk, struct sk_buff *skb,
 	    tcp_paws_reject(&tp->rx_opt, 0))
 		goto discard_and_undo;
 
-	if (th->syn) {
+	if (th->syn && sysctl_tcp_simult_connect) {
 		/* We see SYN without ACK. It is attempt of
 		 * simultaneous connect with crossed SYNs.
 		 * Particularly, it can be connect to self.
-- 
2.36.1

From ba88f37984132f263614dac342f038c3490183a2 Mon Sep 17 00:00:00 2001
From: Levente Polyak <levente@leventepolyak.net>
Date: Thu, 11 Mar 2021 23:09:50 +0100
Subject: [PATCH 101/104] ovl: add config to disable unprivileged user
 namespace mounts

When disabled, unprivileged users will not be able to create
new overlayfs mounts. This cuts the attack surface if no
unprivileged user namespace mounts are required like for
running rootless containers.

Signed-off-by: Levente Polyak <levente@leventepolyak.net>
(cherry picked from commit 2bb7434a6f76faf38277d495be0bebe74c9ec6e0)
---
 fs/overlayfs/Kconfig | 16 ++++++++++++++++
 fs/overlayfs/super.c |  2 ++
 2 files changed, 18 insertions(+)

diff --git a/fs/overlayfs/Kconfig b/fs/overlayfs/Kconfig
index dd188c7996b3..f1f14808bc8f 100644
--- a/fs/overlayfs/Kconfig
+++ b/fs/overlayfs/Kconfig
@@ -124,3 +124,19 @@ config OVERLAY_FS_METACOPY
 	  that doesn't support this feature will have unexpected results.
 
 	  If unsure, say N.
+
+config OVERLAY_FS_UNPRIVILEGED
+	bool "Overlayfs: turn on unprivileged user namespace mounts"
+	default n
+	depends on OVERLAY_FS
+	help
+	  When disabled, unprivileged users will not be able to create
+	  new overlayfs mounts. This cuts the attack surface if no
+	  unprivileged user namespace mounts are required like for
+	  running rootless containers.
+
+	  Overlayfs has been part of several recent local privilege
+	  escalation exploits, so if you are security-conscious
+	  you want to disable this.
+
+	  If unsure, say N.
diff --git a/fs/overlayfs/super.c b/fs/overlayfs/super.c
index 001cdbb8f015..507561ee2f74 100644
--- a/fs/overlayfs/super.c
+++ b/fs/overlayfs/super.c
@@ -2165,7 +2165,9 @@ static struct dentry *ovl_mount(struct file_system_type *fs_type, int flags,
 static struct file_system_type ovl_fs_type = {
 	.owner		= THIS_MODULE,
 	.name		= "overlay",
+#ifdef CONFIG_OVERLAY_FS_UNPRIVILEGED
 	.fs_flags	= FS_USERNS_MOUNT,
+#endif
 	.mount		= ovl_mount,
 	.kill_sb	= kill_anon_super,
 };
-- 
2.36.1

From 6f0497a66571ad0a17a114966cdc19b930bc61cd Mon Sep 17 00:00:00 2001
From: Levente Polyak <levente@leventepolyak.net>
Date: Tue, 25 May 2021 21:04:47 +0200
Subject: [PATCH 102/104] mm, kfence: bug on data corruption after error report

Trigger BUG when kfence encounters data corruption of kfence managed
objects. This allows a finer-grained control instead of globally
enabling panic_on_warn.

Signed-off-by: Levente Polyak <levente@leventepolyak.net>
(cherry picked from commit 90faf496b2031dee30f4f939b2d873adf1812ff9)
---
 lib/Kconfig.kfence | 9 +++++++++
 mm/kfence/report.c | 5 +++++
 2 files changed, 14 insertions(+)

diff --git a/lib/Kconfig.kfence b/lib/Kconfig.kfence
index 459dda9ef619..58f12df99e6f 100644
--- a/lib/Kconfig.kfence
+++ b/lib/Kconfig.kfence
@@ -96,4 +96,13 @@ config KFENCE_KUNIT_TEST
 	  during boot; say M if you want the test to build as a module; say N
 	  if you are unsure.
 
+config KFENCE_BUG_ON_DATA_CORRUPTION
+	bool "Trigger a BUG when data corruption is detected"
+	default y
+	help
+	  Select this option if the kernel should BUG when kfence encounters
+	  data corruption of kfence managed objects after error report.
+
+	  If unsure, say Y.
+
 endif # KFENCE
diff --git a/mm/kfence/report.c b/mm/kfence/report.c
index f5a6d8ba3e21..5f721b2f874e 100644
--- a/mm/kfence/report.c
+++ b/mm/kfence/report.c
@@ -8,6 +8,7 @@
 #include <linux/stdarg.h>
 
 #include <linux/kernel.h>
+#include <linux/bug.h>
 #include <linux/lockdep.h>
 #include <linux/math.h>
 #include <linux/printk.h>
@@ -267,6 +268,10 @@ void kfence_report_error(unsigned long address, bool is_write, struct pt_regs *r
 
 	lockdep_on();
 
+#ifdef CONFIG_KFENCE_BUG_ON_DATA_CORRUPTION
+	BUG();
+#endif
+
 	if (panic_on_warn)
 		panic("panic_on_warn set ...\n");
 
-- 
2.36.1

From 3603ccc14d41bb0c4caf7ab0922f5b999c53dd87 Mon Sep 17 00:00:00 2001
From: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
Date: Thu, 16 Dec 2021 10:55:13 +0100
Subject: [PATCH 103/104] slub: Bug on free of non-slab objects

Before commit d0fe47c64152 ("slub: add back check for free nonslab
objects"), freeing a non-slab object used to trigger a BUG if
CONFIG_DEBUG_VM was enabled. Now it only warns, which I think is not
enough for such a memory corruption. Let's restore the previous
behaviour, but tie it to CONFIG_BUG_ON_DATA_CORRUPTION as suggested by
Levente.

After page folios were introduced in v5.17, this patch was adapted to
trigger a bug when the order of the folio is zero instead of when the
page is not a compound page, which is not equivalent but respects the
semantics of the conversion to page folios and follows the change made
to the WARN_ON_ONCE beneath.

Suggested-by: Levente Polyak <levente@leventepolyak.net>
Signed-off-by: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
(cherry picked from commit 47da5f357c345b294e533d90674c0ca10b663d29)
---
 mm/slub.c | 4 ++++
 1 file changed, 4 insertions(+)

diff --git a/mm/slub.c b/mm/slub.c
index 07b5d66f0044..0dc8f7ec6383 100644
--- a/mm/slub.c
+++ b/mm/slub.c
@@ -3634,8 +3634,12 @@ static inline void free_large_kmalloc(struct folio *folio, void *object)
 {
 	unsigned int order = folio_order(folio);
 
+#ifdef CONFIG_BUG_ON_DATA_CORRUPTION
+	BUG_ON(order == 0);
+#else
 	if (WARN_ON_ONCE(order == 0))
 		pr_warn_once("object pointer: 0x%p\n", object);
+#endif
 
 	kfree_hook(object);
 	mod_lruvec_page_state(folio_page(folio, 0), NR_SLAB_UNRECLAIMABLE_B,
-- 
2.36.1

From 25373886ebb9e448f7a6041db78cb969197e7368 Mon Sep 17 00:00:00 2001
From: Levente Polyak <levente@leventepolyak.net>
Date: Thu, 9 Jun 2022 17:31:14 +0200
Subject: [PATCH 104/104] Linux hardened 5.18.3-hardened1

Signed-off-by: Levente Polyak <levente@leventepolyak.net>
(cherry picked from commit 5ab990100a067c5daf2c03c6f0e7e4304b9a5f56)
---
 Makefile | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/Makefile b/Makefile
index eb3adfec0b22..d586cb42c378 100644
--- a/Makefile
+++ b/Makefile
@@ -2,7 +2,7 @@
 VERSION = 5
 PATCHLEVEL = 18
 SUBLEVEL = 3
-EXTRAVERSION =
+EXTRAVERSION = -hardened1
 NAME = Superb Owl
 
 # *DOCUMENTATION*
-- 
2.36.1

